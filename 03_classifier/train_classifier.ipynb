{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "uY8J4dOtaZQb"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adubowski/redi-xai/blob/main/classifier/train_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brFvUoZ_RVQE"
      },
      "source": [
        "# Train a VGG16 Skin Cancer Classifier\n",
        "The approach here is based on code from https://github.com/laura-rieger/deep-explanation-penalization/tree/master/isic-skin-cancer/ISIC. In particular, the code in the cells \"Functions for training\" and \"Functions for evaluation\" are taken almost directly from the Rieger code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCguKv4TWTvE"
      },
      "source": [
        "## Libraries, arguments and setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFzu7KlCR4Pt"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "import torch\n",
        "import sys\n",
        "import numpy as np\n",
        "import pickle as pkl\n",
        "from os.path import join as oj\n",
        "from datetime import datetime\n",
        "import torch.optim as optim\n",
        "import os\n",
        "from torch.utils.data import TensorDataset, ConcatDataset\n",
        "import argparse\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from torch import nn\n",
        "from numpy.random import randint\n",
        "import torchvision.models as models\n",
        "import time\n",
        "import copy\n",
        "import gc\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ginv9jtpuO2V"
      },
      "source": [
        "### Mount Google Drive and create paths for directories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrTOXk0lSC8F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f53977b4-a1f5-4d3e-e318-6bcba11d97ad"
      },
      "source": [
        "drive.mount(\"/content/drive\")\n",
        "dir_path = \"/content/drive/MyDrive/redi-detecting-cheating\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKhfXd_ry4Og"
      },
      "source": [
        "model_path = oj(dir_path, \"models\", \"initial_classifier\")\n",
        "model_training_path = oj(model_path, \"training_224\")\n",
        "data_path = oj(dir_path, \"data\")\n",
        "\n",
        "not_cancer_path = oj(data_path, \"processed\", \"no_cancer_224\")\n",
        "cancer_path = oj(data_path, \"processed\", \"cancer_224\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDKlrNh3ucu2"
      },
      "source": [
        "#### Arguments for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEo0TcCMUXXo"
      },
      "source": [
        "mean = np.asarray([0.485, 0.456, 0.406])\n",
        "std = np.asarray([0.229, 0.224, 0.225])\n",
        "\n",
        "# Training settings\n",
        "parser = argparse.ArgumentParser(description='ISIC Lesion Classification')\n",
        "parser.add_argument('--batch_size', type=int, default=16, metavar='N',\n",
        "                    help='input batch size for training (default: 64)')\n",
        "\n",
        "parser.add_argument('--epochs', type=int, default=5, metavar='N',\n",
        "                    help='number of epochs to train (default: 10)')\n",
        "parser.add_argument('--lr', type=float, default=0.00001, metavar='LR',\n",
        "                    help='learning rate needs to be extremely small, otherwise loss nans (default: 0.00001)')\n",
        "parser.add_argument('--momentum', type=float, default=0.9, metavar='M',\n",
        "                    help='SGD momentum (default: 0.5)')\n",
        "parser.add_argument('--seed', type=int, default=42, metavar='S',\n",
        "                    help='random seed (default: 42)')\n",
        "parser.add_argument('--regularizer_rate', type=float, default=0.0, metavar='N',\n",
        "                    help='hyperparameter for CDEP weight - higher means more regularization')\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "regularizer_rate = args.regularizer_rate\n",
        "\n",
        "num_epochs = args.epochs\n",
        "\n",
        "device = torch.device(0)\n",
        "\n",
        "torch.manual_seed(args.seed);\n",
        "model = models.vgg16(pretrained=True)\n",
        "\n",
        "model.classifier[-1] = nn.Linear(4096, 2)\n",
        "model = model.to(device)\n",
        "params_to_update = model.classifier.parameters()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uY8J4dOtaZQb"
      },
      "source": [
        "#### Clean up the image directories\n",
        "- Remove empty images\n",
        "- Remove duplicates which appear in a new folder but not the original.\n",
        "- Ensure image sizes are all 224x224"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNzmHhf0aYB6"
      },
      "source": [
        "def clean_up_empty_files(path):\n",
        "    list_files= os.listdir(path)\n",
        "    num_files = len(list_files)\n",
        "    for i in tqdm(range(num_files)):\n",
        "        if os.path.getsize(oj(path, list_files[i])) < 100:\n",
        "            os.remove(oj(path, list_files[i]))\n",
        "            print(\"File \" + str(i) + \"deleted!\")\n",
        "\n",
        "def clean_up_duplicates(path1, path2):\n",
        "    newfiles = os.listdir(path1)\n",
        "    oldfiles = os.listdir(path2)\n",
        "    diff = [f for f in newfiles if f not in oldfiles]\n",
        "    for i in tqdm(diff):\n",
        "        os.remove(oj(path1, i))\n",
        "        print(\"File \" + str(i) + \"deleted!\")\n",
        "\n",
        "def check_img_sizes(path):\n",
        "    list_files= os.listdir(path)\n",
        "    num_files = len(list_files)\n",
        "    for i in tqdm(range(num_files)):\n",
        "        im = Image.open(oj(path, list_files[i]))\n",
        "        if im.width != 224 or im.height != 224:\n",
        "            print(list_files[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87Iig9whP6Pg"
      },
      "source": [
        "# clean_up_empty_files(cancer_path)\n",
        "# clean_up_empty_files(not_cancer_path)   \n",
        "\n",
        "# newpath = oj(data_path, \"no_cancer_224_inpainted\")\n",
        "# oldpath = oj(data_path, \"processed\", \"no_cancer_224\")\n",
        "# clean_up_duplicates(newpath, oldpath)\n",
        "\n",
        "# check_img_sizes(not_cancer_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7by8ywuLarvl"
      },
      "source": [
        "#### Torch dataset class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdF2_RMJmLY2"
      },
      "source": [
        "class CancerDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, path: str = None, is_cancer: int = None, data_files = None, labels = None):\n",
        "        \"\"\" \n",
        "        Expects path and is_cancer both to be supplied if the relevant images all lie in the same directory and have the same class\n",
        "        or a list of full filepaths and list of all labels are both supplied using data_files and labels otherwise.\n",
        "        \"\"\"\n",
        "        if path:\n",
        "            self.path = path\n",
        "            self.data_files = os.listdir(self.path)\n",
        "            self.is_cancer = is_cancer\n",
        "\n",
        "        else:\n",
        "            self.path = ''\n",
        "            self.data_files = data_files\n",
        "            self.labels = labels\n",
        "            self.is_cancer = None\n",
        "      \n",
        "    def __getitem__(self, i):\n",
        "        # Read in the image, convert to float between [0,1] and standardise.\n",
        "        img = Image.open(oj(self.path, self.data_files[i]))\n",
        "        img_array = np.asarray(img)/255.0\n",
        "        img_array -= mean[None, None, :]\n",
        "        img_array /= std[None, None, :]\n",
        "        img.close()\n",
        "        torch_img = torch.from_numpy(img_array.swapaxes(0,2).swapaxes(1,2)).float()\n",
        "        # Take the global class if supplied, otherwise extract the relevant label from the list of labels.\n",
        "        is_cancer = self.is_cancer if self.is_cancer is not None else self.labels[i]\n",
        "        return (torch_img, is_cancer)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyuCsMPBwBC2"
      },
      "source": [
        "#### Functions for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LomNLJdeR8mi"
      },
      "source": [
        "def gradient_sum(im, target, model, crit, device='cuda'):\n",
        "    '''assume that eveything is already on cuda'''\n",
        "    im.requires_grad = True\n",
        "    grad_params = torch.abs(torch.autograd.grad(crit(model(im), target), im,create_graph = True)[0].sum(dim=1)).sum()\n",
        "    return grad_params\n",
        "\n",
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, resume_training=False):\n",
        "    since = time.time()\n",
        "    # train_loss_history = []\n",
        "    # train_acc_history = []\n",
        "    # train_cd_history= []\n",
        "\n",
        "    best_loss = 10.0\n",
        "    patience = 3\n",
        "    cur_patience = 0\n",
        "    if len(os.listdir(model_training_path)) > 0 and resume_training:\n",
        "        model_list = [(f, os.path.getmtime(oj(model_training_path,f))) for f in os.listdir(model_training_path) if f.endswith('.pt')]\n",
        "        model_list.sort(key=lambda tup: tup[1], reverse=True)  # sorts in place from most to least recent\n",
        "        model_name = model_list[0][0]\n",
        "        model.classifier.load_state_dict(torch.load(oj(model_training_path, model_name)))\n",
        "        print(\"Model loaded!\")\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs))\n",
        "        print('-' * 10)\n",
        "        \n",
        "        # Each epoch has a training and validation phase\n",
        "        optimizer.step()\n",
        "        model.train()  # Set model to training mode\n",
        "        phase = 'train'\n",
        "        running_loss = 0.0\n",
        "        running_loss_cd = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        # Iterate over data.\n",
        "        for i, (inputs, labels) in tqdm(enumerate(dataloaders[phase])):\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward\n",
        "            # track history if only in train\n",
        "            with torch.set_grad_enabled(phase == 'train'):\n",
        "                # need to do calc beforehand because we do need the gradients\n",
        "                if phase == 'train' and regularizer_rate !=0:\n",
        "                    inputs.requires_grad = True\n",
        "                    add_loss = gradient_sum(inputs, labels, model, criterion)  \n",
        "                    if add_loss!=0:\n",
        "                        (regularizer_rate*add_loss).backward()\n",
        "                        optimizer.step()\n",
        "                    #print(torch.cuda.memory_allocated()/(np.power(10,9)))\n",
        "                    optimizer.zero_grad()   \n",
        "                    running_loss_cd += add_loss.item() * inputs.size(0)\n",
        "  \n",
        "                    #inputs.require_grad = False\n",
        "                      \n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "                if phase == 'train':\n",
        "                    (loss).backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "            # statistics\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            \n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss / dataset_sizes[phase]\n",
        "        epoch_cd_loss = running_loss_cd / dataset_sizes[phase]\n",
        "    \n",
        "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "        print('{} Loss: {:.4f} Acc: {:.4f} CD Loss : {:.4f}'.format(\n",
        "            phase, epoch_loss, epoch_acc, epoch_cd_loss))\n",
        "\n",
        "        # train_loss_history.append(epoch_loss)\n",
        "        # train_cd_history.append(epoch_cd_loss)\n",
        "        # train_acc_history.append(epoch_acc.item())\n",
        "        torch.save(model.classifier.state_dict(), oj(model_training_path, datetime.now().strftime(\"%Y%m%d%H%M%S\") + \".pt\"))     \n",
        "  \n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60)\n",
        "    )\n",
        "    print('Best val loss: {:4f}'.format(best_loss))\n",
        "\n",
        "    # load best model weights\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0SBBqObJhqd"
      },
      "source": [
        "#### Functions for evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpogJYi27yAv"
      },
      "source": [
        "from sklearn.metrics import auc,average_precision_score, roc_curve,roc_auc_score,precision_recall_curve, f1_score\n",
        "\n",
        "def get_output(model, dataset):\n",
        "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=16,\n",
        "                                             shuffle=False, num_workers=2)\n",
        "    model = model.eval()\n",
        "    y = []\n",
        "    y_hat = []\n",
        "    softmax= torch.nn.Softmax()\n",
        "    with torch.no_grad() :\n",
        "        for inputs, labels in data_loader:\n",
        "            y_hat.append((labels).cpu().numpy())\n",
        "            y.append(torch.nn.Softmax(dim=1)( model(inputs.cuda()))[:,1].detach().cpu().numpy()) # take the probability for cancer\n",
        "    y_hat = np.concatenate( y_hat, axis=0 )\n",
        "    y = np.concatenate( y, axis=0 )\n",
        "    return y, y_hat # in the training set the values were switched\n",
        "\n",
        "def get_auc_f1(model, dataset,fname = None, ):\n",
        "    if fname !=None:\n",
        "        with open(fname, 'rb') as f:\n",
        "            weights = torch.load(f)\n",
        "        if \"classifier.0.weight\" in weights.keys(): #for the gradient models we unfortunately saved all of the weights\n",
        "            model.load_state_dict(weights)\n",
        "        else:\n",
        "            model.classifier.load_state_dict(weights)\n",
        "        y, y_hat = get_output(model.classifier, dataset)\n",
        "    else:   \n",
        "        y, y_hat = get_output(model, dataset)\n",
        "    auc =roc_auc_score(y_hat, y)\n",
        "    f1 = np.asarray([f1_score(y_hat, y > x) for x in np.linspace(0.1,1, num = 10) if (y >x).any() and (y<x).any()]).max()\n",
        "    return auc, f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bh_ofmebWOV1"
      },
      "source": [
        "## Initial Classifier Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNeCSZrmut9r"
      },
      "source": [
        "#### Combine datasets and split to train-test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSXkwWzEPB2B"
      },
      "source": [
        "cancer_dataset = CancerDataset(path=cancer_path, is_cancer=1)\n",
        "not_cancer_dataset = CancerDataset(path=not_cancer_path, is_cancer=0)\n",
        "complete_dataset = ConcatDataset((cancer_dataset, not_cancer_dataset))\n",
        "\n",
        "num_total = len(complete_dataset)\n",
        "num_train = int(0.8 * num_total)\n",
        "num_test = num_total - num_train\n",
        "torch.manual_seed(0);\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(complete_dataset, [num_train, num_test])\n",
        "datasets = {'train' : train_dataset, 'test':test_dataset}\n",
        "dataset_sizes = {'train' : len(train_dataset), 'test':len(test_dataset)}\n",
        "\n",
        "dataloaders = {x: torch.utils.data.DataLoader(datasets[x], batch_size=args.batch_size,\n",
        "                                             shuffle=True, num_workers=2)\n",
        "              for x in ['train', 'test']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8VFcQXuVcM5"
      },
      "source": [
        "##### Record the specific files in the training/test sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "as36MDxbJFsa"
      },
      "source": [
        "def list_to_file(li, filename):\n",
        "  with open(filename, 'w') as f:\n",
        "    for item in li:\n",
        "      f.write(\"%s\\n\" % item)\n",
        "\n",
        "def extract_filenames(train_subset, test_subset):\n",
        "  # Extract the relevant indices of the concat dataset\n",
        "  train_idx, test_idx = train_subset.indices, test_subset.indices\n",
        "\n",
        "  # Extract the filenames for the cancer_dataset and not_cancer_dataset and concatenate with their directory path.\n",
        "  # Each original dataset is stored by the ConcatDataset class. So even though train_subset is a subset, the info for the whole cancer dataset is stored in train_subset.dataset.datasets[0]\n",
        "  cancer_filepaths      = [oj(train_subset.dataset.datasets[0].path, file) for file in train_subset.dataset.datasets[0].data_files]\n",
        "  not_cancer_filepaths  = [oj(train_subset.dataset.datasets[1].path, file) for file in train_subset.dataset.datasets[1].data_files]\n",
        "\n",
        "  filepaths = cancer_filepaths + not_cancer_filepaths    # Append the lists together, this combined list is what the indices are based on.\n",
        "\n",
        "  train_files = [filepaths[i] for i in train_idx]\n",
        "  test_files  = [filepaths[i] for i in test_idx]\n",
        "\n",
        "  return train_files, test_files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tQgG8NcVYtT"
      },
      "source": [
        "# # Call the function and get the full file paths.\n",
        "# train_files, test_files = extract_filenames(train_dataset, test_dataset)\n",
        "# list_to_file(train_files, oj(dir_path, 'models', 'train_files.txt'))   # Write the training filepaths to a text file.\n",
        "# list_to_file(test_files,  oj(dir_path, 'models', 'test_files.txt'))    # Write the testing filepaths to a text file."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAMQLRX5uytt"
      },
      "source": [
        "#### Weights for training\n",
        "Since the classes are unbalanced, we need to account for this in the loss function while training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL-6d9qHR3WP"
      },
      "source": [
        "cancer_ratio = len(cancer_dataset)/len(complete_dataset)\n",
        "\n",
        "not_cancer_ratio = 1 - cancer_ratio\n",
        "cancer_weight = 1/cancer_ratio\n",
        "not_cancer_weight = 1/ not_cancer_ratio\n",
        "weights = np.asarray([not_cancer_weight, cancer_weight])\n",
        "weights /= weights.sum()\n",
        "weights = torch.tensor(weights).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight = weights.double().float())\n",
        "\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=args.lr, momentum=args.momentum)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suYKwRYvv6DV"
      },
      "source": [
        "#### Train and save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jt97ZEQcSARG"
      },
      "source": [
        "model = train_model(model, dataloaders, criterion, optimizer_ft, num_epochs=num_epochs, resume_training=False)\n",
        "# pid = datetime.now().strftime('%Y%m%d%H%M%S') \n",
        "# torch.save(model.classifier.state_dict(),oj(dir_path, model_path, pid + \".pt\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7sSm3CHN1_T"
      },
      "source": [
        "auc, f1 = get_auc_f1(model, test_dataset)\n",
        "print(\"AUC: \", auc)\n",
        "print(\"F1: \", f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwHes9Vs-tXo"
      },
      "source": [
        "results_file_path = oj(dir_path, \"auc_f1_224_10.txt\")\n",
        "print(results_file_path)\n",
        "with open(results_file_path, 'w') as f:\n",
        "    f.write('AUC: ' + str(auc) + \"\\n\")\n",
        "    f.write('F1: ' + str(f1) + \"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzfS28o0VuDl"
      },
      "source": [
        "## Classifier Retraining\n",
        "Train a classifier after inpainting the coloured patches in the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzRXTUdkkDO-"
      },
      "source": [
        "# Save to a different folder so it is easy to access for testing.\n",
        "model_training_path = oj(model_path, \"training_inpainted\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V24C10fmVtm3"
      },
      "source": [
        "train_files = open(oj(dir_path, \"models\", \"train_files_used.txt\"), 'rt').read().splitlines()\n",
        "test_files = open(oj(dir_path, \"models\", \"test_files_used.txt\"), 'rt').read().splitlines()\n",
        "\n",
        "# Create the labels based on the directory the images are contained in.\n",
        "train_labels = [0 if \"no_cancer\" in fpath else 1 for fpath in train_files]\n",
        "test_labels = [0 if \"no_cancer\" in fpath else 1 for fpath in test_files]\n",
        "\n",
        "# Replace the training ims that have patches with their inpainted counterparts.\n",
        "inpainted_train_dir = oj(dir_path, \"data\", \"results_gmcnn\", \n",
        "                         \"test_20210608-102851_inpaint_train_patches_gmcnn_s224x224_gc32\", \"inpainted\")\n",
        "inpainted_train_files = os.listdir(inpainted_train_dir)\n",
        "\n",
        "train_files_adj = [oj(inpainted_train_dir, os.path.basename(fpath)) \n",
        "                      if os.path.basename(fpath) in inpainted_train_files\n",
        "                      else fpath \n",
        "                      for fpath in train_files ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDrstUdhhJav"
      },
      "source": [
        "#### Create Torch datasets and dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syl3GHgnfsoF"
      },
      "source": [
        "train_dataset = CancerDataset(data_files = train_files_adj, labels = train_labels)\n",
        "# Test using the original images rather than inpainted versions.\n",
        "test_dataset = CancerDataset(data_files = test_files, labels = test_labels)\n",
        "\n",
        "datasets = {'train' : train_dataset, 'test':test_dataset}\n",
        "dataset_sizes = {'train' : len(train_dataset), 'test':len(test_dataset)}\n",
        "\n",
        "dataloaders = {x: torch.utils.data.DataLoader(datasets[x], batch_size=args.batch_size,\n",
        "                                             shuffle=True, num_workers=2)\n",
        "              for x in ['train', 'test']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClGYrAgZj89S"
      },
      "source": [
        "#### Initialise new VGG model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT0od75Mj70v"
      },
      "source": [
        "device = torch.device(0)\n",
        "\n",
        "torch.manual_seed(args.seed);\n",
        "model = models.vgg16(pretrained=True)\n",
        "\n",
        "model.classifier[-1] = nn.Linear(4096, 2)\n",
        "model = model.to(device)\n",
        "params_to_update = model.classifier.parameters()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeWELOIqhOGr"
      },
      "source": [
        "#### Weights for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vFkdBA3gbjG"
      },
      "source": [
        "cancer_ratio = sum(train_labels)/len(train_labels)\n",
        "\n",
        "weights = np.asarray([1/(1-cancer_ratio), 1/cancer_ratio])\n",
        "weights /= weights.sum()\n",
        "weights = torch.tensor(weights).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight = weights.double().float())\n",
        "\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=args.lr, momentum=args.momentum)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Thi47IbUlYQn"
      },
      "source": [
        "#### Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxTVeUTuju_D"
      },
      "source": [
        "model = train_model(model, dataloaders, criterion, optimizer_ft, num_epochs=5, resume_training=False)\n",
        "# pid = datetime.now().strftime('%Y%m%d%H%M%S') \n",
        "# torch.save(model.classifier.state_dict(),oj(dir_path, model_path, pid + \".pt\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "insTqmIblnBX"
      },
      "source": [
        "#### Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cdmVqb6lmTa"
      },
      "source": [
        "auc, f1 = get_auc_f1(model, test_dataset)\n",
        "print(\"AUC: \", auc)\n",
        "print(\"F1: \", f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTYdqirAlqO2"
      },
      "source": [
        "results_file_path = oj(dir_path, \"auc_f1_inpainted_10.txt\")\n",
        "print(results_file_path)\n",
        "with open(results_file_path, 'w') as f:\n",
        "    f.write('AUC: ' + str(auc) + \"\\n\")\n",
        "    f.write('F1: ' + str(f1) + \"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}