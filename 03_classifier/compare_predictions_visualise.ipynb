{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "compare_predictions_visualise.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "uYyxiwCwZp-o",
        "UR9uYlkGZsbs",
        "ibwqbCvvZ5EF",
        "R-5gYHClGrWl"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKj_Oz44TYuI"
      },
      "source": [
        "# Run Experiments\n",
        "Code for using the trained classifier and altered images to run the experiments reported in the paper. The probability outputs of the classifier are obtained for the original images and the altered images and then the results are compared. \n",
        "\n",
        "Mostly original code, but small parts have also been reused from other parts of the project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64bch0TWEsDk"
      },
      "source": [
        "### Load Libraries and Initialise Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMz4DOxe1vmt"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, Subset\n",
        "from torchvision import models\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from numpy.random import randint\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "from os.path import join as oj\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "from sklearn.metrics import recall_score, auc, roc_auc_score, f1_score\n",
        "from scipy.stats import pearsonr\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "plt.style.use('seaborn')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d23raFcKjYOO"
      },
      "source": [
        "# Install required Latex dependencies for plots\n",
        "! sudo apt-get install texlive-latex-recommended \n",
        "! sudo apt install texlive-latex-extra\n",
        "! sudo apt install dvipng\n",
        "! sudo apt install cm-super"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkxsW7a3E8y3"
      },
      "source": [
        "##### Mount Google Drive and create & store various directory paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqPXREGv11NT"
      },
      "source": [
        "drive.mount(\"/content/drive\")\n",
        "dir_path = \"/content/drive/MyDrive/redi-detecting-cheating\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExDqDo-1jqeY"
      },
      "source": [
        "model_path = oj(dir_path, \"models\", \"initial_classifier\", \"training_224\")\n",
        "model_inpainted_path = oj(dir_path, \"models\", \"initial_classifier\", \"training_inpainted\")\n",
        "\n",
        "data_path = oj(dir_path, \"data\")\n",
        "\n",
        "test_path  = oj(dir_path, \"models\", \"test_files_used.txt\")\n",
        "\n",
        "patch_run_name = \"test_20210608-083437_inpaint_coloured_patches_gmcnn_s224x224_gc32\"\n",
        "no_patch_run_name = \"test_20210608-083438_inpaint_no_patches_gmcnn_s224x224_gc32_randmask-ellipse_seed-1\"\n",
        "test_path_patches     = oj(dir_path, \"data\", \"test\", patch_run_name, \"inpainted\")\n",
        "test_path_no_patches  = oj(dir_path, \"data\", \"test\", no_patch_run_name, \"inpainted\")\n",
        "path_patches_combined     = oj(dir_path, \"data\", \"test\", patch_run_name, \"combined\")\n",
        "path_no_patches_combined  = oj(dir_path, \"data\", \"test\", no_patch_run_name, \"combined\")\n",
        "\n",
        "path_malignant_patches = oj(dir_path, \"data\", \"malignant-patches\", \"manually-adjusted\")\n",
        "path_malignant_patches_orig = oj(dir_path, \"data\", \"malignant-patches\", \"original\")\n",
        "path_malignant_inpainted = oj(\n",
        "    dir_path, \"data\", \"results_gmcnn\", \"test_20210616-174438_inpaint_malignant_gmcnn_s224x224_gc32\",\"inpainted\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3sHfoIqOknh"
      },
      "source": [
        "Parameters for standardising the data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9b0CGyQOiJJ"
      },
      "source": [
        "mean = np.asarray([0.485, 0.456, 0.406]) \n",
        "std = np.asarray([0.229, 0.224, 0.225])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5LBWHgYY0_-"
      },
      "source": [
        "## Function Definitions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWzl2-I9PFRz"
      },
      "source": [
        "##### Functions to read the data and create a Torch dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lACRR7DH12Pi"
      },
      "source": [
        "def extract_filenames(dataset_path):\n",
        "  \"\"\" Extracts the paths, names and root directory for the image files in a given directory \n",
        "          or given a file containing image filepaths.\n",
        "      Returns:\n",
        "        filenames     filenames sorted alphabetically\n",
        "        file_list     if dataset_path is a directory, then file_list is equivalent to filenames. \n",
        "                      If dataset_path is a file containing filepaths, then file_list is a list of these paths. \n",
        "        root_dir      If dataset_path is a directory, then root_dir=dataset_path, otherwise root_dir=''.\n",
        "  \"\"\"\n",
        "  if os.path.isfile(dataset_path):\n",
        "    file_list = open(dataset_path, 'rt').read().splitlines()\n",
        "    filenames = [os.path.basename(file) for file in file_list] # Extract the filename from the full filepath.\n",
        "    root_dir = ''\n",
        "  elif os.path.isdir(dataset_path):\n",
        "    file_list = os.listdir(dataset_path)\n",
        "    filenames = file_list\n",
        "    root_dir = dataset_path\n",
        "  else:\n",
        "    print('Invalid testing data file/folder path.')\n",
        "    exit(1)\n",
        "\n",
        "  # Sort alphabetically based on the filename.\n",
        "  zip_sorted = sorted(zip(filenames, file_list), key=lambda tup: tup[0])\n",
        "\n",
        "  filenames, file_list = zip(*zip_sorted)   # Unzip the sorted results.\n",
        "\n",
        "  return filenames, file_list, root_dir\n",
        "\n",
        "\n",
        "def load_files(dataset_path, imsize = (224,224)):\n",
        "  \"\"\" filelist should be either a text file containing the full paths of the relevant image files,\n",
        "         or a path to the directory containing the images.\n",
        "      Returns the images as a numpy array with float values between 0 and 1.\"\"\"\n",
        "  filenames, file_list, root_dir = extract_filenames(dataset_path)\n",
        "\n",
        "  filepaths = [oj(root_dir, file) for file in file_list]   # Concatenate the root_dir with the filename\n",
        "\n",
        "  num_files = len(file_list)\n",
        "  imgs_np = np.empty((num_files,  imsize[0], imsize[1], 3))\n",
        "  for i in tqdm(range(num_files)): \n",
        "    try:\n",
        "      img = Image.open(filepaths[i])\n",
        "      imgs_np[i] = np.asarray(img)/255.0              # Transform to float between 0 and 1 from integer between 0-255\n",
        "      img.close()\n",
        "    except FileNotFoundError:\n",
        "      pass\n",
        "    except:\n",
        "      print(i)\n",
        "  return imgs_np, filenames, filepaths\n",
        "\n",
        "\n",
        "def get_dataset(dataset_path, save_path, imsize = (224,224)):\n",
        "  if os.path.isfile(save_path):        # If the dataset has previously been saved as a tensor, load this for efficiency.\n",
        "    dataset = torch.load(save_path)\n",
        "\n",
        "    filenames, _,_ = extract_filenames(dataset_path)   # Get the associated image filenames.\n",
        "  \n",
        "  else:\n",
        "    ims, filenames, filepaths = load_files(dataset_path, imsize)   # Load in all of the images.\n",
        "\n",
        "    ims -= mean[None, None, :]    # Standardise the images as expected by the VGG16 model.\n",
        "    ims /= std[None, None, :]\n",
        "\n",
        "    # Check if the image comes from the 'no_cancer' directory or the 'cancer' directory. Cancer images have target=1.\n",
        "    targets = [0 if \"no_cancer\" in path else 1 for path in filepaths]  \n",
        "    targets = np.array(targets).astype(np.int8)\n",
        "\n",
        "    # Create a tensor dataset with the images and targets.\n",
        "    dataset = TensorDataset(torch.from_numpy(ims.swapaxes(1,3).swapaxes(2,2)).float(), torch.from_numpy(targets))\n",
        "\n",
        "    torch.save(dataset, save_path)    # save for more efficient loading the next time.\n",
        "\n",
        "  return dataset, filenames    # Return the TensorDataset and list of image filenames"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPhTjoG4ZFx2"
      },
      "source": [
        "##### Function to read in the latest model from a given directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dz6fsFF2BLwS"
      },
      "source": [
        "def load_model(model_dir):\n",
        "  # Get a list of the models in the directory and their modified times \n",
        "  model_list = [(f, os.path.getmtime(oj(model_dir,f))) for f in os.listdir(model_dir) if f.endswith('.pt')]\n",
        "  model_list.sort(key=lambda tup: tup[1], reverse=True)  # sorts in place from most to least recent.\n",
        "\n",
        "  model_name = model_list[0][0]                       # Take the most recent model.\n",
        " \n",
        "  model_dict = torch.load(oj(model_dir, model_name)) # Read the paramater dict from file.\n",
        "\n",
        "  model = models.vgg16(pretrained=True)               # Read in the original VGG16 pretrained model.\n",
        "  model.classifier[-1] = torch.nn.Linear(4096, 2)           # Set the final classification layer to have only 2 output nodes.\n",
        "\n",
        "  model.classifier.load_state_dict(model_dict)        # Use the saved model parameters.\n",
        "\n",
        "  device = torch.device(0)\n",
        "  model = model.to(device)\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2fuz5VMZWfY"
      },
      "source": [
        "##### Functions to get predictions from the model and calculate the AUC and F1 scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbhLHxUFJBED"
      },
      "source": [
        "def get_output(model, dataset):\n",
        "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=16,\n",
        "                                             shuffle=False, num_workers=2)\n",
        "    model = model.eval()\n",
        "    y = []\n",
        "    y_hat = []\n",
        "    softmax= torch.nn.Softmax()\n",
        "    with torch.no_grad() :\n",
        "        for inputs, labels in data_loader:\n",
        "          y.append((labels).cpu().numpy())\n",
        "          y_hat.append(torch.nn.Softmax(dim=1)( model(inputs.cuda()))[:,1].detach().cpu().numpy()) # take the probability for cancer\n",
        "    y = np.concatenate( y, axis=0 )\n",
        "    y_hat = np.concatenate( y_hat, axis=0 )\n",
        "    return y, y_hat\n",
        "\n",
        "def f1(y, y_hat):\n",
        "  return np.asarray([f1_score(y, y_hat > x) for x in np.linspace(0.1,1, num = 10) if (y_hat >x).any() and (y_hat<x).any()]).max()\n",
        "\n",
        "def get_auc_f1(model, dataset,fname = None, ):\n",
        "    if fname !=None:\n",
        "        with open(fname, 'rb') as f:\n",
        "            weights = torch.load(f)\n",
        "        if \"classifier.0.weight\" in weights.keys():\n",
        "            model.load_state_dict(weights)\n",
        "        else:\n",
        "            model.classifier.load_state_dict(weights)\n",
        "        y, y_hat = get_output(model.classifier, dataset)\n",
        "    else:   \n",
        "        y, y_hat = get_output(model, dataset)\n",
        "    auc = roc_auc_score(y, y_hat)\n",
        "    return auc, f1(y, y_hat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYyxiwCwZp-o"
      },
      "source": [
        "#### Plot functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR9uYlkGZsbs"
      },
      "source": [
        "##### Set default plot settings to work with the ACM Latex format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWV6i9ykiP3g"
      },
      "source": [
        "def latexify(fig_width=None, fig_height=None, columns=1):\n",
        "    \"\"\"Set up matplotlib's RC params for LaTeX plotting.\n",
        "    Call this before plotting a figure.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    fig_width : float, optional, inches\n",
        "    fig_height : float,  optional, inches\n",
        "    columns : {1, 2}\n",
        "    \"\"\"\n",
        "\n",
        "    # code from https://nipunbatra.github.io/blog/visualisation/2014/06/02/latexify.html\n",
        "    # adapted from http://www.scipy.org/Cookbook/Matplotlib/LaTeX_Examples\n",
        "\n",
        "    assert(columns in [1,2])\n",
        "\n",
        "    if fig_width is None:\n",
        "        fig_width = 3.39 if columns==1 else 6.9 # width in inches\n",
        "\n",
        "    if fig_height is None:\n",
        "        golden_mean = (np.sqrt(5)-1.0)/2.0    # Aesthetic ratio\n",
        "        fig_height = fig_width*golden_mean # height in inches\n",
        "\n",
        "    MAX_HEIGHT_INCHES = 8.0\n",
        "    if fig_height > MAX_HEIGHT_INCHES:\n",
        "        print(\"WARNING: fig_height too large:\" + fig_height + \n",
        "              \"so will reduce to\" + MAX_HEIGHT_INCHES + \"inches.\")\n",
        "        fig_height = MAX_HEIGHT_INCHES\n",
        "\n",
        "    params = {'backend': 'ps',\n",
        "              'text.latex.preamble': [r'\\usepackage{gensymb}'],\n",
        "              'axes.labelsize': 8, # fontsize for x and y labels (was 10)\n",
        "              'axes.titlesize': 8,\n",
        "              'font.size': 8, # was 10\n",
        "              'legend.fontsize': 8, # was 10\n",
        "              'xtick.labelsize': 8,\n",
        "              'ytick.labelsize': 8,\n",
        "              'text.usetex': True,\n",
        "              'figure.figsize': [fig_width,fig_height],\n",
        "              'font.family': 'serif'\n",
        "    }\n",
        "\n",
        "    matplotlib.rcParams.update(params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkZxyiWGaku7"
      },
      "source": [
        "latexify()  # Adjust default matplotlib settings for ACM Latex format."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibwqbCvvZ5EF"
      },
      "source": [
        "##### Function to print & save plots comparing two sets of predicted probabilities.\n",
        "- Histogram of predicted probabilities for Original and Altered datasets.\n",
        "- Histogram of difference in predicted probability for each image.\n",
        "- Scatterplot of probabilities for Original vs. Altered images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dviXLF3parww"
      },
      "source": [
        "def plot_compare_probs(probs_original, probs_altered, probs_original_v2, probs_altered_v2,\n",
        "                       output_dir = oj(dir_path, 'plots', 'report'), output_add = None):\n",
        "  \"\"\" Plots and saves three plots to compare the predicted probabilities before & after altering the images.\n",
        "  Input: \n",
        "    probs_original, probs_altered       The output probabilities of the classification model for the original & altered image, as a Tensor, numpy array or list.\n",
        "    probs_original_v2, probs_altered_v2 As above, but output from the retrained classifier (inpainted ims)\n",
        "    output_dir                          The path to the directory for saving the plots.\n",
        "    output_add                          An ID to add to the output filename. If left blank, then a random 10 digit ID is created.\n",
        "  Returns:\n",
        "    None    The three plots are saved to the relevant directory and also printed to screen.\n",
        "  \"\"\"\n",
        "  if output_add is None:\n",
        "    output_add = ''.join([\"%s\" % randint(0, 9) for num in range(0, 10)]) # Create a random ID to avoid overwriting previous files.\n",
        "\n",
        "  ## Plot Histogram Comparison\n",
        "  fig, ax = plt.subplots(2, 2, figsize=(3.39,3.39), sharey=True)\n",
        "  \n",
        "  ax[0,0].hist(probs_original, range=(0,1), bins=10)\n",
        "  ax[0,0].set_title('\\\\textbf{Vanilla Classifier}\\nOriginal Images')\n",
        "  ax[1,0].hist(probs_altered, range=(0,1), bins=10)\n",
        "  ax[1,0].set_title('Altered Images')\n",
        "  ax[1,0].set_xlabel('Predicted Probability')\n",
        "\n",
        "  ax[0,1].hist(probs_original_v2, range=(0,1), bins=10)\n",
        "  ax[0,1].set_title('\\\\textbf{Retrained Classifier}\\nOriginal Images')\n",
        "  ax[1,1].hist(probs_altered_v2, range=(0,1), bins=10)\n",
        "  ax[1,1].set_title('Altered Images')\n",
        "  ax[1,1].set_xlabel('Predicted Probability')\n",
        "\n",
        "  fig.text(0.0, 0.5, 'Number of Samples', va='center', rotation='vertical')\n",
        "\n",
        "  fig.tight_layout()\n",
        "\n",
        "  fig.savefig(oj(output_dir, 'Probs Comparison Hist ' + output_add + '.png'), dpi=1200)\n",
        "  plt.show()\n",
        "\n",
        "  ## Plot Scatterplot Comparison.\n",
        "  fig, ax = plt.subplots(1, 2, figsize=(3.39,1.85), sharey=True)\n",
        "\n",
        "  ax[0].scatter(probs_original, probs_altered, alpha=0.4, s=10)\n",
        "  ax[0].set(xlim=[0,1],ylim=[0,1]) \n",
        "  ax[0].set_title('\\\\textbf{Vanilla Classifier}')\n",
        "  ax[0].set_xlabel('Probability for Original')\n",
        "  ax[0].set_ylabel('Probability for Altered')\n",
        "\n",
        "  ax[1].scatter(probs_original_v2, probs_altered_v2, alpha=0.4, s=10)\n",
        "  ax[1].set(xlim=[0,1],ylim=[0,1]) \n",
        "  ax[1].set_title('\\\\textbf{Retrained Classifier}')\n",
        "  ax[1].set_xlabel('Probability for Original')\n",
        "  # ax[1].set_ylabel('Probability for Altered')\n",
        "\n",
        "  fig.tight_layout()\n",
        "  fig.savefig(oj(output_dir, 'Probs Comparison Scatter ' + output_add + '.png'), dpi=1200)\n",
        "  plt.show()\n",
        "\n",
        "  ## Calculate differences and plot histogram\n",
        "  diff_preds = probs_altered - probs_original\n",
        "  diff_preds_v2 = probs_altered_v2 - probs_original_v2\n",
        "\n",
        "  fig, ax = plt.subplots(1, 2, figsize=(3.39,1.65), sharey=True)\n",
        "\n",
        "  max_diff = max(max(abs(diff_preds)), max(abs(diff_preds_v2)))\n",
        "\n",
        "  hist_range = (-max_diff, max_diff)  # Make sure histogram is symmetric about zero.\n",
        "\n",
        "  ax[0].hist(diff_preds, range = hist_range, bins = int(np.ceil((hist_range[1]-hist_range[0])/0.05)))\n",
        "  ax[0].set_title('\\\\textbf{Vanilla Classifier}')\n",
        "  ax[0].set_ylabel('Number of Samples')\n",
        "\n",
        "  ax[1].hist(diff_preds_v2, range = hist_range, bins = int(np.ceil((hist_range[1]-hist_range[0])/0.05)))\n",
        "  ax[1].set_title('\\\\textbf{Retrained Classifier}')\n",
        "  # ax[1].set_ylabel('Number of Samples')\n",
        "\n",
        "  # Insert shared xlabel as fixed text.\n",
        "  fig.text(0.3, 0.0, 'Difference in Predicted Probability', va='bottom', rotation='horizontal')\n",
        "\n",
        "  fig.tight_layout()\n",
        "  fig.savefig(oj(output_dir, 'Diff in Predicted Probs Hist ' + output_add + '.png'), dpi=1200)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wZ3aivHao0B"
      },
      "source": [
        "## Experiments with Initial Classifier\n",
        "- Compare predictions for images with patches vs. replacing them with inpainting.\n",
        "- Compare predictions for images with no patches vs. inpainting random sections of the images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmZlPAASWkMg"
      },
      "source": [
        "#### Read the datasets and saved classifier.\n",
        "If they have been previously been saved as a tensor dataset then these are loaded for efficiency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeFBG7_nDGfT"
      },
      "source": [
        "# Load the most recent initial classifier.\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Free up memory (model file is approx. 0.5GB)\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADVAPpoP9l3c"
      },
      "source": [
        "test_dataset, test_files = get_dataset(\n",
        "    test_path, oj(data_path, 'saved-tensors', 'test_dataset.pt'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUeKpcKYCmIh"
      },
      "source": [
        "test_dataset, test_files = get_dataset(\n",
        "    test_path, oj(data_path, 'saved-tensors', 'test_dataset.pt'))\n",
        "\n",
        "inpainted_patch_dataset, patch_files = get_dataset(\n",
        "    test_path_patches, oj(data_path, 'saved-tensors', 'inpainted_patch_dataset.pt'))\n",
        "inpainted_no_patch_dataset, no_patch_files = get_dataset(\n",
        "    test_path_no_patches, oj(data_path, 'saved-tensors', 'inpainted_no_patch_dataset.pt'))\n",
        "\n",
        "print(\"# of test ims: {}\\n # of patch ims: {}\\n # of no-patch ims: {}\".format(\n",
        "    len(test_dataset), len(inpainted_patch_dataset), len(inpainted_no_patch_dataset)))\n",
        "\n",
        "# Get a boolean list of whether each test file has a patch.\n",
        "patch_ind = [file in patch_files for file in test_files]   \n",
        "no_patch_ind = [file in no_patch_files for file in test_files]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4-g4xKnJ1bt"
      },
      "source": [
        "##### Get class predictions (probabilities) for the various datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0qsxpHGZCEQ"
      },
      "source": [
        "targets_test_unaltered, preds_test_unaltered = get_output(model, test_dataset)\n",
        "\n",
        "# Note, do not use the targets created from the following datasets as they are not created properly.\n",
        "# To access these targets, use     targets_test_unaltered[patch_ind] \n",
        "_, preds_inpainted_patches = get_output(model, inpainted_patch_dataset)\n",
        "_, preds_inpainted_no_patches = get_output(model, inpainted_no_patch_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N91OBchNDqb1"
      },
      "source": [
        "##### Save the model predictions to file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6QArshUDiLm"
      },
      "source": [
        "# np.savez(oj(data_path, 'saved-tensors', 'preds_test_unaltered.npz'), test_targets=targets_test_unaltered, test_preds=preds_test_unaltered)\n",
        "# np.savez(oj(data_path, 'saved-tensors', 'preds_inpainted_patches.npz'), test_targets=targets_test_unaltered[patch_ind], test_preds=preds_inpainted_patches)\n",
        "# np.savez(oj(data_path, 'saved-tensors', 'preds_inpainted_no_patches.npz'), test_targets=targets_test_unaltered[no_patch_ind], test_preds=preds_inpainted_no_patches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpg2KEsjLGUe"
      },
      "source": [
        "#### Compare probabilities for original and altered images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlZTHkRczZcW"
      },
      "source": [
        "# #  *** The plot function has been altered so that the initial classifier & the retrained classifier results are compared side by side\n",
        "# #  *** As such, all of the plots are called at the end of the notebook.\n",
        "# # Compare the output probabilities for the inpainted images vs. the originals.\n",
        "# plot_compare_probs(preds_test_unaltered[patch_ind], preds_inpainted_patches, output_add='(inpainted patches)')\n",
        "# plot_compare_probs(preds_test_unaltered[no_patch_ind], preds_inpainted_no_patches, output_add='(inpainted no patches)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tngdvqrmbBNU"
      },
      "source": [
        "# Get the specificity and sensitivity for various partitions of the test set.\n",
        "prob_threshold = 0.4\n",
        "\n",
        "sp_p = recall_score(targets_test_unaltered[patch_ind], preds_test_unaltered[patch_ind] > prob_threshold, pos_label=0)\n",
        "sp_p_in = recall_score(targets_test_unaltered[patch_ind], preds_inpainted_patches > prob_threshold, pos_label=0)\n",
        "print(\"Specificity for images with patches is:\\t\\t\\t {:.2f}\".format(sp_p))\n",
        "print(\"Specificity for images with inpainted patches is:\\t {:.2f}\".format(sp_p_in))\n",
        "\n",
        "sp_np = recall_score(targets_test_unaltered[no_patch_ind], preds_test_unaltered[no_patch_ind] > prob_threshold, pos_label=0)\n",
        "se_np = recall_score(targets_test_unaltered[no_patch_ind], preds_test_unaltered[no_patch_ind] > prob_threshold)\n",
        "print(\"Specificity for images without a patch is:\\t\\t {:.2f}\".format(sp_np))\n",
        "print(\"Sensitivity for images without a patch is:\\t\\t {:.2f}\".format(se_np)) \n",
        "\n",
        "sp_np_in = recall_score(targets_test_unaltered[no_patch_ind], preds_inpainted_no_patches > prob_threshold, pos_label=0)\n",
        "se_np_in = recall_score(targets_test_unaltered[no_patch_ind], preds_inpainted_no_patches > prob_threshold)  \n",
        "print(\"Specificity for images without a patch after inpainting is:\\t {:.2f}\".format(sp_np_in))\n",
        "print(\"Sensitivity for images without a patch after inpainting is:\\t {:.2f}\".format(se_np_in))\n",
        "\n",
        "results_scores = {\n",
        "    'Specificity Ims with Patches': sp_p,\n",
        "    'Specificity Patches Replaced by Inpainting': sp_p_in,\n",
        "    'Specificity Ims No Patches': sp_np,\n",
        "    'Sensitivity Ims No Patches': se_np,\n",
        "    'Specificity Ims No Patches Random Inpainting': sp_np_in,\n",
        "    'Sensitivity Ims No Patches Random Inpainting': se_np_in\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBokCYpEMEwc"
      },
      "source": [
        "## Experiments with Malignant Lesions\n",
        "- Insert coloured patches into malignant images and assess how the class probabilities change.\n",
        "- When we have retrained the classifier after inpainting the patches, do we still observe the same bias?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSFGLJl4Mr0s"
      },
      "source": [
        "malignant_patch_dataset, malignant_patch_files = get_dataset(\n",
        "    path_malignant_patches, oj(data_path, 'saved-tensors', 'malignant_patch_dataset.pt'))\n",
        "\n",
        "# malignant_patch_orig_dataset, malignant_patch_orig_files = get_dataset(\n",
        "#     path_malignant_patches_orig, oj(data_path, 'saved-tensors', 'malignant_patch_orig_dataset.pt'))\n",
        "\n",
        "malignant_inpainted_dataset, _ = get_dataset(\n",
        "    path_malignant_inpainted, oj(data_path, 'saved-tensors', 'malignant_inpainted_dataset.pt'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8tTjr3tYyVJ"
      },
      "source": [
        "#### Use only unique lesion images.\n",
        "There are multiple versions of the same lesion image based on randomly adding three different patches and then manually removing those where the patch partially overlaps the lesion. To avoid skewing results, just take one version of each unique lesion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdjXncoVVXp_"
      },
      "source": [
        "# Find the index of the first occurrence for each unique lesion image from the manually adjusted folder.\n",
        "_, u_idx = np.unique([fname[:12] for fname in malignant_patch_files], return_index=True)\n",
        "\n",
        "# Get the associated filename with these indices.\n",
        "malignant_patch_files = [malignant_patch_files[i] for i in u_idx]\n",
        "\n",
        "# # For the original directory, we first take the same images as above.\n",
        "# # For the unique lesion images that were removed manually from the adjusted folder,\n",
        "# # we take the first corresponding image in the original folder.\n",
        "# fstems_orig = np.unique([fname[:12] for fname in malignant_patch_orig_files])\n",
        "\n",
        "# other_files = [fstem + '_0.jpg'  \n",
        "#                 for fstem in fstems_orig\n",
        "#                if fstem not in [f[:12] for f in malignant_patch_files] ]\n",
        "\n",
        "# selected_orig_files = malignant_patch_files + other_files \n",
        "\n",
        "# orig_idx = [i for f1 in selected_orig_files \n",
        "#               for i, f2 in enumerate(malignant_patch_orig_files) \n",
        "#                 if f1==f2]\n",
        "\n",
        "# Create the required subsets.\n",
        "malignant_patch_dataset = Subset(malignant_patch_dataset, u_idx)\n",
        "malignant_patch_files = [f[:12] + '.jpg' for f in malignant_patch_files]\n",
        "\n",
        "# malignant_patch_orig_dataset = Subset(malignant_patch_orig_dataset, orig_idx)\n",
        "# malignant_patch_orig_files = [f[:12] + '.jpg' for f in selected_orig_files]\n",
        "\n",
        "# The files in the inpainted set match the patch set, so use the same indices.\n",
        "malignant_inpainted_dataset = Subset(malignant_inpainted_dataset, u_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PH2LLMQuNT1e"
      },
      "source": [
        "_, preds_malignant_patches = get_output(model, malignant_patch_dataset)\n",
        "\n",
        "# _, preds_malignant_patches_orig = get_output(model, malignant_patch_orig_dataset)\n",
        "\n",
        "_, preds_malignant_inpainted = get_output(model, malignant_inpainted_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3A39SEyPUxQ9"
      },
      "source": [
        "# np.savez(oj(data_path, 'saved-tensors', 'preds_malignant_patches.npz'), test_targets=np.ones(len(preds_malignant_patches)), test_preds=preds_malignant_patches)\n",
        "# np.savez(oj(data_path, 'saved-tensors', 'preds_malignant_patches_orig.npz'), test_targets=np.ones(len(preds_malignant_patches_orig)), test_preds=preds_malignant_patches_orig)\n",
        "# np.savez(oj(data_path, 'saved-tensors', 'preds_malignant_inpainted.npz'), test_targets=np.ones(len(preds_malignant_inpainted)), test_preds=preds_malignant_inpainted)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfs1YW-eXhWr"
      },
      "source": [
        "#### Find matching indices\n",
        "Find the corresponding indices in the whole test_dataset for each edited malignant image. We use these to compare the original predicted probability with the predicted probability for the altered image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-iaBmlVXUx8"
      },
      "source": [
        "mal_idx = [i for f1 in malignant_patch_files  \n",
        "              for i,f2 in enumerate(test_files) \n",
        "                if f1 == f2]\n",
        "\n",
        "# mal_orig_idx = [i for f1 in malignant_patch_orig_files  \n",
        "#                     for i,f2 in enumerate(test_files) \n",
        "#                       if f1 == f2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53LPBhWc1YzH"
      },
      "source": [
        "#### Evaluate Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIvlA1jhYw3g"
      },
      "source": [
        "se_mal = recall_score(targets_test_unaltered[mal_idx], preds_test_unaltered[mal_idx] > prob_threshold)\n",
        "se_mal_p = recall_score(targets_test_unaltered[mal_idx], preds_malignant_patches > prob_threshold)\n",
        "se_mal_in = recall_score(targets_test_unaltered[mal_idx], preds_malignant_inpainted > prob_threshold)\n",
        "\n",
        "print(\"Sensitivity for selected malignant images is:\\t\\t {:.2f}\".format(se_mal)) \n",
        "print(\"Sensitivity for malignant images after adding a patch is:\\t\\t {:.2f}\".format(se_mal_p)) \n",
        "print(\"Sensitivity for malignant images after inpainting is:\\t\\t {:.2f}\".format(se_mal_in)) \n",
        "\n",
        "results_scores['Sensitivity selected mal images'] = se_mal\n",
        "results_scores['Sensitivity mal images added patch'] = se_mal_p\n",
        "results_scores['Sensitivity mal images inpainted'] = se_mal_in\n",
        "\n",
        "# Compare the outputs for the malignant images.\n",
        "# plot_compare_probs(preds_test_unaltered[mal_idx], preds_malignant_patches, output_add='(malignant manually adjusted)')\n",
        "# plot_compare_probs(preds_test_unaltered[mal_orig_idx], preds_malignant_patches_orig, output_add='(malignant whole)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJn3NNDAU82k"
      },
      "source": [
        "## Experiments with Retrained Classifier\n",
        "The classifier has been retrained after replacing the patches with inpainted versions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BN22hWlUu1N"
      },
      "source": [
        "# Load the new classifier.\n",
        "model_v2 = load_model(model_inpainted_path)\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wt7AlEBnVq4t"
      },
      "source": [
        "_, preds_test_unaltered_v2 = get_output(model_v2, test_dataset)\n",
        "_, preds_malignant_patches_v2 = get_output(model_v2, malignant_patch_dataset)\n",
        "_, preds_malignant_inpainted_v2 = get_output(model_v2, malignant_inpainted_dataset)\n",
        "\n",
        "se_mal_v2 = recall_score(targets_test_unaltered[mal_idx], preds_test_unaltered_v2[mal_idx] > prob_threshold)\n",
        "se_mal_p_v2 = recall_score(targets_test_unaltered[mal_idx], preds_malignant_patches_v2 > prob_threshold)\n",
        "se_mal_in_v2 = recall_score(targets_test_unaltered[mal_idx], preds_malignant_inpainted_v2 > prob_threshold)\n",
        "\n",
        "print(\"Retrained Classifier ----\")\n",
        "print(\"Sensitivity for selected malignant images is:\\t\\t {:.2f}\".format(se_mal_v2))\n",
        "print(\"Sensitivity for malignant images after adding a patch is:\\t\\t {:.2f}\".format(se_mal_p_v2))\n",
        "print(\"Sensitivity for malignant images after inpainting is:\\t\\t {:.2f}\".format(se_mal_in_v2)) \n",
        "results_scores['Sensitivity selected mal images (retrained classifier)'] = se_mal_v2\n",
        "results_scores['Sensitivity mal images added patch (retrained classifier)'] = se_mal_p_v2\n",
        "results_scores['Sensitivity mal images inpainted (retrained classifier)'] = se_mal_in_v2\n",
        "\n",
        "# plot_compare_probs(preds_malignant_patches, preds_malignant_patches_v2, output_add='(malignant using retrained classifier)')\n",
        "# plot_compare_probs(preds_test_unaltered_v2[mal_idx], preds_malignant_patches_v2, output_add='(malignant patches vs. original - retrained mod)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__59Jga6Wg5l"
      },
      "source": [
        "_, preds_inpainted_patches_v2 = get_output(model_v2, inpainted_patch_dataset)\n",
        "_, preds_inpainted_no_patches_v2 = get_output(model_v2, inpainted_no_patch_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2mSVbp9b36L"
      },
      "source": [
        "# np.savez(oj(data_path, 'saved-tensors', 'preds_test_unaltered_v2.npz'), test_targets=targets_test_unaltered, test_preds=preds_test_unaltered_v2)\n",
        "# np.savez(oj(data_path, 'saved-tensors', 'preds_inpainted_patches_v2.npz'), test_targets=targets_test_unaltered[patch_ind], test_preds=preds_inpainted_patches_v2)\n",
        "# np.savez(oj(data_path, 'saved-tensors', 'preds_inpainted_no_patches_v2.npz'), test_targets=targets_test_unaltered[no_patch_ind], test_preds=preds_inpainted_no_patches_v2)\n",
        "# np.savez(oj(data_path, 'saved-tensors', 'preds_malignant_patches_v2.npz'), test_targets=targets_test_unaltered[mal_idx], test_preds=preds_malignant_patches_v2)\n",
        "# np.savez(oj(data_path, 'saved-tensors', 'preds_malignant_inpainted_v2.npz'), test_targets=targets_test_unaltered[mal_idx], test_preds=preds_malignant_inpainted_v2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVXS7EQTWdMj"
      },
      "source": [
        "sp_p_v2 = recall_score(targets_test_unaltered[patch_ind], preds_test_unaltered_v2[patch_ind] > prob_threshold, pos_label=0)\n",
        "sp_p_in_v2 = recall_score(targets_test_unaltered[patch_ind], preds_inpainted_patches_v2 > prob_threshold, pos_label=0)\n",
        "print(\"Specificity for images with patches is:\\t\\t\\t {:.2f}\".format(sp_p_v2))\n",
        "print(\"Specificity for images with inpainted patches is:\\t {:.2f}\".format(sp_p_in_v2))\n",
        "\n",
        "sp_np_v2 = recall_score(targets_test_unaltered[no_patch_ind], preds_test_unaltered_v2[no_patch_ind] > prob_threshold, pos_label=0)\n",
        "se_np_v2 = recall_score(targets_test_unaltered[no_patch_ind], preds_test_unaltered_v2[no_patch_ind] > prob_threshold)\n",
        "print(\"Specificity for images without a patch is:\\t\\t {:.2f}\".format(sp_np_v2))\n",
        "print(\"Sensitivity for images without a patch is:\\t\\t {:.2f}\".format(se_np_v2))\n",
        "\n",
        "sp_np_in_v2 = recall_score(targets_test_unaltered[no_patch_ind], preds_inpainted_no_patches_v2 > prob_threshold, pos_label=0)\n",
        "se_np_in_v2 = recall_score(targets_test_unaltered[no_patch_ind], preds_inpainted_no_patches_v2 > prob_threshold)\n",
        "print(\"Specificity for images without a patch after inpainting is:\\t {:.2f}\".format(sp_np_in_v2))\n",
        "print(\"Sensitivity for images without a patch after inpainting is:\\t {:.2f}\".format(se_np_in_v2))\n",
        "\n",
        "results_scores.update({\n",
        "    'Specificity Ims with Patches (Retrained Classifier)': sp_p_v2,\n",
        "    'Specificity Patches Replaced by Inpainting (Retrained Classifier)': sp_p_in_v2,\n",
        "    'Specificity Ims No Patches (Retrained Classifier)': sp_np_v2,\n",
        "    'Sensitivity Ims No Patches (Retrained Classifier)': se_np_v2,\n",
        "    'Specificity Ims No Patches Random Inpainting (Retrained Classifier)': sp_np_in_v2,\n",
        "    'Sensitivity Ims No Patches Random Inpainting (Retrained Classifier)': se_np_in_v2\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ed0rEdWXJDY"
      },
      "source": [
        "results_file = os.path.join(dir_path, 'models', 'experiment_results_' + datetime.now().strftime('%Y%m%d%H%M%S') + '.txt')\n",
        "with open(results_file, 'w') as file:\n",
        "    for k,v in results_scores.items():\n",
        "      file.write(k + \":\" + str(v) + \"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b6fGcVRIOM6"
      },
      "source": [
        "## Compare models' performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhY8lkDtIUEF"
      },
      "source": [
        "### Compare AUC, F1 and overall Sensitivity/Specificity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSrOiaylIczt"
      },
      "source": [
        "print(\"# of test ims: {}\\n # no_patch ims: {}\".format(\n",
        "    len(test_dataset), sum(no_patch_ind)))\n",
        "\n",
        "print(\"Vanilla model:\")\n",
        "\n",
        "print(\"Calculating AUC and F1 for the full test dataset\")\n",
        "auc = roc_auc_score(targets_test_unaltered, preds_test_unaltered)\n",
        "f1_res = f1(targets_test_unaltered, preds_test_unaltered)\n",
        "print(\"AUC: \", auc)\n",
        "print(\"F1: \", f1_res)\n",
        "print(\"Se: \", recall_score(targets_test_unaltered, preds_test_unaltered > prob_threshold))\n",
        "print(\"Sp: \", recall_score(targets_test_unaltered, preds_test_unaltered > prob_threshold, pos_label=0))\n",
        "\n",
        "print(\"Calculating AUC and F1 for the test dataset excluding images with patches:\")\n",
        "auc = roc_auc_score(targets_test_unaltered[no_patch_ind], preds_test_unaltered[no_patch_ind])\n",
        "f1_res = f1(targets_test_unaltered[no_patch_ind], preds_test_unaltered[no_patch_ind])\n",
        "print(\"AUC: \", auc)\n",
        "print(\"F1: \", f1_res)\n",
        "\n",
        "print(\"Retrained model:\")\n",
        "\n",
        "print(\"Calculating AUC and F1 for the full test dataset\")\n",
        "auc = roc_auc_score(targets_test_unaltered, preds_test_unaltered_v2)\n",
        "f1_res = f1(targets_test_unaltered, preds_test_unaltered_v2)\n",
        "print(\"AUC: \", auc)\n",
        "print(\"F1: \", f1_res)\n",
        "print(\"Se: \", recall_score(targets_test_unaltered, preds_test_unaltered_v2 > prob_threshold))\n",
        "print(\"Sp: \", recall_score(targets_test_unaltered, preds_test_unaltered_v2 > prob_threshold, pos_label=0))\n",
        "\n",
        "print(\"Calculating AUC and F1 for the test dataset excluding images with patches:\")\n",
        "auc = roc_auc_score(targets_test_unaltered[no_patch_ind], preds_test_unaltered_v2[no_patch_ind])\n",
        "f1_res = f1(targets_test_unaltered[no_patch_ind], preds_test_unaltered_v2[no_patch_ind])\n",
        "print(\"AUC: \", auc)\n",
        "print(\"F1: \", f1_res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGACOab6BXmi"
      },
      "source": [
        "## Plot results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWf3hhnSsvlc"
      },
      "source": [
        " ### Load from file if predictions have already been saved."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snghiXTndRj0"
      },
      "source": [
        "targets_test_unaltered, preds_test_unaltered  = np.load(oj(data_path, 'saved-tensors', 'preds_test_unaltered.npz')).values()\n",
        "_, preds_inpainted_patches =    np.load(oj(data_path, 'saved-tensors', 'preds_inpainted_patches.npz')).values()\n",
        "_, preds_inpainted_no_patches = np.load(oj(data_path, 'saved-tensors', 'preds_inpainted_no_patches.npz')).values()\n",
        "_, preds_malignant_patches = np.load(oj(data_path, 'saved-tensors', 'preds_malignant_patches.npz')).values()\n",
        "\n",
        "# Load the output predictions from the classifier retrained on inpainted examples.\n",
        "_, preds_test_unaltered_v2  = np.load(oj(data_path, 'saved-tensors', 'preds_test_unaltered_v2.npz')).values()\n",
        "_, preds_inpainted_patches_v2 =    np.load(oj(data_path, 'saved-tensors', 'preds_inpainted_patches_v2.npz')).values()\n",
        "_, preds_inpainted_no_patches_v2 = np.load(oj(data_path, 'saved-tensors', 'preds_inpainted_no_patches_v2.npz')).values()\n",
        "_, preds_malignant_patches_v2 = np.load(oj(data_path, 'saved-tensors', 'preds_malignant_patches_v2.npz')).values()\n",
        "\n",
        "patch_files,_,_ = extract_filenames(test_path_patches)\n",
        "no_patch_files,_,_ = extract_filenames(test_path_no_patches)\n",
        "test_files,_,_ = extract_filenames(test_path)\n",
        "malignant_patch_files,_,_ = extract_filenames(path_malignant_patches)\n",
        "malignant_patch_files = [f + '.jpg' for f in \n",
        "                         np.unique([fname[:12] for fname in malignant_patch_files])]\n",
        "\n",
        "patch_ind = [file in patch_files for file in test_files]   # Get a boolean list of whether the test file has a patch.\n",
        "no_patch_ind = [file in no_patch_files for file in test_files]\n",
        "# Get a list indices for the relevant malignant files.\n",
        "mal_idx = [i for f1 in malignant_patch_files  \n",
        "              for i,f2 in enumerate(test_files) \n",
        "                if f1 == f2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCBUYUo4MSqu"
      },
      "source": [
        "### Plot & Save Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Klec5aLdfwp"
      },
      "source": [
        "# plot_compare_probs(preds_test_unaltered[no_patch_ind], preds_inpainted_no_patches,\n",
        "#                    preds_test_unaltered_v2[no_patch_ind], preds_inpainted_no_patches_v2,\n",
        "#                    output_add='(inpainted no patches)')\n",
        "\n",
        "# plot_compare_probs(preds_test_unaltered[patch_ind], preds_inpainted_patches, \n",
        "#                    preds_test_unaltered_v2[patch_ind], preds_inpainted_patches_v2, \n",
        "#                    output_add='(inpainted patches)')\n",
        "\n",
        "# plot_compare_probs(preds_test_unaltered[mal_idx], preds_malignant_patches, \n",
        "#                    preds_test_unaltered_v2[mal_idx], preds_malignant_patches_v2, \n",
        "#                    output_add='(malignant patches)')\n",
        "\n",
        "# plot_compare_probs(preds_test_unaltered[mal_idx], preds_malignant_inpainted, \n",
        "#                    preds_test_unaltered_v2[mal_idx], preds_malignant_inpainted_v2, \n",
        "#                    output_add='(malignant inpainted)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwIJaD8fMPBC"
      },
      "source": [
        "### Supplementary Plots for Malignant Experiment\n",
        "Compare to probabilities when we insert a coloured patch into a malignant image vs. if we inpaint the same region."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UQJTcSfG-_R"
      },
      "source": [
        "# ## Plot Histogram Comparison\n",
        "# fig, ax = plt.subplots(3, 2, figsize=(4.5,3.39), sharey=True)\n",
        "\n",
        "# ax[0,0].hist(preds_test_unaltered[mal_idx], range=(0,1), bins=10)\n",
        "# ax[0,0].set_title('\\\\textbf{Vanilla Classifier}\\nOriginal Images')\n",
        "# ax[1,0].hist(preds_malignant_patches, range=(0,1), bins=10)\n",
        "# ax[1,0].set_title('Patches Inserted')\n",
        "# ax[2,0].hist(preds_malignant_inpainted, range=(0,1), bins=10)\n",
        "# ax[2,0].set_title('Inpainted Same Area')\n",
        "# ax[2,0].set_xlabel('Predicted Probability')\n",
        "\n",
        "# ax[0,1].hist(preds_test_unaltered_v2[mal_idx], range=(0,1), bins=10)\n",
        "# ax[0,1].set_title('\\\\textbf{Retrained Classifier}\\nOriginal Images')\n",
        "# ax[1,1].hist(preds_malignant_patches_v2, range=(0,1), bins=10)\n",
        "# ax[1,1].set_title('Patches Inserted')\n",
        "# ax[2,1].hist(preds_malignant_inpainted_v2, range=(0,1), bins=10)\n",
        "# ax[2,1].set_title('Inpainted Same Area')\n",
        "# ax[2,1].set_xlabel('Predicted Probability')\n",
        "\n",
        "# fig.text(0.0, 0.5, 'Number of Samples', va='center', rotation='vertical')\n",
        "\n",
        "# fig.tight_layout()\n",
        "\n",
        "# fig.savefig(oj(dir_path, 'plots', 'report', 'Probs Comparison Hist (Malignant x 2).png'), dpi=1200)\n",
        "# plt.show()\n",
        "\n",
        "# ## Calculate differences and plot histogram\n",
        "# diff_preds_p = preds_malignant_patches - preds_test_unaltered[mal_idx]\n",
        "# diff_preds_p_v2 = preds_malignant_patches_v2 - preds_test_unaltered_v2[mal_idx]\n",
        "# diff_preds_in = preds_malignant_inpainted - preds_test_unaltered[mal_idx]\n",
        "# diff_preds_in_v2 = preds_malignant_inpainted_v2 - preds_test_unaltered_v2[mal_idx]\n",
        "\n",
        "# fig, ax = plt.subplots(2, 2, figsize=(3.39,3.39), sharey=True)\n",
        "\n",
        "# max_diff = max(max(abs(diff_preds_p)), max(abs(diff_preds_p_v2)),\n",
        "#                max(abs(diff_preds_in)), max(abs(diff_preds_in_v2)))\n",
        "\n",
        "# hist_range = (-max_diff, max_diff)  # Make sure histogram is symmetric about zero.\n",
        "\n",
        "# ax[0,0].hist(diff_preds_p, range = hist_range, bins = int(np.ceil((hist_range[1]-hist_range[0])/0.05)))\n",
        "# ax[0,0].set_title('\\\\textbf{Vanilla Classifier}\\nPatches Inserted')\n",
        "\n",
        "# ax[0,1].hist(diff_preds_p_v2, range = hist_range, bins = int(np.ceil((hist_range[1]-hist_range[0])/0.05)))\n",
        "# ax[0,1].set_title('\\\\textbf{Retrained Classifier}\\nPatches Inserted')\n",
        "\n",
        "# ax[1,0].hist(diff_preds_in, range = hist_range, bins = int(np.ceil((hist_range[1]-hist_range[0])/0.05)))\n",
        "# ax[1,0].set_title('Inpainted Same Area')\n",
        "\n",
        "# ax[1,1].hist(diff_preds_in_v2, range = hist_range, bins = int(np.ceil((hist_range[1]-hist_range[0])/0.05)))\n",
        "# ax[1,1].set_title('Inpainted Same Area')\n",
        "\n",
        "# # Insert shared x and y labels as fixed text.\n",
        "# fig.text(0.3, 0.0, 'Difference in Predicted Probability', va='bottom', rotation='horizontal')\n",
        "# fig.text(0.0, 0.5, 'Number of Samples', va='center', rotation='vertical')\n",
        "\n",
        "# fig.tight_layout()\n",
        "# fig.savefig(oj(dir_path, 'plots', 'report', 'Diff in Predicted Probs Hist (Malignant x 2).png'), dpi=1200)\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_HwE44XrfMf"
      },
      "source": [
        "## Fidelity between classifier predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQY8pR6ysNcL"
      },
      "source": [
        "plt.figure(figsize=(3.2,3.2))\n",
        "\n",
        "# c = ['tab:blue' if ind else 'tab:orange' if i in mal_idx else 'tab:grey'\n",
        "#       for i,ind in enumerate(patch_ind)]\n",
        "\n",
        "plt.scatter(preds_test_unaltered[patch_ind], preds_test_unaltered_v2[patch_ind], \n",
        "            alpha = 0.3, color='tab:blue', s=20, label = 'Benign (Patch)')\n",
        "\n",
        "plt.scatter([pred for i,pred in enumerate(preds_test_unaltered) if (no_patch_ind[i]) & (i not in mal_idx)], \n",
        "            [pred for i,pred in enumerate(preds_test_unaltered_v2) if (no_patch_ind[i]) & (i not in mal_idx)], \n",
        "            alpha = 0.3, color='tab:grey', s=20, label = 'Benign (No Patch)')\n",
        "\n",
        "plt.scatter(preds_test_unaltered[mal_idx], preds_test_unaltered_v2[mal_idx], \n",
        "            alpha = 0.3, color='darkred', s=20, label = 'Malignant')\n",
        "\n",
        "# plt.scatter(preds_test_unaltered, preds_test_unaltered_v2, alpha=0.3, c=c, s=15)\n",
        "plt.xlabel('Probability from Vanilla Classifier')\n",
        "plt.ylabel('Probability from Retrained Classifier')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.savefig(oj(dir_path, 'plots', 'report', 'scatter_classifiers.png'), dpi=1200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMeatKxe0Gps"
      },
      "source": [
        "print(pearsonr(preds_test_unaltered, preds_test_unaltered_v2)[0])\n",
        "print(pearsonr(preds_test_unaltered[patch_ind], preds_test_unaltered_v2[patch_ind])[0])\n",
        "print(pearsonr(preds_test_unaltered[mal_idx], preds_test_unaltered_v2[mal_idx])[0])\n",
        "print(pearsonr([pred for i,pred in enumerate(preds_test_unaltered) if (no_patch_ind[i]) & (i not in mal_idx)], \n",
        "            [pred for i,pred in enumerate(preds_test_unaltered_v2) if (no_patch_ind[i]) & (i not in mal_idx)])[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-5gYHClGrWl"
      },
      "source": [
        "## Examine Outliers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "px1SH_THDbLp"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_patches = pd.DataFrame({\n",
        "    'filename': [file for i,file in enumerate(test_files) if patch_ind[i]], \n",
        "    'Ground Truth': targets_test_unaltered[patch_ind],\n",
        "    'Prob Original': preds_test_unaltered[patch_ind], \n",
        "    'Prob Inpainted': preds_inpainted_patches\n",
        "    })\n",
        "\n",
        "df_patches['Diff Prob'] = df_patches['Prob Inpainted'] - df_patches['Prob Original']\n",
        "\n",
        "df_no_patches = pd.DataFrame({\n",
        "    'filename': [file for i,file in enumerate(test_files) if no_patch_ind[i]], \n",
        "    'Ground Truth': targets_test_unaltered[no_patch_ind],   \n",
        "    'Prob Original': preds_test_unaltered[no_patch_ind], \n",
        "    'Prob Inpainted': preds_inpainted_no_patches\n",
        "    })\n",
        "\n",
        "df_no_patches['Diff Prob'] = df_no_patches['Prob Inpainted'] - df_no_patches['Prob Original']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cr14be_cEoQB"
      },
      "source": [
        "plt.style.use('default')\n",
        "\n",
        "bottom_10_no_patch = df_no_patches.sort_values('Diff Prob').head(20)\n",
        "for i in range(20):\n",
        "    rec = bottom_10_no_patch.iloc[i]\n",
        "    print(rec)\n",
        "    img = Image.open(oj(path_no_patches_combined, rec['filename']), 'r')\n",
        "    plt.imshow(np.asarray(img))\n",
        "    plt.tick_params(axis='both',which='both',left=False,right=False,bottom=False,\n",
        "                    top=False,labelbottom=False,labelleft=False)\n",
        "    plt.show()\n",
        "    img.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8jmBi2SQQYY"
      },
      "source": [
        "top_10_patch = df_patches.sort_values('Diff Prob',ascending=False).head(10)\n",
        "for i in range(10):\n",
        "    rec = top_10_patch.iloc[i]\n",
        "    print(rec)\n",
        "    img = Image.open(oj(path_patches_combined, rec['filename']), 'r')\n",
        "    plt.imshow(np.asarray(img))\n",
        "    plt.tick_params(axis='both',which='both',left=False,right=False,bottom=False,\n",
        "                    top=False,labelbottom=False,labelleft=False)\n",
        "    plt.show()\n",
        "    img.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}