{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inpainting_gmcnn_test.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "VnJJVZgId1i-",
        "N9WYeyeIdwpm",
        "osjh1RhJdgEB",
        "l1xRsO-Sdp-Q",
        "qFtzcxARyjvF",
        "jKEOrKK4c9d8",
        "28hpLAavcrZS",
        "UTzCZil4W3S4"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adubowski/redi-xai/blob/main/inpainting/inpainting_gmcnn_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWmt9jzeSRar"
      },
      "source": [
        "# Inpaint Various Datasets using a Trained Inpainted Model\n",
        "Most code here is taken directly from https://github.com/shepnerd/inpainting_gmcnn/tree/master/pytorch with minor adjustments and refactoring into a Jupyter notebook, including a convenient way of providing arguments for test_options.\n",
        "\n",
        "The code cell under \"Create elliptical masks\" is original code, and significant adjustments have been made to the original code from \"test.py\" onwards.\n",
        "\n",
        "Otherwise, the cell titles refer to the module at the above Github link that the code was originally taken from.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg7LOqvwKMfU"
      },
      "source": [
        "### Load libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pc_ksR-CePBI"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "## model.basemodel\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "## model.basenet\n",
        "# import os\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "\n",
        "## model.layer\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "# from util.utils import gauss_kernel\n",
        "import torchvision.models as models\n",
        "import numpy as np\n",
        "\n",
        "## model.loss\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "import torch.autograd as autograd\n",
        "import torch.nn.functional as F\n",
        "# from model.layer import VGG19FeatLayer\n",
        "from functools import reduce\n",
        "\n",
        "## model.net\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "# from model.basemodel import BaseModel\n",
        "# from model.basenet import BaseNet\n",
        "# from model.loss import WGANLoss, IDMRFLoss\n",
        "# from model.layer import init_weights, PureUpsampling, ConfidenceDrivenMaskLayer, SpectralNorm\n",
        "# import numpy as np\n",
        "\n",
        "\n",
        "## options.test_options\n",
        "import argparse\n",
        "# import os\n",
        "import time\n",
        "\n",
        "## original code for ellipse masks\n",
        "import cv2\n",
        "# import numpy as np\n",
        "from numpy import random\n",
        "from numpy.random import randint\n",
        "# from matplotlib import pyplot as plt\n",
        "import math\n",
        "\n",
        "## utils.utils\n",
        "# import numpy as np\n",
        "import scipy.stats as st\n",
        "# import cv2\n",
        "# import time\n",
        "# import os\n",
        "import glob\n",
        "\n",
        "## Dependencies from test.py\n",
        "# import numpy as np\n",
        "# import cv2\n",
        "# import os\n",
        "import subprocess\n",
        "# import glob\n",
        "# from options.test_options import TestOptions\n",
        "# from model.net import InpaintingModel_GMCNN\n",
        "# from util.utils import generate_rect_mask, generate_stroke_mask, getLatest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKVkNFK8pnKQ"
      },
      "source": [
        "drive.mount(\"/content/drive\")\n",
        "dir_path = \"/content/drive/MyDrive/redi-detecting-cheating\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnJJVZgId1i-"
      },
      "source": [
        "### model.basemodel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7epNMH1d5AV"
      },
      "source": [
        "# a complex model consisted of several nets, and each net will be explicitly defined in other py classes\n",
        "class BaseModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BaseModel,self).__init__()\n",
        "\n",
        "    def init(self, opt):\n",
        "        self.opt = opt\n",
        "        self.gpu_ids = opt.gpu_ids\n",
        "        self.save_dir = opt.model_folder\n",
        "        self.device = torch.device('cuda:{}'.format(self.gpu_ids[0])) if self.gpu_ids else torch.device('cpu')\n",
        "        self.model_names = []\n",
        "\n",
        "    def setInput(self, inputData):\n",
        "        self.input = inputData\n",
        "\n",
        "    def forward(self):\n",
        "        pass\n",
        "\n",
        "    def optimize_parameters(self):\n",
        "        pass\n",
        "\n",
        "    def get_current_visuals(self):\n",
        "        pass\n",
        "\n",
        "    def get_current_losses(self):\n",
        "        pass\n",
        "\n",
        "    def update_learning_rate(self):\n",
        "        pass\n",
        "\n",
        "    def test(self):\n",
        "        with torch.no_grad():\n",
        "            self.forward()\n",
        "\n",
        "    # save models to the disk\n",
        "    def save_networks(self, which_epoch):\n",
        "        for name in self.model_names:\n",
        "            if isinstance(name, str):\n",
        "                save_filename = '%s_net_%s.pth' % (which_epoch, name)\n",
        "                save_path = os.path.join(self.save_dir, save_filename)\n",
        "                net = getattr(self, 'net' + name)\n",
        "\n",
        "                if len(self.gpu_ids) > 0 and torch.cuda.is_available():\n",
        "                    torch.save(net.state_dict(), save_path)\n",
        "                    # net.cuda(self.gpu_ids[0])\n",
        "                else:\n",
        "                    torch.save(net.state_dict(), save_path)\n",
        "\n",
        "    def __patch_instance_norm_state_dict(self, state_dict, module, keys, i=0):\n",
        "        key = keys[i]\n",
        "        if i + 1 == len(keys):  # at the end, pointing to a parameter/buffer\n",
        "            if module.__class__.__name__.startswith('InstanceNorm') and \\\n",
        "                    (key == 'running_mean' or key == 'running_var'):\n",
        "                if getattr(module, key) is None:\n",
        "                    state_dict.pop('.'.join(keys))\n",
        "        else:\n",
        "            self.__patch_instance_norm_state_dict(state_dict, getattr(module, key), keys, i + 1)\n",
        "\n",
        "    # load models from the disk\n",
        "    def load_networks(self, load_path):\n",
        "        for name in self.model_names:\n",
        "            if isinstance(name, str):\n",
        "                net = getattr(self, 'net' + name)\n",
        "                if isinstance(net, torch.nn.DataParallel):\n",
        "                    net = net.module\n",
        "                print('loading the model from %s' % load_path)\n",
        "                # if you are using PyTorch newer than 0.4 (e.g., built from\n",
        "                # GitHub source), you can remove str() on self.device\n",
        "                state_dict = torch.load(load_path)\n",
        "                # patch InstanceNorm checkpoints prior to 0.4\n",
        "                for key in list(state_dict.keys()):  # need to copy keys here because we mutate in loop\n",
        "                    self.__patch_instance_norm_state_dict(state_dict, net, key.split('.'))\n",
        "                net.load_state_dict(state_dict)\n",
        "\n",
        "    # print network information\n",
        "    def print_networks(self, verbose=True):\n",
        "        print('---------- Networks initialized -------------')\n",
        "        for name in self.model_names:\n",
        "            if isinstance(name, str):\n",
        "                net = getattr(self, 'net' + name)\n",
        "                num_params = 0\n",
        "                for param in net.parameters():\n",
        "                    num_params += param.numel()\n",
        "                if verbose:\n",
        "                    print(net)\n",
        "                print('[Network %s] Total number of parameters : %.3f M' % (name, num_params / 1e6))\n",
        "        print('-----------------------------------------------')\n",
        "\n",
        "    # set requies_grad=Fasle to avoid computation\n",
        "    def set_requires_grad(self, nets, requires_grad=False):\n",
        "        if not isinstance(nets, list):\n",
        "            nets = [nets]\n",
        "        for net in nets:\n",
        "            if net is not None:\n",
        "                for param in net.parameters():\n",
        "                    param.requires_grad = requires_grad\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9WYeyeIdwpm"
      },
      "source": [
        "### model.basenet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBJg57_tdy4I"
      },
      "source": [
        "class BaseNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BaseNet, self).__init__()\n",
        "\n",
        "    def init(self, opt):\n",
        "        self.opt = opt\n",
        "        self.gpu_ids = opt.gpu_ids\n",
        "        self.save_dir = opt.checkpoint_dir\n",
        "        self.device = torch.device('cuda:{}'.format(self.gpu_ids[0])) if self.gpu_ids else torch.device('cpu')\n",
        "\n",
        "    def forward(self, *input):\n",
        "        return super(BaseNet, self).forward(*input)\n",
        "\n",
        "    def test(self, *input):\n",
        "        with torch.no_grad():\n",
        "            self.forward(*input)\n",
        "\n",
        "    def save_network(self, network_label, epoch_label):\n",
        "        save_filename = '%s_net_%s.pth' % (epoch_label, network_label)\n",
        "        save_path = os.path.join(self.save_dir, save_filename)\n",
        "        torch.save(self.cpu().state_dict(), save_path)\n",
        "\n",
        "    def load_network(self, network_label, epoch_label):\n",
        "        save_filename = '%s_net_%s.pth' % (epoch_label, network_label)\n",
        "        save_path = os.path.join(self.save_dir, save_filename)\n",
        "        if not os.path.isfile(save_path):\n",
        "            print('%s not exists yet!' % save_path)\n",
        "        else:\n",
        "            try:\n",
        "                self.load_state_dict(torch.load(save_path))\n",
        "            except:\n",
        "                pretrained_dict = torch.load(save_path)\n",
        "                model_dict = self.state_dict()\n",
        "                try:\n",
        "                    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
        "                    self.load_state_dict(pretrained_dict)\n",
        "                    print('Pretrained network %s has excessive layers; Only loading layers that are used' % network_label)\n",
        "                except:\n",
        "                    print('Pretrained network %s has fewer layers; The following are not initialized: ' % network_label)\n",
        "                    for k, v in pretrained_dict.items():\n",
        "                        if v.size() == model_dict[k].size():\n",
        "                            model_dict[k] = v\n",
        "\n",
        "                    for k, v in model_dict.items():\n",
        "                        if k not in pretrained_dict or v.size() != pretrained_dict[k].size():\n",
        "                            print(k.split('.')[0])\n",
        "                    self.load_state_dict(model_dict)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osjh1RhJdgEB"
      },
      "source": [
        "### model.layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJPbQ3hNdcuj"
      },
      "source": [
        "class Conv2d_BN(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True):\n",
        "        super(Conv2d_BN, self).__init__()\n",
        "        self.model = nn.Sequential([\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias),\n",
        "            nn.BatchNorm2d(out_channels)\n",
        "        ])\n",
        "\n",
        "    def forward(self, *input):\n",
        "        return self.model(*input)\n",
        "\n",
        "\n",
        "class upsampling(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, scale=2):\n",
        "        super(upsampling, self).__init__()\n",
        "        assert isinstance(scale, int)\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding,\n",
        "                     dilation=dilation, groups=groups, bias=bias)\n",
        "        self.scale = scale\n",
        "\n",
        "    def forward(self, x):\n",
        "        h, w = x.size(2) * self.scale, x.size(3) * self.scale\n",
        "        xout = self.conv(F.interpolate(input=x, size=(h, w), mode='nearest', align_corners=True))\n",
        "        return xout\n",
        "\n",
        "\n",
        "class PureUpsampling(nn.Module):\n",
        "    def __init__(self, scale=2, mode='bilinear'):\n",
        "        super(PureUpsampling, self).__init__()\n",
        "        assert isinstance(scale, int)\n",
        "        self.scale = scale\n",
        "        self.mode = mode\n",
        "\n",
        "    def forward(self, x):\n",
        "        h, w = x.size(2) * self.scale, x.size(3) * self.scale\n",
        "        if self.mode == 'nearest':\n",
        "            xout = F.interpolate(input=x, size=(h, w), mode=self.mode)\n",
        "        else:\n",
        "            xout = F.interpolate(input=x, size=(h, w), mode=self.mode, align_corners=True)\n",
        "        return xout\n",
        "\n",
        "\n",
        "class GaussianBlurLayer(nn.Module):\n",
        "    def __init__(self, size, sigma, in_channels=1, stride=1, pad=1):\n",
        "        super(GaussianBlurLayer, self).__init__()\n",
        "        self.size = size\n",
        "        self.sigma = sigma\n",
        "        self.ch = in_channels\n",
        "        self.stride = stride\n",
        "        self.pad = nn.ReflectionPad2d(pad)\n",
        "\n",
        "    def forward(self, x):\n",
        "        kernel = gauss_kernel(self.size, self.sigma, self.ch, self.ch)\n",
        "        kernel_tensor = torch.from_numpy(kernel)\n",
        "        kernel_tensor = kernel_tensor.cuda()\n",
        "        x = self.pad(x)\n",
        "        blurred = F.conv2d(x, kernel_tensor, stride=self.stride)\n",
        "        return blurred\n",
        "\n",
        "\n",
        "class ConfidenceDrivenMaskLayer(nn.Module):\n",
        "    def __init__(self, size=65, sigma=1.0/40, iters=7):\n",
        "        super(ConfidenceDrivenMaskLayer, self).__init__()\n",
        "        self.size = size\n",
        "        self.sigma = sigma\n",
        "        self.iters = iters\n",
        "        self.propagationLayer = GaussianBlurLayer(size, sigma, pad=32)\n",
        "\n",
        "    def forward(self, mask):\n",
        "        # here mask 1 indicates missing pixels and 0 indicates the valid pixels\n",
        "        init = 1 - mask\n",
        "        mask_confidence = None\n",
        "        for i in range(self.iters):\n",
        "            mask_confidence = self.propagationLayer(init)\n",
        "            mask_confidence = mask_confidence * mask\n",
        "            init = mask_confidence + (1 - mask)\n",
        "        return mask_confidence\n",
        "\n",
        "\n",
        "class VGG19(nn.Module):\n",
        "    def __init__(self, pool='max'):\n",
        "        super(VGG19, self).__init__()\n",
        "        self.conv1_1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
        "        self.conv1_2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        self.conv2_1 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        self.conv3_3 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        self.conv3_4 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
        "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.conv4_3 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.conv4_4 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.conv5_1 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.conv5_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.conv5_3 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.conv5_4 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        if pool == 'max':\n",
        "            self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "            self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "            self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "            self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "            self.pool5 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        elif pool == 'avg':\n",
        "            self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "            self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "            self.pool3 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "            self.pool4 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "            self.pool5 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = {}\n",
        "        out['r11'] = F.relu(self.conv1_1(x))\n",
        "        out['r12'] = F.relu(self.conv1_2(out['r11']))\n",
        "        out['p1'] = self.pool1(out['r12'])\n",
        "        out['r21'] = F.relu(self.conv2_1(out['p1']))\n",
        "        out['r22'] = F.relu(self.conv2_2(out['r21']))\n",
        "        out['p2'] = self.pool2(out['r22'])\n",
        "        out['r31'] = F.relu(self.conv3_1(out['p2']))\n",
        "        out['r32'] = F.relu(self.conv3_2(out['r31']))\n",
        "        out['r33'] = F.relu(self.conv3_3(out['r32']))\n",
        "        out['r34'] = F.relu(self.conv3_4(out['r33']))\n",
        "        out['p3'] = self.pool3(out['r34'])\n",
        "        out['r41'] = F.relu(self.conv4_1(out['p3']))\n",
        "        out['r42'] = F.relu(self.conv4_2(out['r41']))\n",
        "        out['r43'] = F.relu(self.conv4_3(out['r42']))\n",
        "        out['r44'] = F.relu(self.conv4_4(out['r43']))\n",
        "        out['p4'] = self.pool4(out['r44'])\n",
        "        out['r51'] = F.relu(self.conv5_1(out['p4']))\n",
        "        out['r52'] = F.relu(self.conv5_2(out['r51']))\n",
        "        out['r53'] = F.relu(self.conv5_3(out['r52']))\n",
        "        out['r54'] = F.relu(self.conv5_4(out['r53']))\n",
        "        out['p5'] = self.pool5(out['r54'])\n",
        "        return out\n",
        "\n",
        "\n",
        "class VGG19FeatLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VGG19FeatLayer, self).__init__()\n",
        "        self.vgg19 = models.vgg19(pretrained=True).features.eval().cuda()\n",
        "        self.mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1).cuda()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = {}\n",
        "        x = x - self.mean\n",
        "        ci = 1\n",
        "        ri = 0\n",
        "        for layer in self.vgg19.children():\n",
        "            if isinstance(layer, nn.Conv2d):\n",
        "                ri += 1\n",
        "                name = 'conv{}_{}'.format(ci, ri)\n",
        "            elif isinstance(layer, nn.ReLU):\n",
        "                ri += 1\n",
        "                name = 'relu{}_{}'.format(ci, ri)\n",
        "                layer = nn.ReLU(inplace=False)\n",
        "            elif isinstance(layer, nn.MaxPool2d):\n",
        "                ri = 0\n",
        "                name = 'pool_{}'.format(ci)\n",
        "                ci += 1\n",
        "            elif isinstance(layer, nn.BatchNorm2d):\n",
        "                name = 'bn_{}'.format(ci)\n",
        "            else:\n",
        "                raise RuntimeError('Unrecognized layer: {}'.format(layer.__class__.__name__))\n",
        "            x = layer(x)\n",
        "            out[name] = x\n",
        "        # print([x for x in out])\n",
        "        return out\n",
        "\n",
        "\n",
        "def init_weights(net, init_type='normal', gain=0.02):\n",
        "    def init_func(m):\n",
        "        classname = m.__class__.__name__\n",
        "        if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
        "            if init_type == 'normal':\n",
        "                nn.init.normal_(m.weight.data, 0.0, gain)\n",
        "            elif init_type == 'xavier':\n",
        "                nn.init.xavier_normal_(m.weight.data, gain=gain)\n",
        "            elif init_type == 'kaiming':\n",
        "                nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
        "            elif init_type == 'orthogonal':\n",
        "                nn.init.orthogonal_(m.weight.data, gain=gain)\n",
        "            else:\n",
        "                raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n",
        "            if hasattr(m, 'bias') and m.bias is not None:\n",
        "                nn.init.constant_(m.bias.data, 0.0)\n",
        "        elif classname.find('BatchNorm2d') != -1:\n",
        "            nn.init.normal_(m.weight.data, 1.0, gain)\n",
        "            nn.init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "    print('initialize network with %s' % init_type)\n",
        "    net.apply(init_func)\n",
        "\n",
        "\n",
        "def init_net(net, init_type='normal', gpu_ids=[]):\n",
        "    if len(gpu_ids) > 0:\n",
        "        assert(torch.cuda.is_available())\n",
        "        net.to(gpu_ids[0])\n",
        "        net = torch.nn.DataParallel(net, gpu_ids)\n",
        "    init_weights(net, init_type)\n",
        "    return net\n",
        "\n",
        "\n",
        "def l2normalize(v, eps=1e-12):\n",
        "    return v / (v.norm()+eps)\n",
        "\n",
        "\n",
        "class SpectralNorm(nn.Module):\n",
        "    def __init__(self, module, name='weight', power_iteration=1):\n",
        "        super(SpectralNorm, self).__init__()\n",
        "        self.module = module\n",
        "        self.name = name\n",
        "        self.power_iteration = power_iteration\n",
        "        if not self._made_params():\n",
        "            self._make_params()\n",
        "\n",
        "    def _update_u_v(self):\n",
        "        u = getattr(self.module, self.name + '_u')\n",
        "        v = getattr(self.module, self.name + '_v')\n",
        "        w = getattr(self.module, self.name + '_bar')\n",
        "\n",
        "        height = w.data.shape[0]\n",
        "        for _ in range(self.power_iteration):\n",
        "            v.data = l2normalize(torch.mv(torch.t(w.view(height, -1).data), u.data))\n",
        "            u.data = l2normalize(torch.mv(w.view(height, -1).data, v.data))\n",
        "\n",
        "        sigma = u.dot(w.view(height, -1).mv(v))\n",
        "        setattr(self.module, self.name, w / sigma.expand_as(w))\n",
        "\n",
        "    def _made_params(self):\n",
        "        try:\n",
        "            u = getattr(self.module, self.name + '_u')\n",
        "            v = getattr(self.module, self.name + '_v')\n",
        "            w = getattr(self.module, self.name + '_bar')\n",
        "            return True\n",
        "        except AttributeError:\n",
        "            return False\n",
        "\n",
        "    def _make_params(self):\n",
        "        w = getattr(self.module, self.name)\n",
        "\n",
        "        height = w.data.shape[0]\n",
        "        width = w.view(height, -1).data.shape[1]\n",
        "\n",
        "        u = nn.Parameter(w.data.new(height).normal_(0, 1), requires_grad=False)\n",
        "        v = nn.Parameter(w.data.new(width).normal_(0, 1), requires_grad=False)\n",
        "        u.data = l2normalize(u.data)\n",
        "        v.data = l2normalize(v.data)\n",
        "        w_bar = nn.Parameter(w.data)\n",
        "\n",
        "        del self.module._parameters[self.name]\n",
        "\n",
        "        self.module.register_parameter(self.name+'_u', u)\n",
        "        self.module.register_parameter(self.name+'_v', v)\n",
        "        self.module.register_parameter(self.name+'_bar', w_bar)\n",
        "\n",
        "    def forward(self, *input):\n",
        "        self._update_u_v()\n",
        "        return self.module.forward(*input)\n",
        "\n",
        "\n",
        "class PartialConv(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=32, ksize=3, stride=1):\n",
        "        super(PartialConv, self).__init__()\n",
        "        self.ksize = ksize\n",
        "        self.stride = stride\n",
        "        self.fnum = 32\n",
        "        self.padSize = self.ksize // 2\n",
        "        self.pad = nn.ReflectionPad2d(self.padSize)\n",
        "        self.eplison = 1e-5\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, stride=stride, kernel_size=ksize)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "\n",
        "        mask_ch = mask.size(1)\n",
        "        sum_kernel_np = np.ones((mask_ch, mask_ch, self.ksize, self.ksize), dtype=np.float32)\n",
        "        sum_kernel = torch.from_numpy(sum_kernel_np).cuda()\n",
        "\n",
        "        x = x * mask / (F.conv2d(mask, sum_kernel, stride=1, padding=self.padSize)+self.eplison)\n",
        "        x = self.pad(x)\n",
        "        x = self.conv(x)\n",
        "        mask = F.max_pool2d(mask, self.ksize, stride=self.stride, padding=self.padSize)\n",
        "        return x, mask\n",
        "\n",
        "\n",
        "class GatedConv(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=32, ksize=3, stride=1, act=F.elu):\n",
        "        super(GatedConv, self).__init__()\n",
        "        self.ksize = ksize\n",
        "        self.stride = stride\n",
        "        self.act = act\n",
        "        self.padSize = self.ksize // 2\n",
        "        self.pad = nn.ReflectionPad2d(self.padSize)\n",
        "        self.convf = nn.Conv2d(in_channels, out_channels, stride=stride, kernel_size=ksize)\n",
        "        self.convm = nn.Conv2d(in_channels, out_channels, stride=stride, kernel_size=ksize,\n",
        "                               padding=self.padSize)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pad(x)\n",
        "        x = self.convf(x)\n",
        "        x = self.act(x)\n",
        "        m = self.convm(x)\n",
        "        m = F.sigmoid(m)\n",
        "        x = x * m\n",
        "        return x\n",
        "\n",
        "\n",
        "class GatedDilatedConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, ksize=3, stride=1, pad=1, dilation=2, act=F.elu):\n",
        "        super(GatedDilatedConv, self).__init__()\n",
        "        self.ksize = ksize\n",
        "        self.stride = stride\n",
        "        self.act = act\n",
        "        self.padSize = pad\n",
        "        self.pad = nn.ReflectionPad2d(self.padSize)\n",
        "        self.convf = nn.Conv2d(in_channels, out_channels, stride=stride, kernel_size=ksize, dilation=dilation)\n",
        "        self.convm = nn.Conv2d(in_channels, out_channels, stride=stride, kernel_size=ksize, dilation=dilation,\n",
        "                               padding=self.padSize)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pad(x)\n",
        "        x = self.convf(x)\n",
        "        x = self.act(x)\n",
        "        m = self.convm(x)\n",
        "        m = F.sigmoid(m)\n",
        "        x = x * m\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1xRsO-Sdp-Q"
      },
      "source": [
        "### model.loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WH7yAyQgdqxB"
      },
      "source": [
        "class WGANLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(WGANLoss, self).__init__()\n",
        "\n",
        "    def __call__(self, input, target):\n",
        "        d_loss = (input - target).mean()\n",
        "        g_loss = -input.mean()\n",
        "        return {'g_loss': g_loss, 'd_loss': d_loss}\n",
        "\n",
        "\n",
        "def gradient_penalty(xin, yout, mask=None):\n",
        "    gradients = autograd.grad(yout, xin, create_graph=True,\n",
        "                              grad_outputs=torch.ones(yout.size()).cuda(), retain_graph=True, only_inputs=True)[0]\n",
        "    if mask is not None:\n",
        "        gradients = gradients * mask\n",
        "    gradients = gradients.view(gradients.size(0), -1)\n",
        "    gp = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
        "    return gp\n",
        "\n",
        "\n",
        "def random_interpolate(gt, pred):\n",
        "    batch_size = gt.size(0)\n",
        "    alpha = torch.rand(batch_size, 1, 1, 1).cuda()\n",
        "    # alpha = alpha.expand(gt.size()).cuda()\n",
        "    interpolated = gt * alpha + pred * (1 - alpha)\n",
        "    return interpolated\n",
        "\n",
        "\n",
        "class IDMRFLoss(nn.Module):\n",
        "    def __init__(self, featlayer=VGG19FeatLayer):\n",
        "        super(IDMRFLoss, self).__init__()\n",
        "        self.featlayer = featlayer()\n",
        "        self.feat_style_layers = {'relu3_2': 1.0, 'relu4_2': 1.0}\n",
        "        self.feat_content_layers = {'relu4_2': 1.0}\n",
        "        self.bias = 1.0\n",
        "        self.nn_stretch_sigma = 0.5\n",
        "        self.lambda_style = 1.0\n",
        "        self.lambda_content = 1.0\n",
        "\n",
        "    def sum_normalize(self, featmaps):\n",
        "        reduce_sum = torch.sum(featmaps, dim=1, keepdim=True)\n",
        "        return featmaps / reduce_sum\n",
        "\n",
        "    def patch_extraction(self, featmaps):\n",
        "        patch_size = 1\n",
        "        patch_stride = 1\n",
        "        patches_as_depth_vectors = featmaps.unfold(2, patch_size, patch_stride).unfold(3, patch_size, patch_stride)\n",
        "        self.patches_OIHW = patches_as_depth_vectors.permute(0, 2, 3, 1, 4, 5)\n",
        "        dims = self.patches_OIHW.size()\n",
        "        self.patches_OIHW = self.patches_OIHW.view(-1, dims[3], dims[4], dims[5])\n",
        "        return self.patches_OIHW\n",
        "\n",
        "    def compute_relative_distances(self, cdist):\n",
        "        epsilon = 1e-5\n",
        "        div = torch.min(cdist, dim=1, keepdim=True)[0]\n",
        "        relative_dist = cdist / (div + epsilon)\n",
        "        return relative_dist\n",
        "\n",
        "    def exp_norm_relative_dist(self, relative_dist):\n",
        "        scaled_dist = relative_dist\n",
        "        dist_before_norm = torch.exp((self.bias - scaled_dist)/self.nn_stretch_sigma)\n",
        "        self.cs_NCHW = self.sum_normalize(dist_before_norm)\n",
        "        return self.cs_NCHW\n",
        "\n",
        "    def mrf_loss(self, gen, tar):\n",
        "        meanT = torch.mean(tar, 1, keepdim=True)\n",
        "        gen_feats, tar_feats = gen - meanT, tar - meanT\n",
        "\n",
        "        gen_feats_norm = torch.norm(gen_feats, p=2, dim=1, keepdim=True)\n",
        "        tar_feats_norm = torch.norm(tar_feats, p=2, dim=1, keepdim=True)\n",
        "\n",
        "        gen_normalized = gen_feats / gen_feats_norm\n",
        "        tar_normalized = tar_feats / tar_feats_norm\n",
        "\n",
        "        cosine_dist_l = []\n",
        "        BatchSize = tar.size(0)\n",
        "\n",
        "        for i in range(BatchSize):\n",
        "            tar_feat_i = tar_normalized[i:i+1, :, :, :]\n",
        "            gen_feat_i = gen_normalized[i:i+1, :, :, :]\n",
        "            patches_OIHW = self.patch_extraction(tar_feat_i)\n",
        "\n",
        "            cosine_dist_i = F.conv2d(gen_feat_i, patches_OIHW)\n",
        "            cosine_dist_l.append(cosine_dist_i)\n",
        "        cosine_dist = torch.cat(cosine_dist_l, dim=0)\n",
        "        cosine_dist_zero_2_one = - (cosine_dist - 1) / 2\n",
        "        relative_dist = self.compute_relative_distances(cosine_dist_zero_2_one)\n",
        "        rela_dist = self.exp_norm_relative_dist(relative_dist)\n",
        "        dims_div_mrf = rela_dist.size()\n",
        "        k_max_nc = torch.max(rela_dist.view(dims_div_mrf[0], dims_div_mrf[1], -1), dim=2)[0]\n",
        "        div_mrf = torch.mean(k_max_nc, dim=1)\n",
        "        div_mrf_sum = -torch.log(div_mrf)\n",
        "        div_mrf_sum = torch.sum(div_mrf_sum)\n",
        "        return div_mrf_sum\n",
        "\n",
        "    def forward(self, gen, tar):\n",
        "        gen_vgg_feats = self.featlayer(gen)\n",
        "        tar_vgg_feats = self.featlayer(tar)\n",
        "\n",
        "        style_loss_list = [self.feat_style_layers[layer] * self.mrf_loss(gen_vgg_feats[layer], tar_vgg_feats[layer]) for layer in self.feat_style_layers]\n",
        "        self.style_loss = reduce(lambda x, y: x+y, style_loss_list) * self.lambda_style\n",
        "\n",
        "        content_loss_list = [self.feat_content_layers[layer] * self.mrf_loss(gen_vgg_feats[layer], tar_vgg_feats[layer]) for layer in self.feat_content_layers]\n",
        "        self.content_loss = reduce(lambda x, y: x+y, content_loss_list) * self.lambda_content\n",
        "\n",
        "        return self.style_loss + self.content_loss\n",
        "\n",
        "\n",
        "class StyleLoss(nn.Module):\n",
        "    def __init__(self, featlayer=VGG19FeatLayer, style_layers=None):\n",
        "        super(StyleLoss, self).__init__()\n",
        "        self.featlayer = featlayer()\n",
        "        if style_layers is not None:\n",
        "            self.feat_style_layers = style_layers\n",
        "        else:\n",
        "            self.feat_style_layers = {'relu2_2': 1.0, 'relu3_2': 1.0, 'relu4_2': 1.0}\n",
        "\n",
        "    def gram_matrix(self, x):\n",
        "        b, c, h, w = x.size()\n",
        "        feats = x.view(b * c, h * w)\n",
        "        g = torch.mm(feats, feats.t())\n",
        "        return g.div(b * c * h * w)\n",
        "\n",
        "    def _l1loss(self, gen, tar):\n",
        "        return torch.abs(gen-tar).mean()\n",
        "\n",
        "    def forward(self, gen, tar):\n",
        "        gen_vgg_feats = self.featlayer(gen)\n",
        "        tar_vgg_feats = self.featlayer(tar)\n",
        "        style_loss_list = [self.feat_style_layers[layer] * self._l1loss(self.gram_matrix(gen_vgg_feats[layer]), self.gram_matrix(tar_vgg_feats[layer])) for\n",
        "                           layer in self.feat_style_layers]\n",
        "        style_loss = reduce(lambda x, y: x + y, style_loss_list)\n",
        "        return style_loss\n",
        "\n",
        "\n",
        "class ContentLoss(nn.Module):\n",
        "    def __init__(self, featlayer=VGG19FeatLayer, content_layers=None):\n",
        "        super(ContentLoss, self).__init__()\n",
        "        self.featlayer = featlayer()\n",
        "        if content_layers is not None:\n",
        "            self.feat_content_layers = content_layers\n",
        "        else:\n",
        "            self.feat_content_layers = {'relu4_2': 1.0}\n",
        "\n",
        "    def _l1loss(self, gen, tar):\n",
        "        return torch.abs(gen-tar).mean()\n",
        "\n",
        "    def forward(self, gen, tar):\n",
        "        gen_vgg_feats = self.featlayer(gen)\n",
        "        tar_vgg_feats = self.featlayer(tar)\n",
        "        content_loss_list = [self.feat_content_layers[layer] * self._l1loss(gen_vgg_feats[layer], tar_vgg_feats[layer]) for\n",
        "                             layer in self.feat_content_layers]\n",
        "        content_loss = reduce(lambda x, y: x + y, content_loss_list)\n",
        "        return content_loss\n",
        "\n",
        "\n",
        "class TVLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TVLoss, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        h_x, w_x = x.size()[2:]\n",
        "        h_tv = torch.abs(x[:, :, 1:, :] - x[:, :, :h_x-1, :])\n",
        "        w_tv = torch.abs(x[:, :, :, 1:] - x[:, :, :, :w_x-1])\n",
        "        loss = torch.sum(h_tv) + torch.sum(w_tv)\n",
        "        return loss\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqINVIOCdSRA"
      },
      "source": [
        "### options.test_options"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tm2y-AL1dQGf"
      },
      "source": [
        "class TestOptions:\n",
        "    def __init__(self):\n",
        "        self.parser = argparse.ArgumentParser()\n",
        "        self.initialized = False\n",
        "\n",
        "    def initialize(self):\n",
        "        self.parser.add_argument('--dataset', type=str, default='skin_test',\n",
        "                                 help='The dataset of the experiment.')\n",
        "        self.parser.add_argument('--data_file', type=str, default=os.path.join(dir_path, 'data', 'processed', 'cancer'), help='the file storing testing file paths')\n",
        "        self.parser.add_argument('--mask_dir', type=str, default=os.path.join(dir_path, 'data', 'masks', 'dilated-masks-224'), help='directory with saved masks, if applicable')\n",
        "        self.parser.add_argument('--test_dir', type=str, default=os.path.join(dir_path, 'data', 'results_gmcnn'), help='models are saved here')\n",
        "        self.parser.add_argument('--load_model_dir', type=str, default= os.path.join(dir_path, 'models','inpainting_gmcnn',   \\\n",
        "                                   '20210601-112529_GMCNN_isic_b8_s224x224_gc32_dc64_randmask-ellipse'), help='pretrained models are given here')\n",
        "        self.parser.add_argument('--seed', type=int, default=1, help='random seed')\n",
        "        self.parser.add_argument('--gpu_ids', type=str, default='0')\n",
        "\n",
        "        self.parser.add_argument('--model', type=str, default='gmcnn')\n",
        "        self.parser.add_argument('--random_mask', type=int, default=1,\n",
        "                                 help='using random mask')\n",
        "\n",
        "        self.parser.add_argument('--img_shapes', type=str, default='224,224,3',\n",
        "                                 help='given shape parameters: h,w,c or h,w')\n",
        "        self.parser.add_argument('--mask_shapes', type=str, default='40',\n",
        "                                 help='given mask parameters: h,w  or if mask_type==ellipse then should be number representing ellipse width.')\n",
        "        self.parser.add_argument('--mask_type', type=str, default='ellipse')\n",
        "        self.parser.add_argument('--test_num', type=int, default=-1)\n",
        "        self.parser.add_argument('--mode', type=str, default='save')\n",
        "        self.parser.add_argument('--phase', type=str, default='test')\n",
        "\n",
        "        # for generator\n",
        "        self.parser.add_argument('--g_cnum', type=int, default=32,\n",
        "                                 help='# of generator filters in first conv layer')\n",
        "        self.parser.add_argument('--d_cnum', type=int, default=32,\n",
        "                                 help='# of discriminator filters in first conv layer')\n",
        "\n",
        "    def parse(self, args=[]):\n",
        "        if not self.initialized:\n",
        "            self.initialize()\n",
        "\n",
        "        if isinstance(args, dict):                    # If args is supplied as a dict, flatten to a list.\n",
        "          args = [item for pair in args.items() for item in pair]\n",
        "        elif not isinstance(args, list):              # Otherwise, it should be a list.\n",
        "          raise('args should be a dict or a list.')\n",
        "        \n",
        "        self.opt = self.parser.parse_args(args=args)          # Added args=[]  to make it work in notebook.\n",
        "\n",
        "        if self.opt.data_file != '':\n",
        "            self.opt.dataset_path = self.opt.data_file\n",
        "\n",
        "        if os.path.exists(self.opt.test_dir) is False:\n",
        "            os.mkdir(self.opt.test_dir)\n",
        "\n",
        "        assert self.opt.random_mask in [0, 1]\n",
        "        self.opt.random_mask = True if self.opt.random_mask == 1 else False\n",
        "\n",
        "        assert self.opt.mask_type in ['rect', 'stroke', 'ellipse', 'saved']     # Added ellipse mask_type option\n",
        "\n",
        "        str_img_shapes = self.opt.img_shapes.split(',')\n",
        "        self.opt.img_shapes = [int(x) for x in str_img_shapes]\n",
        "\n",
        "        if self.opt.mask_type=='ellipse':                                      # If ellipse type then the mask size is just one number.\n",
        "          self.opt.mask_shapes = int(self.opt.mask_shapes)\n",
        "        elif self.opt.mask_type == 'saved':\n",
        "          pass\n",
        "        else:\n",
        "          str_mask_shapes = self.opt.mask_shapes.split(',')\n",
        "          self.opt.mask_shapes = [int(x) for x in str_mask_shapes]\n",
        "\n",
        "        # model name and date\n",
        "        self.opt.date_str = 'test_'+time.strftime('%Y%m%d-%H%M%S')\n",
        "        self.opt.model_folder = self.opt.date_str + '_' + self.opt.dataset + '_' + self.opt.model\n",
        "        self.opt.model_folder += '_s' + str(self.opt.img_shapes[0]) + 'x' + str(self.opt.img_shapes[1])\n",
        "        self.opt.model_folder += '_gc' + str(self.opt.g_cnum)\n",
        "        self.opt.model_folder += '_randmask-' + self.opt.mask_type if self.opt.random_mask else ''\n",
        "        if self.opt.random_mask:\n",
        "            self.opt.model_folder += '_seed-' + str(self.opt.seed)\n",
        "        self.opt.saving_path = os.path.join(self.opt.test_dir, self.opt.model_folder)\n",
        "\n",
        "        if os.path.exists(self.opt.saving_path) is False and self.opt.mode == 'save':\n",
        "            os.mkdir(self.opt.saving_path)\n",
        "\n",
        "        if os.path.exists(os.path.join(self.opt.saving_path, \"combined\")) is False and self.opt.mode == 'save':\n",
        "          os.mkdir(os.path.join(self.opt.saving_path, \"combined\"))\n",
        "\n",
        "        if os.path.exists(os.path.join(self.opt.saving_path, \"inpainted\")) is False and self.opt.mode == 'save':\n",
        "          os.mkdir(os.path.join(self.opt.saving_path, \"inpainted\"))\n",
        "\n",
        "        args = vars(self.opt)\n",
        "\n",
        "        print('------------ Options -------------')\n",
        "        for k, v in sorted(args.items()):\n",
        "            print('%s: %s' % (str(k), str(v)))\n",
        "        print('-------------- End ----------------')\n",
        "\n",
        "        return self.opt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFtzcxARyjvF"
      },
      "source": [
        "### Create elliptical masks\n",
        "Original code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajDV_EtQyhl_"
      },
      "source": [
        "def find_angle(pos1, pos2, ret_type = 'deg'):\n",
        "    # Find the angle between two pixel points, pos1 and pos2.\n",
        "    angle_rads = math.atan2(pos2[1] - pos1[1], pos2[0] - pos1[1])\n",
        "    \n",
        "    if ret_type == 'rads':\n",
        "        return angle_rads\n",
        "    elif ret_type == 'deg':\n",
        "        return math.degrees(angle_rads)                                     # Convert from radians to degrees.\n",
        "\n",
        "\n",
        "def sample_centre_pts(n, imsize, xlimits=(50,250), ylimits=(50,250)):\n",
        "    # Function to generate random sample of points for the centres of the elliptical masks.\n",
        "    pts = np.empty((n,2))                                                   # Empty array to hold the final points\n",
        "    \n",
        "    count=0\n",
        "    while count < n:\n",
        "        sample = randint(0, imsize[0], (n,2))[0]                            # Assumes im_size is symmetric\n",
        "\n",
        "        # Check the point is in the valid region.\n",
        "        is_valid = (sample[0] < xlimits[0]) | (sample[0] > xlimits[1]) |     \\\n",
        "                (sample[1] < ylimits[0]) | (sample[1] > ylimits[1])\n",
        "        \n",
        "        if is_valid:                                                        # Only take the point if it's within the valid region.\n",
        "            pts[count] = sample\n",
        "            count += 1\n",
        "\n",
        "    return pts\n",
        "\n",
        "def generate_ellipse_mask(imsize, mask_size, seed=None):\n",
        "    im_centre = (int(imsize[0]/2), int(imsize[1]/2))\n",
        "    x_bounds =  (int(0.1*imsize[0]), int(imsize[0] - 0.1*imsize[0]))        # Bounds for the valid region of mask centres.\n",
        "    y_bounds =  (int(0.1*imsize[1]), int(imsize[1] - 0.1*imsize[1]))\n",
        "    \n",
        "    if seed is not None:\n",
        "      random.seed(seed)   # Set seed for repeatability\n",
        "\n",
        "    n = 1 + random.binomial(1, 0.3)                                         # The number of masks per image either 1 (70% of the time) or 2 (30% of the time) \n",
        "    centre_pts = sample_centre_pts(n, imsize, x_bounds, y_bounds)           # Get a random sample for the mask centres.\n",
        "    \n",
        "    startAngle = 0.0\n",
        "    endAngle = 360.0                                                        # Draw full ellipses (although part may fall outside the image)\n",
        "        \n",
        "    mask = np.zeros((imsize[0], imsize[1], 1), np.float32)                  # Create blank canvas for the mask.\n",
        "\n",
        "    for pt in centre_pts:\n",
        "        size = abs(int(random.normal(mask_size, mask_size/5.0)))            # Randomness introduced in the mask size. \n",
        "        ratio = 2*random.random(1) + 1                                      # Ratio between length and width. Sample from Unif(1,3).\n",
        "        \n",
        "        centrex = int(pt[0])\n",
        "        centrey = int(pt[1])\n",
        "        \n",
        "        angle = find_angle(im_centre, (centrex, centrey))                   # Get the angle between the centre of the image and the mask centre.\n",
        "        angle = int(angle + random.normal(0.0, 5.0))                        # Base the angle of rotation on the above angle.\n",
        "        \n",
        "        mask = cv2.ellipse(mask, (centrex,centrey), (size, int(size*ratio)), \n",
        "                           angle, startAngle, endAngle, \n",
        "                           color=1, thickness=-1)                         # Insert a ellipse with the parameters defined above.\n",
        "\n",
        "    mask = np.minimum(mask, 1.0)                                          # This may be redundant.\n",
        "    mask = np.transpose(mask, [2, 0, 1])                                  # bring the 'channel' axis to the first axis.\n",
        "    mask = np.expand_dims(mask, 0)                                        # Add in extra axis at axis=0 - resulting shape (1, 1, imsize[0],imsize[1])\n",
        "\n",
        "    return mask\n",
        "\n",
        "# test_mask = generate_ellipse_mask((224,224))\n",
        "# from matplotlib import pyplot as plt\n",
        "# plt.imshow(test_mask[0][0], cmap='Greys_r')\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKEOrKK4c9d8"
      },
      "source": [
        "### utils.utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzlSFSUDc7vv"
      },
      "source": [
        "def gauss_kernel(size=21, sigma=3, inchannels=3, outchannels=3):\n",
        "    interval = (2 * sigma + 1.0) / size\n",
        "    x = np.linspace(-sigma-interval/2,sigma+interval/2,size+1)\n",
        "    ker1d = np.diff(st.norm.cdf(x))\n",
        "    kernel_raw = np.sqrt(np.outer(ker1d, ker1d))\n",
        "    kernel = kernel_raw / kernel_raw.sum()\n",
        "    out_filter = np.array(kernel, dtype=np.float32)\n",
        "    out_filter = out_filter.reshape((1, 1, size, size))\n",
        "    out_filter = np.tile(out_filter, [outchannels, inchannels, 1, 1])\n",
        "    return out_filter\n",
        "\n",
        "\n",
        "def np_free_form_mask(maxVertex, maxLength, maxBrushWidth, maxAngle, h, w):\n",
        "    mask = np.zeros((h, w, 1), np.float32)\n",
        "    numVertex = np.random.randint(maxVertex + 1)\n",
        "    startY = np.random.randint(h)\n",
        "    startX = np.random.randint(w)\n",
        "    brushWidth = 0\n",
        "    for i in range(numVertex):\n",
        "        angle = np.random.randint(maxAngle + 1)\n",
        "        angle = angle / 360.0 * 2 * np.pi\n",
        "        if i % 2 == 0:\n",
        "            angle = 2 * np.pi - angle\n",
        "        length = np.random.randint(maxLength + 1)\n",
        "        brushWidth = np.random.randint(10, maxBrushWidth + 1) // 2 * 2\n",
        "        nextY = startY + length * np.cos(angle)\n",
        "        nextX = startX + length * np.sin(angle)\n",
        "\n",
        "        nextY = np.maximum(np.minimum(nextY, h - 1), 0).astype(np.int)\n",
        "        nextX = np.maximum(np.minimum(nextX, w - 1), 0).astype(np.int)\n",
        "\n",
        "        cv2.line(mask, (startY, startX), (nextY, nextX), 1, brushWidth)\n",
        "        cv2.circle(mask, (startY, startX), brushWidth // 2, 2)\n",
        "\n",
        "        startY, startX = nextY, nextX\n",
        "    cv2.circle(mask, (startY, startX), brushWidth // 2, 2)\n",
        "    return mask\n",
        "\n",
        "\n",
        "def generate_rect_mask(im_size, mask_size, margin=8, rand_mask=True):\n",
        "    mask = np.zeros((im_size[0], im_size[1])).astype(np.float32)\n",
        "    if rand_mask:\n",
        "        sz0, sz1 = mask_size[0], mask_size[1]\n",
        "        of0 = np.random.randint(margin, im_size[0] - sz0 - margin)\n",
        "        of1 = np.random.randint(margin, im_size[1] - sz1 - margin)\n",
        "    else:\n",
        "        sz0, sz1 = mask_size[0], mask_size[1]\n",
        "        of0 = (im_size[0] - sz0) // 2\n",
        "        of1 = (im_size[1] - sz1) // 2\n",
        "    mask[of0:of0+sz0, of1:of1+sz1] = 1\n",
        "    mask = np.expand_dims(mask, axis=0)\n",
        "    mask = np.expand_dims(mask, axis=0)\n",
        "    rect = np.array([[of0, sz0, of1, sz1]], dtype=int)\n",
        "    return mask, rect\n",
        "\n",
        "\n",
        "def generate_stroke_mask(im_size, parts=10, maxVertex=20, maxLength=100, maxBrushWidth=24, maxAngle=360):\n",
        "    mask = np.zeros((im_size[0], im_size[1], 1), dtype=np.float32)\n",
        "    for i in range(parts):\n",
        "        mask = mask + np_free_form_mask(maxVertex, maxLength, maxBrushWidth, maxAngle, im_size[0], im_size[1])\n",
        "    mask = np.minimum(mask, 1.0)\n",
        "    mask = np.transpose(mask, [2, 0, 1])\n",
        "    mask = np.expand_dims(mask, 0)\n",
        "    return mask\n",
        "\n",
        "\n",
        "def generate_mask(type, im_size, mask_size):\n",
        "    if type == 'rect':\n",
        "        return generate_rect_mask(im_size, mask_size)\n",
        "    elif type == 'ellipse':\n",
        "        return generate_ellipse_mask(im_size, mask_size), None\n",
        "    else:\n",
        "        return generate_stroke_mask(im_size), None\n",
        "\n",
        "\n",
        "def getLatest(folder_path):\n",
        "    files = glob.glob(folder_path)\n",
        "    file_times = list(map(lambda x: time.ctime(os.path.getctime(x)), files))\n",
        "    return files[sorted(range(len(file_times)), key=lambda x: file_times[x])[-1]]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28hpLAavcrZS"
      },
      "source": [
        "### model.net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5QakEudb8zf"
      },
      "source": [
        "# generative multi-column convolutional neural net\n",
        "class GMCNN(BaseNet):\n",
        "    def __init__(self, in_channels, out_channels, cnum=32, act=F.elu, norm=F.instance_norm, using_norm=False):\n",
        "        super(GMCNN, self).__init__()\n",
        "        self.act = act\n",
        "        self.using_norm = using_norm\n",
        "        if using_norm is True:\n",
        "            self.norm = norm\n",
        "        else:\n",
        "            self.norm = None\n",
        "        ch = cnum\n",
        "\n",
        "        # network structure\n",
        "        self.EB1 = []\n",
        "        self.EB2 = []\n",
        "        self.EB3 = []\n",
        "        self.decoding_layers = []\n",
        "\n",
        "        self.EB1_pad_rec = []\n",
        "        self.EB2_pad_rec = []\n",
        "        self.EB3_pad_rec = []\n",
        "\n",
        "        self.EB1.append(nn.Conv2d(in_channels, ch, kernel_size=7, stride=1))\n",
        "\n",
        "        self.EB1.append(nn.Conv2d(ch, ch * 2, kernel_size=7, stride=2))\n",
        "        self.EB1.append(nn.Conv2d(ch * 2, ch * 2, kernel_size=7, stride=1))\n",
        "\n",
        "        self.EB1.append(nn.Conv2d(ch * 2, ch * 4, kernel_size=7, stride=2))\n",
        "        self.EB1.append(nn.Conv2d(ch * 4, ch * 4, kernel_size=7, stride=1))\n",
        "        self.EB1.append(nn.Conv2d(ch * 4, ch * 4, kernel_size=7, stride=1))\n",
        "\n",
        "        self.EB1.append(nn.Conv2d(ch * 4, ch * 4, kernel_size=7, stride=1, dilation=2))\n",
        "        self.EB1.append(nn.Conv2d(ch * 4, ch * 4, kernel_size=7, stride=1, dilation=4))\n",
        "        self.EB1.append(nn.Conv2d(ch * 4, ch * 4, kernel_size=7, stride=1, dilation=8))\n",
        "        self.EB1.append(nn.Conv2d(ch * 4, ch * 4, kernel_size=7, stride=1, dilation=16))\n",
        "\n",
        "        self.EB1.append(nn.Conv2d(ch * 4, ch * 4, kernel_size=7, stride=1))\n",
        "        self.EB1.append(nn.Conv2d(ch * 4, ch * 4, kernel_size=7, stride=1))\n",
        "\n",
        "        self.EB1.append(PureUpsampling(scale=4))\n",
        "\n",
        "        self.EB1_pad_rec = [3, 3, 3, 3, 3, 3, 6, 12, 24, 48, 3, 3, 0]\n",
        "\n",
        "        self.EB2.append(nn.Conv2d(in_channels, ch, kernel_size=5, stride=1))\n",
        "\n",
        "        self.EB2.append(nn.Conv2d(ch, ch * 2, kernel_size=5, stride=2))\n",
        "        self.EB2.append(nn.Conv2d(ch * 2, ch * 2, kernel_size=5, stride=1))\n",
        "\n",
        "        self.EB2.append(nn.Conv2d(ch * 2, ch * 4, kernel_size=5, stride=2))\n",
        "        self.EB2.append(nn.Conv2d(ch * 4, ch * 4, kernel_size=5, stride=1))\n",
        "        self.EB2.append(nn.Conv2d(ch * 4, ch * 4, kernel_size=5, stride=1))\n",
        "\n",
        "        self.EB2.append(nn.Conv2d(ch * 4, ch * 4, kernel_size=5, stride=1, dilation=2))\n",
        "        self.EB2.append(nn.Conv2d(ch * 4, ch * 4, kernel_size=5, stride=1, dilation=4))\n",
        "        self.EB2.append(nn.Conv2d(ch * 4, ch * 4, kernel_size=5, stride=1, dilation=8))\n",
        "        self.EB2.append(nn.Conv2d(ch * 4, ch * 4, kernel_size=5, stride=1, dilation=16))\n",
        "\n",
        "        self.EB2.append(nn.Conv2d(ch * 4, ch * 4, kernel_size=5, stride=1))\n",
        "        self.EB2.append(nn.Conv2d(ch * 4, ch * 4, kernel_size=5, stride=1))\n",
        "\n",
        "        self.EB2.append(PureUpsampling(scale=2, mode='nearest'))\n",
        "        self.EB2.append(nn.Conv2d(ch * 4, ch * 2, kernel_size=5, stride=1))\n",
        "        self.EB2.append(nn.Conv2d(ch * 2, ch * 2, kernel_size=5, stride=1))\n",
        "        self.EB2.append(PureUpsampling(scale=2))\n",
        "        self.EB2_pad_rec = [2, 2, 2, 2, 2, 2, 4, 8, 16, 32, 2, 2, 0, 2, 2, 0]\n",
        "\n",
        "        self.EB3.append(nn.Conv2d(in_channels, ch, kernel_size=3, stride=1))\n",
        "\n",
        "        self.EB3.append(nn.Conv2d(ch, ch * 2, kernel_size=3, stride=2))\n",
        "        self.EB3.append(nn.Conv2d(ch * 2, ch * 2, kernel_size=3, stride=1))\n",
        "\n",
        "        self.EB3.append(nn.Conv2d(ch * 2, ch * 4, kernel_size=3, stride=2))\n",
        "        self.EB3.append(nn.Conv2d(ch * 4, ch * 4, kernel_size=3, stride=1))\n",
        "        self.EB3.append(nn.Conv2d(ch * 4, ch * 4, kernel_size=3, stride=1))\n",
        "\n",
        "        self.EB3.append(nn.Conv2d(ch * 4, ch * 4, kernel_size=3, stride=1, dilation=2))\n",
        "        self.EB3.append(nn.Conv2d(ch * 4, ch * 4, kernel_size=3, stride=1, dilation=4))\n",
        "        self.EB3.append(nn.Conv2d(ch * 4, ch * 4, kernel_size=3, stride=1, dilation=8))\n",
        "        self.EB3.append(nn.Conv2d(ch * 4, ch * 4, kernel_size=3, stride=1, dilation=16))\n",
        "\n",
        "        self.EB3.append(nn.Conv2d(ch * 4, ch * 4, kernel_size=3, stride=1))\n",
        "        self.EB3.append(nn.Conv2d(ch * 4, ch * 4, kernel_size=3, stride=1))\n",
        "\n",
        "        self.EB3.append(PureUpsampling(scale=2, mode='nearest'))\n",
        "        self.EB3.append(nn.Conv2d(ch * 4, ch * 2, kernel_size=3, stride=1))\n",
        "        self.EB3.append(nn.Conv2d(ch * 2, ch * 2, kernel_size=3, stride=1))\n",
        "        self.EB3.append(PureUpsampling(scale=2, mode='nearest'))\n",
        "        self.EB3.append(nn.Conv2d(ch * 2, ch, kernel_size=3, stride=1))\n",
        "        self.EB3.append(nn.Conv2d(ch, ch, kernel_size=3, stride=1))\n",
        "\n",
        "        self.EB3_pad_rec = [1, 1, 1, 1, 1, 1, 2, 4, 8, 16, 1, 1, 0, 1, 1, 0, 1, 1]\n",
        "\n",
        "        self.decoding_layers.append(nn.Conv2d(ch * 7, ch // 2, kernel_size=3, stride=1))\n",
        "        self.decoding_layers.append(nn.Conv2d(ch // 2, out_channels, kernel_size=3, stride=1))\n",
        "\n",
        "        self.decoding_pad_rec = [1, 1]\n",
        "\n",
        "        self.EB1 = nn.ModuleList(self.EB1)\n",
        "        self.EB2 = nn.ModuleList(self.EB2)\n",
        "        self.EB3 = nn.ModuleList(self.EB3)\n",
        "        self.decoding_layers = nn.ModuleList(self.decoding_layers)\n",
        "\n",
        "        # padding operations\n",
        "        padlen = 49\n",
        "        self.pads = [0] * padlen\n",
        "        for i in range(padlen):\n",
        "            self.pads[i] = nn.ReflectionPad2d(i)\n",
        "        self.pads = nn.ModuleList(self.pads)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1, x2, x3 = x, x, x\n",
        "        for i, layer in enumerate(self.EB1):\n",
        "            pad_idx = self.EB1_pad_rec[i]\n",
        "            x1 = layer(self.pads[pad_idx](x1))\n",
        "            if self.using_norm:\n",
        "                x1 = self.norm(x1)\n",
        "            if pad_idx != 0:\n",
        "                x1 = self.act(x1)\n",
        "\n",
        "        for i, layer in enumerate(self.EB2):\n",
        "            pad_idx = self.EB2_pad_rec[i]\n",
        "            x2 = layer(self.pads[pad_idx](x2))\n",
        "            if self.using_norm:\n",
        "                x2 = self.norm(x2)\n",
        "            if pad_idx != 0:\n",
        "                x2 = self.act(x2)\n",
        "\n",
        "        for i, layer in enumerate(self.EB3):\n",
        "            pad_idx = self.EB3_pad_rec[i]\n",
        "            x3 = layer(self.pads[pad_idx](x3))\n",
        "            if self.using_norm:\n",
        "                x3 = self.norm(x3)\n",
        "            if pad_idx != 0:\n",
        "                x3 = self.act(x3)\n",
        "\n",
        "        x_d = torch.cat((x1, x2, x3), 1)\n",
        "        x_d = self.act(self.decoding_layers[0](self.pads[self.decoding_pad_rec[0]](x_d)))\n",
        "        x_d = self.decoding_layers[1](self.pads[self.decoding_pad_rec[1]](x_d))\n",
        "        x_out = torch.clamp(x_d, -1, 1)\n",
        "        return x_out\n",
        "\n",
        "\n",
        "# return one dimensional output indicating the probability of realness or fakeness\n",
        "class Discriminator(BaseNet):\n",
        "    def __init__(self, in_channels, cnum=32, fc_channels=8*8*32*4, act=F.elu, norm=None, spectral_norm=True):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.act = act\n",
        "        self.norm = norm\n",
        "        self.embedding = None\n",
        "        self.logit = None\n",
        "\n",
        "        ch = cnum\n",
        "        self.layers = []\n",
        "        if spectral_norm:\n",
        "            self.layers.append(SpectralNorm(nn.Conv2d(in_channels, ch, kernel_size=5, padding=2, stride=2)))\n",
        "            self.layers.append(SpectralNorm(nn.Conv2d(ch, ch * 2, kernel_size=5, padding=2, stride=2)))\n",
        "            self.layers.append(SpectralNorm(nn.Conv2d(ch * 2, ch * 4, kernel_size=5, padding=2, stride=2)))\n",
        "            self.layers.append(SpectralNorm(nn.Conv2d(ch * 4, ch * 4, kernel_size=5, padding=2, stride=2)))\n",
        "            self.layers.append(SpectralNorm(nn.Linear(fc_channels, 1)))\n",
        "        else:\n",
        "            self.layers.append(nn.Conv2d(in_channels, ch, kernel_size=5, padding=2, stride=2))\n",
        "            self.layers.append(nn.Conv2d(ch, ch * 2, kernel_size=5, padding=2, stride=2))\n",
        "            self.layers.append(nn.Conv2d(ch*2, ch*4, kernel_size=5, padding=2, stride=2))\n",
        "            self.layers.append(nn.Conv2d(ch*4, ch*4, kernel_size=5, padding=2, stride=2))\n",
        "            self.layers.append(nn.Linear(fc_channels, 1))\n",
        "        self.layers = nn.ModuleList(self.layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers[:-1]:\n",
        "            x = layer(x)\n",
        "            if self.norm is not None:\n",
        "                x = self.norm(x)\n",
        "            x = self.act(x)\n",
        "        self.embedding = x.view(x.size(0), -1)\n",
        "        self.logit = self.layers[-1](self.embedding)\n",
        "        return self.logit\n",
        "\n",
        "\n",
        "class GlobalLocalDiscriminator(BaseNet):\n",
        "    def __init__(self, in_channels, cnum=32, g_fc_channels=16*16*32*4, l_fc_channels=8*8*32*4, act=F.elu, norm=None,\n",
        "                 spectral_norm=True):\n",
        "        super(GlobalLocalDiscriminator, self).__init__()\n",
        "        self.act = act\n",
        "        self.norm = norm\n",
        "\n",
        "        self.global_discriminator = Discriminator(in_channels=in_channels, fc_channels=g_fc_channels, cnum=cnum,\n",
        "                                                  act=act, norm=norm, spectral_norm=spectral_norm)\n",
        "        self.local_discriminator = Discriminator(in_channels=in_channels, fc_channels=l_fc_channels, cnum=cnum,\n",
        "                                                 act=act, norm=norm, spectral_norm=spectral_norm)\n",
        "\n",
        "    def forward(self, x_g, x_l):\n",
        "        x_global = self.global_discriminator(x_g)\n",
        "        x_local = self.local_discriminator(x_l)\n",
        "        return x_global, x_local\n",
        "\n",
        "\n",
        "# from util.utils import generate_mask\n",
        "\n",
        "\n",
        "class InpaintingModel_GMCNN(BaseModel):\n",
        "    def __init__(self, in_channels, act=F.elu, norm=None, opt=None):\n",
        "        super(InpaintingModel_GMCNN, self).__init__()\n",
        "        self.opt = opt\n",
        "        self.init(opt)\n",
        "\n",
        "        self.confidence_mask_layer = ConfidenceDrivenMaskLayer()\n",
        "\n",
        "        self.netGM = GMCNN(in_channels, out_channels=3, cnum=opt.g_cnum, act=act, norm=norm).cuda()\n",
        "        # self.netGM = GMCNN(in_channels, out_channels=3, cnum=opt.g_cnum, act=act, norm=norm).cpu()\n",
        "\n",
        "        init_weights(self.netGM)\n",
        "        self.model_names = ['GM']\n",
        "        if self.opt.phase == 'test':\n",
        "            return\n",
        "\n",
        "        self.netD = None\n",
        "\n",
        "        self.optimizer_G = torch.optim.Adam(self.netGM.parameters(), lr=opt.lr, betas=(0.5, 0.9))\n",
        "        self.optimizer_D = None\n",
        "\n",
        "        self.wganloss = None\n",
        "        self.recloss = nn.L1Loss()\n",
        "        self.aeloss = nn.L1Loss()\n",
        "        self.mrfloss = None\n",
        "        self.lambda_adv = opt.lambda_adv\n",
        "        self.lambda_rec = opt.lambda_rec\n",
        "        self.lambda_ae = opt.lambda_ae\n",
        "        self.lambda_gp = opt.lambda_gp\n",
        "        self.lambda_mrf = opt.lambda_mrf\n",
        "        self.G_loss = None\n",
        "        self.G_loss_reconstruction = None\n",
        "        self.G_loss_mrf = None\n",
        "        self.G_loss_adv, self.G_loss_adv_local = None, None\n",
        "        self.G_loss_ae = None\n",
        "        self.D_loss, self.D_loss_local = None, None\n",
        "        self.GAN_loss = None\n",
        "\n",
        "        self.gt, self.gt_local = None, None\n",
        "        self.mask, self.mask_01 = None, None\n",
        "        self.rect = None\n",
        "        self.im_in, self.gin = None, None\n",
        "\n",
        "        self.completed, self.completed_local = None, None\n",
        "        self.completed_logit, self.completed_local_logit = None, None\n",
        "        self.gt_logit, self.gt_local_logit = None, None\n",
        "\n",
        "        self.pred = None\n",
        "\n",
        "        if self.opt.pretrain_network is False:\n",
        "            if self.opt.mask_type == 'rect':\n",
        "                self.netD = GlobalLocalDiscriminator(3, cnum=opt.d_cnum, act=act,\n",
        "                                                     g_fc_channels=opt.img_shapes[0]//16*opt.img_shapes[1]//16*opt.d_cnum*4,\n",
        "                                                     l_fc_channels=opt.mask_shapes[0]//16*opt.mask_shapes[1]//16*opt.d_cnum*4,\n",
        "                                                     spectral_norm=self.opt.spectral_norm).cuda()\n",
        "            else:\n",
        "                self.netD = GlobalLocalDiscriminator(3, cnum=opt.d_cnum, act=act,\n",
        "                                                     spectral_norm=self.opt.spectral_norm,\n",
        "                                                     g_fc_channels=opt.img_shapes[0]//16*opt.img_shapes[1]//16*opt.d_cnum*4,\n",
        "                                                     l_fc_channels=opt.img_shapes[0]//16*opt.img_shapes[1]//16*opt.d_cnum*4).cuda()\n",
        "            init_weights(self.netD)\n",
        "            self.optimizer_D = torch.optim.Adam(filter(lambda x: x.requires_grad, self.netD.parameters()), lr=opt.lr,\n",
        "                                                betas=(0.5, 0.9))\n",
        "            self.wganloss = WGANLoss()\n",
        "            self.mrfloss = IDMRFLoss()\n",
        "\n",
        "    def initVariables(self):\n",
        "        self.gt = self.input['gt']\n",
        "        mask, rect = generate_mask(self.opt.mask_type, self.opt.img_shapes, self.opt.mask_shapes)\n",
        "        self.mask_01 = torch.from_numpy(mask).cuda().repeat([self.opt.batch_size, 1, 1, 1])\n",
        "        self.mask = self.confidence_mask_layer(self.mask_01)\n",
        "        if self.opt.mask_type == 'rect':\n",
        "            self.rect = [rect[0, 0], rect[0, 1], rect[0, 2], rect[0, 3]]\n",
        "            self.gt_local = self.gt[:, :, self.rect[0]:self.rect[0] + self.rect[1],\n",
        "                            self.rect[2]:self.rect[2] + self.rect[3]]\n",
        "        else:\n",
        "            self.gt_local = self.gt\n",
        "        self.im_in = self.gt * (1 - self.mask_01)\n",
        "        self.gin = torch.cat((self.im_in, self.mask_01), 1)\n",
        "\n",
        "    def forward_G(self):\n",
        "        self.G_loss_reconstruction = self.recloss(self.completed * self.mask, self.gt.detach() * self.mask)\n",
        "        self.G_loss_reconstruction = self.G_loss_reconstruction / torch.mean(self.mask_01)\n",
        "        self.G_loss_ae = self.aeloss(self.pred * (1 - self.mask_01), self.gt.detach() * (1 - self.mask_01))\n",
        "        self.G_loss_ae = self.G_loss_ae / torch.mean(1 - self.mask_01)\n",
        "        self.G_loss = self.lambda_rec * self.G_loss_reconstruction + self.lambda_ae * self.G_loss_ae\n",
        "        if self.opt.pretrain_network is False:\n",
        "            # discriminator\n",
        "            self.completed_logit, self.completed_local_logit = self.netD(self.completed, self.completed_local)\n",
        "            self.G_loss_mrf = self.mrfloss((self.completed_local+1)/2.0, (self.gt_local.detach()+1)/2.0)\n",
        "            self.G_loss = self.G_loss + self.lambda_mrf * self.G_loss_mrf\n",
        "\n",
        "            self.G_loss_adv = -self.completed_logit.mean()\n",
        "            self.G_loss_adv_local = -self.completed_local_logit.mean()\n",
        "            self.G_loss = self.G_loss + self.lambda_adv * (self.G_loss_adv + self.G_loss_adv_local)\n",
        "\n",
        "    def forward_D(self):\n",
        "        self.completed_logit, self.completed_local_logit = self.netD(self.completed.detach(), self.completed_local.detach())\n",
        "        self.gt_logit, self.gt_local_logit = self.netD(self.gt, self.gt_local)\n",
        "        # hinge loss\n",
        "        self.D_loss_local = nn.ReLU()(1.0 - self.gt_local_logit).mean() + nn.ReLU()(1.0 + self.completed_local_logit).mean()\n",
        "        self.D_loss = nn.ReLU()(1.0 - self.gt_logit).mean() + nn.ReLU()(1.0 + self.completed_logit).mean()\n",
        "        self.D_loss = self.D_loss + self.D_loss_local\n",
        "\n",
        "    def backward_G(self):\n",
        "        self.G_loss.backward()\n",
        "\n",
        "    def backward_D(self):\n",
        "        self.D_loss.backward(retain_graph=True)\n",
        "\n",
        "    def optimize_parameters(self):\n",
        "        self.initVariables()\n",
        "\n",
        "        self.pred = self.netGM(self.gin)\n",
        "        self.completed = self.pred * self.mask_01 + self.gt * (1 - self.mask_01)\n",
        "        if self.opt.mask_type == 'rect':\n",
        "            self.completed_local = self.completed[:, :, self.rect[0]:self.rect[0] + self.rect[1],\n",
        "                                   self.rect[2]:self.rect[2] + self.rect[3]]\n",
        "        else:\n",
        "            self.completed_local = self.completed\n",
        "\n",
        "        if self.opt.pretrain_network is False:\n",
        "            for i in range(self.opt.D_max_iters):\n",
        "                self.optimizer_D.zero_grad()\n",
        "                self.optimizer_G.zero_grad()\n",
        "                self.forward_D()\n",
        "                self.backward_D()\n",
        "                self.optimizer_D.step()\n",
        "\n",
        "        self.optimizer_G.zero_grad()\n",
        "        self.forward_G()\n",
        "        self.backward_G()\n",
        "        self.optimizer_G.step()\n",
        "\n",
        "    def get_current_losses(self):\n",
        "        l = {'G_loss': self.G_loss.item(), 'G_loss_rec': self.G_loss_reconstruction.item(),\n",
        "             'G_loss_ae': self.G_loss_ae.item()}\n",
        "        if self.opt.pretrain_network is False:\n",
        "            l.update({'G_loss_adv': self.G_loss_adv.item(),\n",
        "                      'G_loss_adv_local': self.G_loss_adv_local.item(),\n",
        "                      'D_loss': self.D_loss.item(),\n",
        "                      'G_loss_mrf': self.G_loss_mrf.item()})\n",
        "        return l\n",
        "\n",
        "    def get_current_visuals(self):\n",
        "        return {'input': self.im_in.cpu().detach().numpy(), 'gt': self.gt.cpu().detach().numpy(),\n",
        "                'completed': self.completed.cpu().detach().numpy()}\n",
        "\n",
        "    def get_current_visuals_tensor(self):\n",
        "        return {'input': self.im_in.cpu().detach(), 'gt': self.gt.cpu().detach(),\n",
        "                'completed': self.completed.cpu().detach()}\n",
        "\n",
        "    def evaluate(self, im_in, mask):\n",
        "        im_in = torch.from_numpy(im_in).type(torch.FloatTensor).cuda() / 127.5 - 1\n",
        "        mask = torch.from_numpy(mask).type(torch.FloatTensor).cuda()\n",
        "        im_in = im_in * (1-mask)\n",
        "        xin = torch.cat((im_in, mask), 1)\n",
        "        ret = self.netGM(xin) * mask + im_in * (1-mask)\n",
        "        ret = (ret.cpu().detach().numpy() + 1) * 127.5\n",
        "        return ret.astype(np.uint8)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQ7jw170czQH"
      },
      "source": [
        "### test.py\n",
        "Based on code from inpainting_gmcnn but adjusted significantly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHlGcoiRK6mK"
      },
      "source": [
        "##### Set up inpainting parameters - first inpaint the coloured patches using saved masks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmvRomn0JKON"
      },
      "source": [
        "args_patches = {'--dataset': 'inpaint_coloured_patches',  \n",
        "                '--test_num': '-1', \n",
        "                '--data_file': '{}'.format(os.path.join(dir_path, 'models', 'test_files.txt')),\n",
        "                '--mask_type': 'saved',\n",
        "                '--random_mask': '0',\n",
        "                '--load_model_dir': '{}'.format(os.path.join(dir_path, 'models', 'inpainting_gmcnn', \\\n",
        "                                                             '20210607-165607_GMCNN_expanded_isic_no_patch_fifth_run_b8_s224x224_gc32_dc64_randmask-ellipse'))\n",
        "}\n",
        "\n",
        "args_no_patches = {'--dataset': 'inpaint_no_patches',  \n",
        "                  '--test_num': '-1', \n",
        "                  '--data_file': '{}'.format(os.path.join(dir_path, 'models', 'test_files.txt')),\n",
        "                  '--mask_type': 'ellipse',\n",
        "                  '--random_mask': '1',\n",
        "                  '--load_model_dir': '{}'.format(os.path.join(dir_path, 'models', 'inpainting_gmcnn', \\\n",
        "                                                             '20210607-165607_GMCNN_expanded_isic_no_patch_fifth_run_b8_s224x224_gc32_dc64_randmask-ellipse'))                   \n",
        "}\n",
        "\n",
        "# Arguments for inpainting the patches in the training set.\n",
        "args_train_patches = {'--dataset': 'inpaint_train_patches',  \n",
        "                  '--test_num': '-1', \n",
        "                  '--data_file': '{}'.format(os.path.join(dir_path, 'models', 'train_files.txt')),\n",
        "                  '--mask_type': 'saved',\n",
        "                  '--random_mask': '0',\n",
        "                  '--load_model_dir': '{}'.format(os.path.join(dir_path, 'models', 'inpainting_gmcnn', \\\n",
        "                                                             '20210607-165607_GMCNN_expanded_isic_no_patch_fifth_run_b8_s224x224_gc32_dc64_randmask-ellipse'))                   \n",
        "}\n",
        "\n",
        "# Arguments for inpainting the patches in the training set.\n",
        "args_malignant = {'--dataset': 'inpaint_malignant',  \n",
        "                  '--test_num': '-1', \n",
        "                  '--data_file': '{}'.format(os.path.join(dir_path, 'data', 'malignant-patches', 'manually-adjusted')),\n",
        "                  '--mask_type': 'saved',\n",
        "                  '--mask_dir': '{}'.format(os.path.join(dir_path, 'data', 'masks', 'malignant-patches')),\n",
        "                  '--random_mask': '0',\n",
        "                  '--load_model_dir': '{}'.format(os.path.join(dir_path, 'models', 'inpainting_gmcnn', \\\n",
        "                                                             '20210607-165607_GMCNN_expanded_isic_no_patch_fifth_run_b8_s224x224_gc32_dc64_randmask-ellipse'))                   \n",
        "}\n",
        "\n",
        "config_patches    = TestOptions().parse(args=args_patches)\n",
        "config_no_patches = TestOptions().parse(args=args_no_patches)\n",
        "config_train_patches = TestOptions().parse(args=args_train_patches)\n",
        "config_malignant = TestOptions().parse(args=args_malignant)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NG6XFR1UJX9_"
      },
      "source": [
        "##### Set up the trained inpainting model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_MMOlE6xQuk"
      },
      "source": [
        "# Get the available GPUs.\n",
        "os.environ['CUDA_VISIBLE_DEVICES']=str(np.argmax([int(x.split()[2]) for x in subprocess.Popen(\n",
        "        \"nvidia-smi -q -d Memory | grep -A4 GPU | grep Free\", shell=True, stdout=subprocess.PIPE).stdout.readlines()]\n",
        "        ))\n",
        "\n",
        "# Set up a model and load the trained weights.\n",
        "print('configuring model..')\n",
        "ourModel = InpaintingModel_GMCNN(in_channels=4, opt=config_patches)\n",
        "ourModel.print_networks()\n",
        "if config_patches.load_model_dir != '':\n",
        "    print('Loading trained model from {}'.format(config_patches.load_model_dir))\n",
        "    ourModel.load_networks(getLatest(os.path.join(config_patches.load_model_dir, '*.pth')))\n",
        "    print('Loading done.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Px6DvEolKjiv"
      },
      "source": [
        "##### Extract the relevant file paths."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryIt0sm1JyCW"
      },
      "source": [
        "if os.path.isfile(config_patches.dataset_path):\n",
        "    pathfile = open(config_patches.dataset_path, 'rt').read().splitlines()\n",
        "elif os.path.isdir(config_patches.dataset_path):\n",
        "    pathfile = glob.glob(os.path.join(config_patches.dataset_path, '*.jpg'))   # Changed from png.\n",
        "else:\n",
        "    print('Invalid testing data file/folder path.')\n",
        "    exit(1)\n",
        "\n",
        "mask_files = os.listdir(config_patches.mask_dir)        # Get list of all the mask image names.\n",
        "\n",
        "# Separate images without patches and with patches (i.e. with corresponding mask)\n",
        "patch_ind = [os.path.basename(file) in mask_files for file in pathfile]\n",
        "path_ims_patches    = [file for i, file in enumerate(pathfile) if patch_ind[i]]\n",
        "path_ims_no_patches = [file for i, file in enumerate(pathfile) if not patch_ind[i]]\n",
        "\n",
        "# Extract the paths for the training images with patches.\n",
        "pathfile_train = open(config_train_patches.dataset_path, 'rt').read().splitlines()\n",
        "\n",
        "path_train_patches = [file for file in pathfile_train if os.path.basename(file) in mask_files]\n",
        "\n",
        "# Extract the paths for the relevant malignant images.\n",
        "pathfile_malignant = glob.glob(os.path.join(config_malignant.dataset_path, '*.jpg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTzCZil4W3S4"
      },
      "source": [
        "##### Function for looping through the images, inpainting & saving the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7DWs2vdkhh0"
      },
      "source": [
        "def inpaint_ims(config, pathfile):\n",
        "  print(\"-\" * 30, \"\\n Inpainting on {}\".format(config.dataset))\n",
        "\n",
        "  if config.random_mask:\n",
        "      np.random.seed(config.seed)\n",
        "\n",
        "  total_number = len(pathfile)\n",
        "  test_num = total_number if config.test_num == -1 else min(total_number, config.test_num)\n",
        "  print('The total number of testing images is {}, and we take {} for test.'.format(total_number, test_num))\n",
        "\n",
        "  for i in range(test_num):  \n",
        "      filename = os.path.basename(pathfile[i])                                # Extract the filename from the full path.\n",
        "\n",
        "      if config.mask_type == 'saved':                                         # Use a saved mask for this project, rather than randomly generating one.\n",
        "        mask_img = cv2.imread(os.path.join(config.mask_dir, filename), 0)     # Read the mask in grayscale.\n",
        "        mask = (mask_img > 100)  # Threshold the mask for intensities from 100-255.\n",
        "        # Add two extra axes at the start of the array to match the expected shape for the model: (1, 1, 224, 224)\n",
        "        mask = np.expand_dims(mask, axis=(0,1)) \n",
        "\n",
        "      else:\n",
        "        mask, _ = generate_mask(config.mask_type, config.img_shapes, config.mask_shapes)\n",
        "\n",
        "      image = cv2.imread(pathfile[i])\n",
        "      if image is None:                                           # Added because some of the images in our directory may be empty.\n",
        "        continue\n",
        "      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "      h, w = image.shape[:2]\n",
        "\n",
        "      if h >= config.img_shapes[0] and w >= config.img_shapes[1]:\n",
        "          h_start = (h-config.img_shapes[0]) // 2\n",
        "          w_start = (w-config.img_shapes[1]) // 2\n",
        "          image = image[h_start: h_start+config.img_shapes[0], w_start: w_start+config.img_shapes[1], :]\n",
        "      else:\n",
        "          t = min(h, w)\n",
        "          image = image[(h-t)//2:(h-t)//2+t, (w-t)//2:(w-t)//2+t, :]\n",
        "          image = cv2.resize(image, (config.img_shapes[1], config.img_shapes[0]))\n",
        "\n",
        "      image = np.transpose(image, [2, 0, 1])\n",
        "      image = np.expand_dims(image, axis=0)\n",
        "      image_vis = image * (1-mask) + 255 * mask\n",
        "      image_vis = np.transpose(image_vis[0][::-1,:,:], [1, 2, 0])\n",
        "      # cv2.imwrite(os.path.join(config.saving_path, 'input_{}'.format(filename)), image_vis.astype(np.uint8))\n",
        "\n",
        "      h, w = image.shape[2:]\n",
        "      grid = 4\n",
        "      image = image[:, :, :h // grid * grid, :w // grid * grid]\n",
        "      mask = mask[:, :, :h // grid * grid, :w // grid * grid]\n",
        "      result = ourModel.evaluate(image, mask)\n",
        "      result = np.transpose(result[0][::-1,:,:], [1, 2, 0])\n",
        "      cv2.imwrite(os.path.join(config.saving_path, \"inpainted\", filename), result)   # The extension '.jpg' is already included in the filename variable.\n",
        "\n",
        "      image = np.transpose(image[0][::-1,:,:], [1, 2, 0])\n",
        "      if (image.shape == result.shape) & (image.shape == image_vis.shape):               \n",
        "        im_combined = np.concatenate((image, image_vis, result), axis=1)                # Combine the original, masked & output images and write to file.\n",
        "        cv2.imwrite(os.path.join(config.saving_path, \"combined\", filename), im_combined)\n",
        "      else: \n",
        "        print('Mismatched shapes, images not combined. \\n\\toriginal: {}, input: {}, result: {}'.format(image.shape, image_vis.shape, result.shape))\n",
        "\n",
        "      print(' > {} / {}'.format(i+1, test_num))\n",
        "  print('done.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqLfZxx9W_EQ"
      },
      "source": [
        "##### Run the inpainting for both sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cgEaLlGVY7V"
      },
      "source": [
        "inpaint_ims(config_patches, path_ims_patches)\n",
        "inpaint_ims(config_no_patches, path_ims_no_patches)\n",
        "\n",
        "# inpaint the patches in the training set.\n",
        "inpaint_ims(config_train_patches, path_train_patches) \n",
        "\n",
        "# inpaint the relevant patch sections for the malignant experiment.\n",
        "inpaint_ims(config_malignant, pathfile_malignant) "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}