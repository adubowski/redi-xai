{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_blank_patches.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "n8Tt_ZTaOwpl",
        "nWzl2-I9PFRz",
        "GhDv9IKePKQv",
        "gJHhAhMePRH1"
      ],
      "authorship_tag": "ABX9TyPSN+kAOYLj3p9IpCyKas8n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adubowski/redi-xai/blob/main/classifier/test_blank_patches.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64bch0TWEsDk"
      },
      "source": [
        "### Load Libraries and Initialise Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMz4DOxe1vmt"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "import torch\n",
        "import sys\n",
        "import numpy as np\n",
        "import pickle as pkl\n",
        "from os.path import join as oj\n",
        "\n",
        "import torch.optim as optim\n",
        "import os\n",
        "from torch.utils.data import TensorDataset, ConcatDataset, Subset\n",
        "import argparse\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from torch import nn\n",
        "from numpy.random import randint\n",
        "import torchvision.models as models\n",
        "import time\n",
        "import copy\n",
        "import gc\n",
        "import json\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "plt.style.use('seaborn')\n",
        "from matplotlib.pyplot import imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkxsW7a3E8y3"
      },
      "source": [
        "##### Mount Google Drive and create & save various directory paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqPXREGv11NT"
      },
      "source": [
        "drive.mount(\"/content/drive\")\n",
        "dir_path = \"/content/drive/MyDrive/redi-detecting-cheating\"\n",
        "\n",
        "with open(oj(dir_path, 'config.json')) as json_file:\n",
        "    data = json.load(json_file)\n",
        "\n",
        "model_path = oj(dir_path, data[\"model_folder\"], \"initial_classifier\")\n",
        "data_path = oj(dir_path, data[\"data_folder\"])\n",
        "\n",
        "seg_path  = oj(data_path, \"patch-segmentation\")\n",
        "not_cancer_path = oj(data_path, \"processed/no_cancer\")\n",
        "cancer_path = oj(data_path, \"processed/cancer\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3sHfoIqOknh"
      },
      "source": [
        "##### Parameters for standardising the data - taken from Rieger et al Github.\n",
        "Need to check if these are specific to that project or to the VGG16 model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9b0CGyQOiJJ"
      },
      "source": [
        "mean = np.asarray([0.485, 0.456, 0.406]) \n",
        "std = np.asarray([0.229, 0.224, 0.225])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JZLeFtVIuz7"
      },
      "source": [
        "##### Function to plot image and segmentation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oh6dgnfIt-V"
      },
      "source": [
        "def plot_lesion_and_seg(dataset, idx):\n",
        "  \"\"\" \n",
        "  Input: \n",
        "    dataset   -   Tensor dataset of images. Contained in each element of the dataset is the image, label and segmentation.\n",
        "    idx       -   The image index to plot.\n",
        "  Returns:\n",
        "    None      -   Plots the original lesion image and segmentation image to screen.\n",
        "  \"\"\"\n",
        "  plt.style.use('default')\n",
        "  fig, ax = plt.subplots(2, 1)\n",
        "\n",
        "  # The axes have been swapped in the tensor dataset so that the colour channels are the first axis. Undo this with permute().\n",
        "  # The image has been standardised, so multiply by the std and add to the mean to reverse this.\n",
        "  orig_img = dataset[idx][0].permute(1, 2, 0).numpy()*std + mean\n",
        "  ax[0].imshow(orig_img)\n",
        "\n",
        "  ax[1].imshow(dataset[idx][2], cmap=\"Greys\")   # Plot the segmentation\n",
        "\n",
        "# plot_lesion_and_seg(not_cancer_dataset, 1100)       # Example.\n",
        "\n",
        "def plot_lesion(datalist, idx):\n",
        "  \"\"\" \n",
        "  Input: \n",
        "    dataset   -   Tensor dataset of images. Contained in each element of the dataset is the image, label and segmentation.\n",
        "    idx       -   The image index to plot.\n",
        "  Returns:\n",
        "    None      -   Plots the original lesion image and segmentation image to screen.\n",
        "  \"\"\"\n",
        "  plt.style.use('default')\n",
        "  fig, ax = plt.subplots(1, 1)\n",
        "\n",
        "  # The axes have been swapped in the tensor dataset so that the colour channels are the first axis. Undo this with permute().\n",
        "  # The image has been standardised, so multiply by the std and add to the mean to reverse this.\n",
        "  orig_img = datalist[idx].permute(1, 2, 0).numpy()*std + mean\n",
        "  ax.imshow(orig_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVKXOv1NJB4m"
      },
      "source": [
        "##### Functions to get model predictions and AUC and F1 scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbhLHxUFJBED"
      },
      "source": [
        "from sklearn.metrics import auc,average_precision_score, roc_curve,roc_auc_score,precision_recall_curve, f1_score\n",
        "\n",
        "def get_output(model, dataset):\n",
        "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=16,\n",
        "                                             shuffle=False, num_workers=4)\n",
        "    model = model.eval()\n",
        "    y = []\n",
        "    y_hat = []\n",
        "    softmax= torch.nn.Softmax()\n",
        "    with torch.no_grad() :\n",
        "        for inputs, labels, cd in data_loader:\n",
        "          y.append((labels).cpu().numpy())\n",
        "          y_hat.append(torch.nn.Softmax(dim=1)( model(inputs.cuda()))[:,1].detach().cpu().numpy()) # take the probability for cancer\n",
        "    y = np.concatenate( y, axis=0 )\n",
        "    y_hat = np.concatenate( y_hat, axis=0 )\n",
        "    return y, y_hat \n",
        "\n",
        "def get_auc_f1(model, dataset,fname = None, ):\n",
        "    if fname !=None:\n",
        "        with open(fname, 'rb') as f:\n",
        "            weights = torch.load(f)\n",
        "        if \"classifier.0.weight\" in weights.keys(): #for the gradient models we unfortunately saved all of the weights\n",
        "            model.load_state_dict(weights)\n",
        "        else:\n",
        "            model.classifier.load_state_dict(weights)\n",
        "        y, y_hat = get_output(model.classifier, dataset)\n",
        "    else:   \n",
        "        y, y_hat = get_output(model, dataset)\n",
        "    auc = roc_auc_score(y, y_hat)\n",
        "    f1 = np.asarray([f1_score(y, y_hat > x) for x in np.linspace(0.1,1, num = 10) if (y_hat >x).any() and (y_hat<x).any()]).max()\n",
        "    return auc, f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8Tt_ZTaOwpl"
      },
      "source": [
        "### Load Data\n",
        "Load dataset from file to test effect of altering the patches.\n",
        "The dataset has subsequently been saved as a tensor so it is quicker to read it in from this format. This section can be skipped."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWzl2-I9PFRz"
      },
      "source": [
        "##### Functions to read the various datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lACRR7DH12Pi"
      },
      "source": [
        "def load_folder(path):\n",
        "    list_files= os.listdir(path)\n",
        "    num_files = min([2000, len(list_files)])\n",
        "    imgs_np = np.empty((num_files,  299, 299,3))\n",
        "    for i in tqdm(range(num_files)): \n",
        "        try:\n",
        "            img = Image.open(oj(path, list_files[i]))\n",
        "            imgs_np[i-num_files] = np.asarray(img)/255.0\n",
        "            \n",
        "            img.close()\n",
        "        except:\n",
        "            print(i)\n",
        "    return imgs_np\n",
        "\n",
        "def load_other_benign(path):\n",
        "    list_files= os.listdir(path)\n",
        "    num_files = min([2000, len(list_files)])\n",
        "    imgs_np = np.empty((num_files,  299, 299,3))\n",
        "    for i in tqdm(range(num_files, num_files+num_files)):   \n",
        "        try:\n",
        "            img = Image.open(oj(path, list_files[i]))\n",
        "            imgs_np[i-num_files] = np.asarray(img)/255.0\n",
        "            \n",
        "            img.close()\n",
        "        except:\n",
        "            print(i)\n",
        "    return imgs_np\n",
        "\n",
        "def load_seg(path, orig_path):\n",
        "    list_files= os.listdir(orig_path)\n",
        "    num_files = min([2000, len(list_files)])\n",
        "    imgs_np = np.zeros((num_files,  299, 299), dtype = np.bool)\n",
        "    for i in tqdm(range(num_files, num_files+num_files)):\n",
        "        if os.path.isfile(oj(path,  list_files[i])):\n",
        "            img = Image.open(oj(path, list_files[i]))\n",
        "            imgs_np[i-num_files] = np.asarray(img)[:,:,0] > 100\n",
        "            img.close()\n",
        "    return imgs_np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhDv9IKePKQv"
      },
      "source": [
        "##### Load the cancer images and create a Tensor dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdqJL6uE2bpW"
      },
      "source": [
        "cancer_set = load_folder(cancer_path)\n",
        "cancer_set -= mean[None, None, :]\n",
        "cancer_set /= std[None, None, :]\n",
        "\n",
        "cancer_targets = np.ones((cancer_set.shape[0])).astype(np.int64)\n",
        "\n",
        "cancer_dataset = TensorDataset(torch.from_numpy(cancer_set.swapaxes(1,3).swapaxes(2,2)).float(), torch.from_numpy(cancer_targets),torch.from_numpy(np.zeros((len(cancer_set), 299, 299), dtype = np.bool)))\n",
        "del cancer_set\n",
        "\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJHhAhMePRH1"
      },
      "source": [
        "##### Load the non-cancer dataset and patch segmentations and create a Tensor dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3iClE6O2emh"
      },
      "source": [
        "not_cancer_set = load_other_benign(not_cancer_path)\n",
        "not_cancer_set -= mean[None, None, :]\n",
        "not_cancer_set /= std[None, None, :]\n",
        "seg_set = load_seg(seg_path, not_cancer_path)\n",
        "\n",
        "not_cancer_targets = np.zeros((not_cancer_set.shape[0])).astype(np.int64)\n",
        "\n",
        "not_cancer_dataset = TensorDataset(torch.from_numpy(not_cancer_set.swapaxes(1,3).swapaxes(2,3)).float(), torch.from_numpy(not_cancer_targets),torch.from_numpy(seg_set))\n",
        "\n",
        "del not_cancer_set\n",
        "del seg_set\n",
        "\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4VWHiLRplTf"
      },
      "source": [
        "##### Save the tensor datasets for speed of reading the next time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xey67V1DD6f7"
      },
      "source": [
        "torch.save(cancer_dataset, oj(data_path, 'saved-tensors', 'cancer_dataset_0_196.pt'))\n",
        "torch.save(not_cancer_dataset, oj(data_path, 'saved-tensors', 'not_cancer_dataset_2000_3999.pt'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4xlrAkoPk1L"
      },
      "source": [
        "### Load Tensor Datasets\n",
        "The data from the previous section has been previously saved as tensor datasets for speed of loading."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fji-9iv3pkau"
      },
      "source": [
        "# cancer_dataset = torch.load(oj(data_path, 'saved-tensors', 'cancer_dataset_0_196.pt'))\n",
        "not_cancer_dataset = torch.load(oj(data_path, 'saved-tensors', 'not_cancer_dataset_2000_3999.pt'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aahRNQpxFqqH"
      },
      "source": [
        "### Load Model\n",
        "Model has been trained on the first 2,000 non-cancer images and the 196 cancer images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dz6fsFF2BLwS"
      },
      "source": [
        "# Get a list of the models in the directory and their modified times \n",
        "model_list = [(f, os.path.getmtime(oj(dir_path,model_path,f))) for f in os.listdir(oj(dir_path, model_path)) if f.endswith('.pt')]\n",
        "model_list.sort(key=lambda tup: tup[1], reverse=True)  # sorts in place from most to least recent.\n",
        "\n",
        "model_name = model_list[0][0]  # Take the most recent model.\n",
        "\n",
        "model_dict = torch.load(oj(dir_path, model_path, model_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlGpWoNtNb7V"
      },
      "source": [
        "model = models.vgg16(pretrained=True)\n",
        "\n",
        "model.classifier[-1] = nn.Linear(4096, 2)\n",
        "\n",
        "model.classifier.load_state_dict(model_dict)\n",
        "\n",
        "device = torch.device(0)\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAIu3hZNF3ao"
      },
      "source": [
        "Free up space (model file is approx. 0.5GB)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "te1Hid3yOqp0"
      },
      "source": [
        "del model_dict, model_list\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4-g4xKnJ1bt"
      },
      "source": [
        "##### Get and save predictions for the original images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4w63DO23OWsw"
      },
      "source": [
        "has_patch = [torch.max(seg) for im, label, seg in not_cancer_dataset]\n",
        "patch_idx = [i for i in range(len(not_cancer_dataset)) if has_patch[i]]\n",
        "\n",
        "dataset_with_patches = torch.utils.data.Subset(not_cancer_dataset, patch_idx)\n",
        "\n",
        "preds_not_cancer = get_output(model, dataset_with_patches)\n",
        "\n",
        "# np.save(oj(data_path, 'saved-tensors', 'not_cancer_preds_patches_2000_3999.npy'), preds_not_cancer[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h94MKdVGwp8-"
      },
      "source": [
        "np.save(oj(data_path, 'saved-tensors', 'not_cancer_preds_patches_2000_3999.npy'), preds_not_cancer[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYqwJvFkJ81N"
      },
      "source": [
        "### Alter the images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7jnbMBM5Tsa"
      },
      "source": [
        "##### **Update the images based on the segmentation mask.**\n",
        "Loop through each element to update the image part.\n",
        "\n",
        "Want to set the location of the patches to be zero, but the data is standardised so in fact we want to set it to -mean/std.\n",
        "\n",
        "First get (~seg)*im to take the original image values in all locations except  the patch locations where it will be zero. \n",
        "\n",
        "Then update these patch locations by the 'shifted zero'. The resulting image should be three-dimensional so the inputs need to reshaped here to achieve this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNEMRz6ey9si"
      },
      "source": [
        "def replace_patch(dataset, replacement_val):\n",
        "  \"\"\" Function to replace the patches with a specific colour.\n",
        "    dataset           -     Dataset containing images, labels, segmentation_masks\n",
        "    replacement_val   -     The RGB value expressed as 1D array with length=3, where the values are floats between 0 and 1.\n",
        "  Returns:\n",
        "    updated_ims, labels, seg      (type: lists) Where the updated_ims are the altered images but the labels and segmentation are unchanged from the original.\n",
        "  \"\"\"\n",
        "  shifted_val = (replacement_val-mean)/std    # The image data has been standardised - this is the value zero is shifted to. One value for each RGB channel.\n",
        "\n",
        "  # Get the updated image based on the segmentation mask.\n",
        "  updated_ims = [ ((~seg)*im + (seg.reshape(1,299,299) * shifted_val[:,None,None])).float()\n",
        "                          for im, label, seg in dataset]\n",
        "  labels = [label for _, label, _ in dataset]\n",
        "  segs = [seg for _,_,seg in dataset]\n",
        "\n",
        "  return updated_ims, labels, segs\n",
        "\n",
        "\n",
        "# altered_ims_black, labels, segs  =   replace_patch(not_cancer_dataset, np.array([0,0,0]))\n",
        "altered_ims_white,labels, segs       =   replace_patch(not_cancer_dataset, np.array([1,1,1]))\n",
        "# altered_ims_grey, _, _          =   replace_patch(not_cancer_dataset, np.array([169/255, 169/255, 169/255]))     # Use RGB colour for 'darkgrey (SVG)'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2XdA-MGBGza"
      },
      "source": [
        "# Free up memory\n",
        "del not_cancer_dataset\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfVoJvrKd_Nz"
      },
      "source": [
        "plot_lesion(altered_ims_white, 0)   # Show example image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtOybddTWPpT"
      },
      "source": [
        "np.uint8(seg[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kA9wAyh4U6xC"
      },
      "source": [
        "##### Save/Reload altered images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pO_0Jo1JT2Sy"
      },
      "source": [
        "## ------------------------------\n",
        "## Save data in case of RAM crash.\n",
        "\n",
        "with open(oj(data_path, 'saved-tensors', 'altered_ims_white.pkl'), 'wb') as f:\n",
        "  pkl.dump(altered_ims_white, f)\n",
        "\n",
        "# with open(oj(data_path, 'saved-tensors', 'labels.pkl'), 'wb') as f:\n",
        "#   pkl.dump(labels, f)  \n",
        "\n",
        "# with open(oj(data_path, 'saved-tensors', 'segs.pkl'), 'wb') as f:\n",
        "#   pkl.dump(segs, f)  \n",
        "\n",
        "## ------------------------------\n",
        "## Load previously saved data.\n",
        "\n",
        "# with open(oj(data_path, 'saved-tensors', 'altered_ims_white.pkl'), 'rb') as f:\n",
        "#   altered_ims_white = pkl.load(f)\n",
        "\n",
        "# with open(oj(data_path, 'saved-tensors', 'labels.pkl'), 'rb') as f:\n",
        "#   labels = pkl.load(f)  \n",
        "\n",
        "# with open(oj(data_path, 'saved-tensors', 'segs.pkl'), 'rb') as f:\n",
        "#   segs = pkl.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_o2NO9tlU-0R"
      },
      "source": [
        "##### Create Tensor Dataset for altered data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKgUMQCe-Flw"
      },
      "source": [
        "not_cancer_altered = TensorDataset(torch.stack(altered_ims_white), torch.stack(labels), torch.stack(labels))\n",
        "\n",
        "# del altered_ims_white, labels, segs\n",
        "# gc.collect()\n",
        "\n",
        "# torch.save(not_cancer_altered, oj(data_path, 'saved-tensors', 'not_cancer_altered_white_2000_3999.pt'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vx9vzPSMxfF"
      },
      "source": [
        "##### Get predicted probabilities for the altered dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4SJuv0SaDTy"
      },
      "source": [
        "labels, preds_altered = get_output(model, not_cancer_altered)\n",
        "\n",
        "# np.save(oj(data_path, 'saved-tensors', 'not_cancer_preds_altered_white_2000_3999.npy'), preds_altered)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unRNr7TiK3IQ"
      },
      "source": [
        "##### Reload previously saved predicted probabilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0iX2g1jaasT"
      },
      "source": [
        "# preds_not_cancer  = np.load(oj(data_path, 'saved-tensors', 'not_cancer_preds_2000_3999.npy'))\n",
        "# preds_altered     = np.load(oj(data_path, 'saved-tensors', 'not_cancer_preds_altered_2000_3999.npy'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpg2KEsjLGUe"
      },
      "source": [
        "##### Compare probabilities for original and altered images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dviXLF3parww"
      },
      "source": [
        "def plot_compare_probs(probs_original, probs_altered, output_dir = oj(dir_path, 'plots'), output_add = None):\n",
        "  \"\"\" Plots and saves three plots to compare the predicted probabilities before & after altering the images.\n",
        "  Input: \n",
        "    probs_original, probs_altered     The output probabilities of the classification model for the original & altered image, as a Tensor, numpy array or list.\n",
        "    output_dir                        The path to the directory for saving the plots.\n",
        "    output_add                        An ID to add to the output filename. If left blank, then a random 10 digit ID is created.\n",
        "  Returns:\n",
        "    None    The three plots are saved to the relevant directory and also printed to screen.\n",
        "  \"\"\"\n",
        "  if output_add is None:\n",
        "    output_add = ''.join([\"%s\" % randint(0, 9) for num in range(0, 10)]) # Create a random ID to avoid overwriting previous files.\n",
        "\n",
        "  ## Plot Histogram Comparison\n",
        "  fig, ax = plt.subplots(2, 1, figsize = (10,8))\n",
        "\n",
        "  ax[0].hist(probs_original)\n",
        "  ax[0].set_title('Original')\n",
        "  ax[0].set_xlabel('Predicted Probability')\n",
        "  ax[0].set_ylabel('Number of Samples')\n",
        "  ax[1].hist(probs_altered)\n",
        "  ax[1].set_title('Patches Altered')\n",
        "  ax[1].set_xlabel('Predicted Probability')\n",
        "  ax[1].set_ylabel('Number of Samples')\n",
        "\n",
        "  fig.suptitle('Predicted Probabilities Before & After Altering Patches', fontsize=16)\n",
        "  fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "\n",
        "  fig.savefig(oj(output_dir, 'Probs Comparison Hist ' + output_add + '.png'))\n",
        "  plt.show()\n",
        "\n",
        "  ## Plot Scatterplot Comparison.\n",
        "  fig, ax = plt.subplots(1, 1, figsize = (8,8))\n",
        "\n",
        "  ax.scatter(probs_original, probs_altered, alpha=0.4)\n",
        "  ax.set_xlabel('Original', fontsize=12)\n",
        "  ax.set_ylabel('Altered',fontsize=12)\n",
        "  ax.set_title('Predicted Probs for Original Images & After Altering Patches', fontsize=16)\n",
        "\n",
        "  fig.savefig(oj(output_dir, 'Probs Comparison Scatter ' + output_add + '.png'))\n",
        "  plt.show()\n",
        "\n",
        "  ## Calculate differences and plot histogram\n",
        "  diff_preds = probs_altered - probs_original\n",
        "\n",
        "  fig, ax = plt.subplots(1, 1, figsize = (8,8))\n",
        "\n",
        "  hist_range = (-max(abs(diff_preds)), max(abs(diff_preds)))  # Make sure histogram is symmetric about zero.\n",
        "\n",
        "  ax.hist(diff_preds, range = hist_range, bins = 20)\n",
        "  ax.set_title('Histogram of differences in predicted probs after altering patches', fontsize=16)\n",
        "  ax.set_ylabel('Number of Samples')\n",
        "  ax.set_xlabel('Difference in Predicted Probability')\n",
        "\n",
        "  fig.savefig(oj(output_dir, 'Diff in Predicted Probs Hist ' + output_add + '.png'))\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tngdvqrmbBNU"
      },
      "source": [
        "plot_compare_probs(preds_not_cancer, preds_altered,output_add='(white)')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}