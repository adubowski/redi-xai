{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "compare_predictions.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNYm+y9SebgghKduKd+iVpP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adubowski/redi-xai/blob/main/classifier/compare_predictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64bch0TWEsDk"
      },
      "source": [
        "### Load Libraries and Initialise Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMz4DOxe1vmt"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset\n",
        "from torchvision import models\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from numpy.random import randint\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "from os.path import join as oj\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "\n",
        "from sklearn.metrics import recall_score\n",
        "from matplotlib import pyplot as plt\n",
        "plt.style.use('seaborn')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkxsW7a3E8y3"
      },
      "source": [
        "##### Mount Google Drive and create & store various directory paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqPXREGv11NT"
      },
      "source": [
        "drive.mount(\"/content/drive\")\n",
        "dir_path = \"/content/drive/MyDrive/redi-detecting-cheating\"\n",
        "\n",
        "model_path = oj(dir_path, \"models\", \"initial_classifier\")\n",
        "data_path = oj(dir_path, \"data\")\n",
        "\n",
        "test_path             = oj(dir_path, \"models\", \"test_files_224.txt\")\n",
        "test_path_patches     = oj(dir_path, \"data\", \"test\", \"inpainted_patches\")\n",
        "test_path_no_patches  = oj(dir_path, \"data\", \"test\", \"inpainted_no_patches\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3sHfoIqOknh"
      },
      "source": [
        "##### Parameters for standardising the data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9b0CGyQOiJJ"
      },
      "source": [
        "mean = np.asarray([0.485, 0.456, 0.406]) \n",
        "std = np.asarray([0.229, 0.224, 0.225])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JZLeFtVIuz7"
      },
      "source": [
        "##### Function to plot individual image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oh6dgnfIt-V"
      },
      "source": [
        "def plot_lesion(dataset, idx):\n",
        "  \"\"\" \n",
        "  Input:    dataset   -   Tensor dataset of images. Contained in each element of the dataset is the image and label\n",
        "            idx       -   The image index to plot.\n",
        "  Returns:  None      -   Plots the original lesion image to screen.\n",
        "  \"\"\"\n",
        "  plt.style.use('default')   # Reset the style to avoid plotting axes on the plot.\n",
        "\n",
        "  # The axes have been swapped in the tensor dataset so that the colour channels are the first axis. Undo this with permute().\n",
        "  # The image has been standardised, so multiply by the std and add to the mean to reverse this.\n",
        "  orig_img = datalist[idx].permute(1, 2, 0).numpy()*std + mean\n",
        "  plt.imshow(orig_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8Tt_ZTaOwpl"
      },
      "source": [
        "### Load Data\n",
        "Load dataset from file to test effect of altering the patches.\n",
        "The dataset has subsequently been saved as a tensor so it is quicker to read it in from this format. This section can be skipped."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWzl2-I9PFRz"
      },
      "source": [
        "##### Function to read the relevant files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lACRR7DH12Pi"
      },
      "source": [
        "def extract_filenames(dataset_path):\n",
        "  \"\"\" Extracts the paths, names and root directory for the image files in a given directory \n",
        "          or given a file containing image filepaths.\n",
        "      Returns:\n",
        "        filenames     filenames sorted alphabetically\n",
        "        file_list     if dataset_path is a directory, then file_list is equivalent to filenames. \n",
        "                      If dataset_path is a file containing filepaths, then file_list is a list of these paths. \n",
        "        root_dir      If dataset_path is a directory, then root_dir=dataset_path, otherwise root_dir=''.\n",
        "  \"\"\"\n",
        "  if os.path.isfile(dataset_path):\n",
        "    file_list = open(dataset_path, 'rt').read().splitlines()\n",
        "    filenames = [os.path.basename(file) for file in file_list] # Extract the filename from the full filepath.\n",
        "    root_dir = ''\n",
        "  elif os.path.isdir(dataset_path):\n",
        "    file_list = os.listdir(dataset_path)\n",
        "    filenames = file_list\n",
        "    root_dir = dataset_path\n",
        "  else:\n",
        "    print('Invalid testing data file/folder path.')\n",
        "    exit(1)\n",
        "\n",
        "  # Sort alphabetically based on the filename.\n",
        "  zip_sorted = sorted(zip(filenames, file_list), key=lambda tup: tup[0])\n",
        "\n",
        "  filenames, file_list = zip(*zip_sorted)   # Unzip the sorted results.\n",
        "\n",
        "  return filenames, file_list, root_dir\n",
        "\n",
        "\n",
        "def load_files(dataset_path, imsize = (224,224)):\n",
        "  \"\"\" filelist should be either a text file containing the full paths of the relevant image files,\n",
        "         or a path to the directory containing the images.\n",
        "      Returns the images as a numpy array with float values between 0 and 1.\"\"\"\n",
        "  filenames, file_list, root_dir = extract_filenames(dataset_path)\n",
        "\n",
        "  num_files = len(file_list)\n",
        "  imgs_np = np.empty((num_files,  imsize[0], imsize[1], 3))\n",
        "  for i in tqdm(range(num_files)): \n",
        "    try:\n",
        "      img = Image.open(oj(root_dir, file_list[i]))\n",
        "      imgs_np[i] = np.asarray(img)/255.0              # Transform to float between 0 and 1 from integer between 0-255\n",
        "\n",
        "      img.close()\n",
        "    except:\n",
        "      print(i)\n",
        "  return imgs_np, filenames\n",
        "\n",
        "\n",
        "def get_dataset(dataset_path, save_path, imsize = (224,224)):\n",
        "  if os.path.isfile(save_path):        # If the dataset has previously been saved as a tensor, load this for efficiency.\n",
        "    dataset = torch.load(save_path)\n",
        "\n",
        "    filenames, _,_ = extract_filenames(dataset_path)   # Get the associated image filenames.\n",
        "  \n",
        "  else:\n",
        "    ims, filenames = load_files(dataset_path, imsize)   # Load in all of the images.\n",
        "\n",
        "    ims -= mean[None, None, :]    # Standardise the images as expected by the VGG16 model.\n",
        "    ims /= std[None, None, :]\n",
        "\n",
        "    # Check if the image comes from the 'no_cancer' directory or the 'cancer' directory. Cancer images have target=1.\n",
        "    targets = [0 if \"no_cancer\" in file else 1 for file in filenames]  \n",
        "    targets = np.array(targets).astype(np.int8)\n",
        "\n",
        "    # Create a tensor dataset with the images and targets.\n",
        "    dataset = TensorDataset(torch.from_numpy(ims.swapaxes(1,3).swapaxes(2,2)).float(), torch.from_numpy(targets))\n",
        "\n",
        "    torch.save(dataset, save_path)    # save for more efficient loading the next time.\n",
        "\n",
        "  return dataset, filenames    # Return the TensorDataset and list of image filenames"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmZlPAASWkMg"
      },
      "source": [
        "##### Read the test datasets.\n",
        "Or if they have been previously been saved as a tensor dataset then load these for efficiency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUeKpcKYCmIh"
      },
      "source": [
        "test_dataset, test_files                    = get_dataset(test_path, oj(data_path, 'saved-tensors', 'test_dataset.pt'))\n",
        "\n",
        "inpainted_patch_dataset, patch_files        = get_dataset(test_path_patches, oj(data_path, 'saved-tensors', 'inpainted_patch_dataset.pt'))\n",
        "inpainted_no_patch_dataset, no_patch_files  = get_dataset(test_path_no_patches, oj(data_path, 'saved-tensors', 'inpainted_no_patch_dataset.pt'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aahRNQpxFqqH"
      },
      "source": [
        "### Load Model\n",
        "Take the most recent trained classifier. The weights of the classification section of the model have been saved, and the weights of the feature extraction part are taken from the original pretrained VGG16 model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dz6fsFF2BLwS"
      },
      "source": [
        "# Get a list of the models in the directory and their modified times \n",
        "model_list = [(f, os.path.getmtime(oj(model_path,f))) for f in os.listdir(model_path) if f.endswith('.pt')]\n",
        "model_list.sort(key=lambda tup: tup[1], reverse=True)  # sorts in place from most to least recent.\n",
        "\n",
        "model_name = model_list[0][0]                       # Take the most recent model.\n",
        "\n",
        "model_dict = torch.load(oj(model_path, model_name)) # Read the paramater dict from file.\n",
        "\n",
        "model = models.vgg16(pretrained=True)               # Read in the original VGG16 pretrained model.\n",
        "model.classifier[-1] = torch.nn.Linear(4096, 2)           # Set the final classification layer to have only 2 output nodes.\n",
        "\n",
        "model.classifier.load_state_dict(model_dict)        # Use the saved model parameters.\n",
        "\n",
        "device = torch.device(0)\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAIu3hZNF3ao"
      },
      "source": [
        "Free up space (model file is approx. 0.5GB)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "te1Hid3yOqp0"
      },
      "source": [
        "del model_dict, model_list\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4-g4xKnJ1bt"
      },
      "source": [
        "##### Get and save predictions for the original images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbhLHxUFJBED"
      },
      "source": [
        "from sklearn.metrics import auc, roc_auc_score, f1_score\n",
        "\n",
        "def get_output(model, dataset):\n",
        "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=16,\n",
        "                                             shuffle=False, num_workers=4)\n",
        "    model = model.eval()\n",
        "    y = []\n",
        "    y_hat = []\n",
        "    softmax= torch.nn.Softmax()\n",
        "    with torch.no_grad() :\n",
        "        for inputs, labels in data_loader:\n",
        "          y.append((labels).cpu().numpy())\n",
        "          y_hat.append(torch.nn.Softmax(dim=1)( model(inputs.cuda()))[:,1].detach().cpu().numpy()) # take the probability for cancer\n",
        "    y = np.concatenate( y, axis=0 )\n",
        "    y_hat = np.concatenate( y_hat, axis=0 )\n",
        "    return y, y_hat \n",
        "\n",
        "def get_auc_f1(model, dataset,fname = None, ):\n",
        "    if fname !=None:\n",
        "        with open(fname, 'rb') as f:\n",
        "            weights = torch.load(f)\n",
        "        if \"classifier.0.weight\" in weights.keys():\n",
        "            model.load_state_dict(weights)\n",
        "        else:\n",
        "            model.classifier.load_state_dict(weights)\n",
        "        y, y_hat = get_output(model.classifier, dataset)\n",
        "    else:   \n",
        "        y, y_hat = get_output(model, dataset)\n",
        "    auc = roc_auc_score(y, y_hat)\n",
        "    f1 = np.asarray([f1_score(y, y_hat > x) for x in np.linspace(0.1,1, num = 10) if (y_hat >x).any() and (y_hat<x).any()]).max()\n",
        "    return auc, f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0qsxpHGZCEQ"
      },
      "source": [
        "preds_test_unaltered, targets_test_unaltered = get_output(model, test_dataset)\n",
        "# np.savez(oj(data_path, 'saved-tensors', 'preds_test_unaltered.npz'), test_targets=targets_test_unaltered, test_preds=preds_test_unaltered)\n",
        "\n",
        "preds_inpainted_patches, targets_inpainted_patches = get_output(model, inpainted_patch_dataset)\n",
        "# np.savez(oj(data_path, 'saved-tensors', 'preds_inpainted_patches.npz'), test_targets=targets_inpainted_patches, test_preds=preds_inpainted_patches)\n",
        "\n",
        "preds_inpainted_no_patches, targets_inpainted_no_patches = get_output(model, inpainted_no_patch_dataset)\n",
        "# np.savez(oj(data_path, 'saved-tensors', 'preds_inpainted_no_patches.npz'), test_targets=targets_inpainted_no_patches, test_preds=preds_inpainted_no_patches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpg2KEsjLGUe"
      },
      "source": [
        "#### Compare probabilities for original and altered images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dviXLF3parww"
      },
      "source": [
        "def plot_compare_probs(probs_original, probs_altered, output_dir = oj(dir_path, 'plots'), output_add = None):\n",
        "  \"\"\" Plots and saves three plots to compare the predicted probabilities before & after altering the images.\n",
        "  Input: \n",
        "    probs_original, probs_altered     The output probabilities of the classification model for the original & altered image, as a Tensor, numpy array or list.\n",
        "    output_dir                        The path to the directory for saving the plots.\n",
        "    output_add                        An ID to add to the output filename. If left blank, then a random 10 digit ID is created.\n",
        "  Returns:\n",
        "    None    The three plots are saved to the relevant directory and also printed to screen.\n",
        "  \"\"\"\n",
        "  if output_add is None:\n",
        "    output_add = ''.join([\"%s\" % randint(0, 9) for num in range(0, 10)]) # Create a random ID to avoid overwriting previous files.\n",
        "\n",
        "  ## Plot Histogram Comparison\n",
        "  fig, ax = plt.subplots(2, 1, figsize = (10,8))\n",
        "\n",
        "  ax[0].hist(probs_original)\n",
        "  ax[0].set_title('Original')\n",
        "  ax[0].set_xlabel('Predicted Probability')\n",
        "  ax[0].set_ylabel('Number of Samples')\n",
        "  ax[1].hist(probs_altered)\n",
        "  ax[1].set_title('Patches Altered')\n",
        "  ax[1].set_xlabel('Predicted Probability')\n",
        "  ax[1].set_ylabel('Number of Samples')\n",
        "\n",
        "  fig.suptitle('Predicted Probabilities Before & After Altering Patches', fontsize=16)\n",
        "  fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "\n",
        "  fig.savefig(oj(output_dir, 'Probs Comparison Hist ' + output_add + '.png'))\n",
        "  plt.show()\n",
        "\n",
        "  ## Plot Scatterplot Comparison.\n",
        "  fig, ax = plt.subplots(1, 1, figsize = (8,8))\n",
        "\n",
        "  ax.scatter(probs_original, probs_altered, alpha=0.4)\n",
        "  ax.set_xlabel('Original', fontsize=12)\n",
        "  ax.set_ylabel('Altered',fontsize=12)\n",
        "  ax.set_title('Predicted Probs for Original Images & After Altering Patches', fontsize=16)\n",
        "\n",
        "  fig.savefig(oj(output_dir, 'Probs Comparison Scatter ' + output_add + '.png'))\n",
        "  plt.show()\n",
        "\n",
        "  ## Calculate differences and plot histogram\n",
        "  diff_preds = probs_altered - probs_original\n",
        "\n",
        "  fig, ax = plt.subplots(1, 1, figsize = (8,8))\n",
        "\n",
        "  hist_range = (-max(abs(diff_preds)), max(abs(diff_preds)))  # Make sure histogram is symmetric about zero.\n",
        "\n",
        "  ax.hist(diff_preds, range = hist_range, bins = 20)\n",
        "  ax.set_title('Histogram of differences in predicted probs after altering patches', fontsize=16)\n",
        "  ax.set_ylabel('Number of Samples')\n",
        "  ax.set_xlabel('Difference in Predicted Probability')\n",
        "\n",
        "  fig.savefig(oj(output_dir, 'Diff in Predicted Probs Hist ' + output_add + '.png'))\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GY-6ih8-4F-"
      },
      "source": [
        "##### Get results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlZTHkRczZcW"
      },
      "source": [
        "patch_ind = [file in patch_files for file in test_filenames]   # Get a boolean list of whether the test file has a patch.\n",
        "\n",
        "# Compare the outputs for the inpainted images vs. the originals.\n",
        "plot_compare_probs(preds_test_unaltered[patch_ind], preds_inpainted_patches, output_add='(inpainted patches)')\n",
        "plot_compare_probs(preds_test_unaltered[~patch_ind], preds_inpainted_no_patches, output_add='(inpainted no patches)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tngdvqrmbBNU"
      },
      "source": [
        "print(\"Specificity for images with patches is: {:.2f}\".format( \\\n",
        "    recall_score(preds_test_unaltered[patch_ind] > 0.5, targets_test_unaltered[patch_ind], pos_label=0))\n",
        "\n",
        "print(\"Specificity for images without a patch is:\\t {:.2f}\".format( \\\n",
        "    recall_score(preds_test_unaltered[~patch_ind] > 0.5, targets_test_unaltered[~patch_ind], pos_label=0))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}