{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPyfuipRdXQ5rdne4lhPG3F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "97c56a3cacb7418d8145010cad62fc62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b978638af2994e15a3b4d144c607f586",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_216d1fe6fe3845f0973a9bf9ae010872",
              "IPY_MODEL_044f706a1208494cb3421672187ea9a2"
            ]
          }
        },
        "b978638af2994e15a3b4d144c607f586": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "216d1fe6fe3845f0973a9bf9ae010872": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1e43adf7874a4d0781b2b4aa39322909",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 553433881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 553433881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c12aeb2963d9481eb634804a9ed6611e"
          }
        },
        "044f706a1208494cb3421672187ea9a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d8c9a75d485c4a55870cbf1ac8cfa85a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 528M/528M [01:25&lt;00:00, 6.48MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_86b5584c4e044b00a334e53535e019a4"
          }
        },
        "1e43adf7874a4d0781b2b4aa39322909": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c12aeb2963d9481eb634804a9ed6611e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d8c9a75d485c4a55870cbf1ac8cfa85a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "86b5584c4e044b00a334e53535e019a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adubowski/redi-xai/blob/main/classifier/train_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFzu7KlCR4Pt"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "import torch\n",
        "import sys\n",
        "import numpy as np\n",
        "import pickle as pkl\n",
        "from os.path import join as oj\n",
        "\n",
        "import torch.optim as optim\n",
        "import os\n",
        "from torch.utils.data import TensorDataset, ConcatDataset\n",
        "import argparse\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from torch import nn\n",
        "from numpy.random import randint\n",
        "import torchvision.models as models\n",
        "import time\n",
        "import copy\n",
        "import gc\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ginv9jtpuO2V"
      },
      "source": [
        "### Mount Google Drive and create paths for directories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrTOXk0lSC8F",
        "outputId": "e91025bf-bdef-417e-8aa4-743332fae553"
      },
      "source": [
        "drive.mount(\"/content/drive\")\n",
        "dir_path = \"/content/drive/MyDrive/redi-detecting-cheating\"\n",
        "\n",
        "with open(oj(dir_path, 'config.json')) as json_file:\n",
        "    data = json.load(json_file)\n",
        "\n",
        "model_path = oj(dir_path, data[\"model_folder\"], \"initial_classifier\")\n",
        "data_path = oj(dir_path, data[\"data_folder\"])\n",
        "\n",
        "seg_path  = oj(data_path, \"patch-segmentation\")\n",
        "not_cancer_path = oj(data_path, \"processed/no_cancer\")\n",
        "cancer_path = oj(data_path, \"processed/cancer\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDKlrNh3ucu2"
      },
      "source": [
        "#### Arguments for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEo0TcCMUXXo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82,
          "referenced_widgets": [
            "97c56a3cacb7418d8145010cad62fc62",
            "b978638af2994e15a3b4d144c607f586",
            "216d1fe6fe3845f0973a9bf9ae010872",
            "044f706a1208494cb3421672187ea9a2",
            "1e43adf7874a4d0781b2b4aa39322909",
            "c12aeb2963d9481eb634804a9ed6611e",
            "d8c9a75d485c4a55870cbf1ac8cfa85a",
            "86b5584c4e044b00a334e53535e019a4"
          ]
        },
        "outputId": "ed4de167-bb5c-49c8-8b7d-486f1ad43cb0"
      },
      "source": [
        "mean = np.asarray([0.485, 0.456, 0.406])\n",
        "std = np.asarray([0.229, 0.224, 0.225])\n",
        "\n",
        "# Training settings\n",
        "parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
        "parser.add_argument('--batch_size', type=int, default=16, metavar='N',\n",
        "                    help='input batch size for training (default: 64)')\n",
        "\n",
        "parser.add_argument('--epochs', type=int, default=5, metavar='N',\n",
        "                    help='number of epochs to train (default: 10)')\n",
        "parser.add_argument('--lr', type=float, default=0.00001, metavar='LR',\n",
        "                    help='learning rate needs to be extremely small, otherwise loss nans (default: 0.00001)')\n",
        "parser.add_argument('--momentum', type=float, default=0.9, metavar='M',\n",
        "                    help='SGD momentum (default: 0.5)')\n",
        "parser.add_argument('--seed', type=int, default=42, metavar='S',\n",
        "                    help='random seed (default: 42)')\n",
        "parser.add_argument('--regularizer_rate', type=float, default=0.0, metavar='N',\n",
        "                    help='hyperparameter for CDEP weight - higher means more regularization')\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "regularizer_rate = args.regularizer_rate\n",
        "\n",
        "num_epochs = args.epochs\n",
        "\n",
        "device = torch.device(0)\n",
        "\n",
        "torch.manual_seed(args.seed);\n",
        "model = models.vgg16(pretrained=True)\n",
        "\n",
        "model.classifier[-1] = nn.Linear(4096, 2)\n",
        "model = model.to(device)\n",
        "params_to_update = model.classifier.parameters()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "97c56a3cacb7418d8145010cad62fc62",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=553433881.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNqLnCkUugEZ"
      },
      "source": [
        "#### Functions for reading in the image files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1RZ5_CFZSqF"
      },
      "source": [
        "def load_folder(path):\n",
        "    list_files= os.listdir(path)\n",
        "    num_files = min([2000, len(list_files)])\n",
        "    imgs_np = np.empty((num_files,  299, 299,3))\n",
        "    for i in tqdm(range(num_files)):    # Take a max of 100 for purposes of testing the code.\n",
        "        try:\n",
        "            img = Image.open(oj(path, list_files[i]))\n",
        "            imgs_np[i] = np.asarray(img)/255.0\n",
        "            \n",
        "            img.close()\n",
        "        except:\n",
        "            print(i)\n",
        "    return imgs_np\n",
        "\n",
        "def load_seg(path, orig_path):\n",
        "    list_files= os.listdir(orig_path)\n",
        "    num_files = min([2000, len(list_files)])\n",
        "    imgs_np = np.zeros((num_files,  299, 299), dtype = np.bool)\n",
        "    for i in tqdm(range(num_files)):\n",
        "        if os.path.isfile(oj(path,  list_files[i])):\n",
        "            img = Image.open(oj(path, list_files[i]))\n",
        "            imgs_np[i] = np.asarray(img)[:,:,0] > 100\n",
        "            img.close()\n",
        "    return imgs_np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6S6Ilm0xulka"
      },
      "source": [
        "#### Read in the malignant images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NfhilqzbFw1",
        "outputId": "51577264-9971-4f65-ad35-6ba5261448ba"
      },
      "source": [
        "cancer_set = load_folder(cancer_path)\n",
        "cancer_set -= mean[None, None, :]\n",
        "cancer_set /= std[None, None, :]\n",
        "\n",
        "cancer_targets = np.ones((cancer_set.shape[0])).astype(np.int64)\n",
        "\n",
        "cancer_dataset = TensorDataset(torch.from_numpy(cancer_set.swapaxes(1,3).swapaxes(2,2)).float(), torch.from_numpy(cancer_targets),torch.from_numpy(np.zeros((len(cancer_set), 299, 299), dtype = np.bool)))\n",
        "del cancer_set\n",
        "\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [00:48<00:00,  4.00it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zvb_gjDruphc"
      },
      "source": [
        "#### Read in the benign images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmFCxXF6Od8n",
        "outputId": "5e098f1f-cbfb-4436-8c3e-c6ecdc45243c"
      },
      "source": [
        "not_cancer_set = load_folder(not_cancer_path)\n",
        "not_cancer_set -= mean[None, None, :]\n",
        "not_cancer_set /= std[None, None, :]\n",
        "seg_set = load_seg(seg_path, not_cancer_path)\n",
        "\n",
        "not_cancer_targets = np.zeros((not_cancer_set.shape[0])).astype(np.int64)\n",
        "\n",
        "not_cancer_dataset = TensorDataset(torch.from_numpy(not_cancer_set.swapaxes(1,3).swapaxes(2,3)).float(), torch.from_numpy(not_cancer_targets),torch.from_numpy(seg_set))\n",
        "\n",
        "del not_cancer_set\n",
        "del seg_set\n",
        "\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [08:38<00:00,  3.85it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [08:22<00:00,  3.98it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNeCSZrmut9r"
      },
      "source": [
        "#### Combine datasets and split to train-test-val"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSXkwWzEPB2B",
        "outputId": "735fb601-e46c-485b-fb6a-c7ed84c9e69a"
      },
      "source": [
        "complete_dataset = ConcatDataset((not_cancer_dataset, cancer_dataset ))\n",
        "num_total = len(complete_dataset)\n",
        "num_train = int(0.8 * num_total)\n",
        "num_val = int(0.1 * num_total)\n",
        "num_test = num_total - num_train - num_val\n",
        "torch.manual_seed(0);\n",
        "train_dataset, test_dataset, val_dataset= torch.utils.data.random_split(complete_dataset, [num_train, num_test, num_val])\n",
        "datasets = {'train' : train_dataset, 'test':test_dataset, 'val': val_dataset}\n",
        "dataset_sizes = {'train' : len(train_dataset), 'test':len(test_dataset), 'val': len(val_dataset)}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(datasets[x], batch_size=args.batch_size,\n",
        "                                             shuffle=True, num_workers=4)\n",
        "              for x in ['train', 'test','val']}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAMQLRX5uytt"
      },
      "source": [
        "#### Weights for training\n",
        "Since the classes are unbalanced, we need to account for this in the loss function while training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL-6d9qHR3WP"
      },
      "source": [
        "cancer_ratio =len(cancer_dataset)/len(complete_dataset)\n",
        "\n",
        "not_cancer_ratio = 1- cancer_ratio\n",
        "cancer_weight = 1/cancer_ratio\n",
        "not_cancer_weight = 1/ not_cancer_ratio\n",
        "weights = np.asarray([not_cancer_weight, cancer_weight])\n",
        "weights /= weights.sum()\n",
        "weights = torch.tensor(weights).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight = weights.double().float())\n",
        "\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=args.lr, momentum=args.momentum)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyuCsMPBwBC2"
      },
      "source": [
        "#### Functions for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LomNLJdeR8mi"
      },
      "source": [
        "def gradient_sum(im, target, seg ,  model, crit, device='cuda'):\n",
        "    '''  assume that eveything is already on cuda'''\n",
        "    im.requires_grad = True\n",
        "    grad_params = torch.abs(torch.autograd.grad(crit(model(im), target), im,create_graph = True)[0].sum(dim=1).masked_select(seg.byte())**2).sum()\n",
        "    return grad_params\n",
        "\n",
        "def train_model(model,dataloaders, criterion, optimizer, num_epochs=25):\n",
        "    since = time.time()\n",
        "    val_acc_history = []\n",
        "    val_loss_history = []\n",
        "    train_loss_history = []\n",
        "    \n",
        "    train_acc_history = []\n",
        "    train_cd_history= []\n",
        "    \n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_loss = 10.0\n",
        "    patience = 3\n",
        "    cur_patience = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                optimizer.step()\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_loss_cd = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for i, (inputs, labels, seg) in tqdm(enumerate(dataloaders[phase])):\n",
        "    \n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                \n",
        "                seg = seg.to(device)\n",
        "                \n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # need to do calc beforehand because we do need the gradients\n",
        "                    if phase == 'train' and regularizer_rate !=0:\n",
        "                        inputs.requires_grad = True\n",
        "                        add_loss = gradient_sum(inputs, labels, seg, model, criterion)  \n",
        "                        if add_loss!=0:\n",
        "                            (regularizer_rate*add_loss).backward()\n",
        "                            optimizer.step()\n",
        "                        #print(torch.cuda.memory_allocated()/(np.power(10,9)))\n",
        "                        optimizer.zero_grad()   \n",
        "                        running_loss_cd +=add_loss.item() * inputs.size(0)\n",
        "     \n",
        "                        #inputs.require_grad = False\n",
        "                         \n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    if phase == 'train':\n",
        "                        (loss).backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                \n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_cd_loss = running_loss_cd / dataset_sizes[phase]\n",
        "       \n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "  \n",
        "            print('{} Loss: {:.4f} Acc: {:.4f} CD Loss : {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc, epoch_cd_loss))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc.item())\n",
        "                val_loss_history.append(epoch_loss)\n",
        "            if phase == 'train':\n",
        "                train_loss_history.append(epoch_loss)\n",
        "                train_cd_history.append(epoch_cd_loss)\n",
        "                train_acc_history.append(epoch_acc.item())\n",
        "                \n",
        "            if phase == 'val':\n",
        "                if epoch_loss < best_loss:\n",
        "            \n",
        "                    best_loss = epoch_loss\n",
        "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                    cur_patience = 0\n",
        "                else:\n",
        "                    cur_patience+=1\n",
        "        if cur_patience >= patience:\n",
        "            break\n",
        "  \n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val loss: {:4f}'.format(best_loss))\n",
        "\n",
        "    # load best model weights\n",
        "\n",
        "    hist_dict = {}\n",
        "    hist_dict['val_acc_history'] = val_acc_history\n",
        "    hist_dict['val_loss_history'] = val_loss_history\n",
        "    \n",
        "    hist_dict['train_acc_history'] = train_acc_history\n",
        "\n",
        "    hist_dict['train_loss_history'] = val_loss_history\n",
        "    hist_dict['train_cd_history'] = train_cd_history\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model,hist_dict "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suYKwRYvv6DV"
      },
      "source": [
        "#### Train and save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jt97ZEQcSARG",
        "outputId": "be1dee2f-e694-44ec-fcab-77e357054ab7"
      },
      "source": [
        "model, hist_dict = train_model(model, dataloaders, criterion, optimizer_ft, num_epochs=num_epochs)\n",
        "pid = ''.join([\"%s\" % randint(0, 9) for num in range(0, 20)])\n",
        "torch.save(model.classifier.state_dict(),oj(dir_path, model_path, pid + \".pt\"))\n",
        "\n",
        "hist_dict['pid'] = pid\n",
        "hist_dict['regularizer_rate'] = regularizer_rate\n",
        "hist_dict['seed'] = args.seed\n",
        "hist_dict['batch_size'] = args.batch_size\n",
        "hist_dict['learning_rate'] = args.lr\n",
        "hist_dict['momentum'] = args.momentum\n",
        "pkl.dump(hist_dict, open(os.path.join(model_path , pid +  '.pkl'), 'wb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/4\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "110it [00:45,  2.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.5867 Acc: 0.8064 CD Loss : 0.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "14it [00:02,  6.65it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.4511 Acc: 0.9909 CD Loss : 0.0000\n",
            "Epoch 1/4\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "110it [00:46,  2.38it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.4013 Acc: 0.9533 CD Loss : 0.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "14it [00:02,  6.46it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.3349 Acc: 0.9954 CD Loss : 0.0000\n",
            "Epoch 2/4\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "110it [00:47,  2.33it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.3236 Acc: 0.9801 CD Loss : 0.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "14it [00:02,  6.30it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.2642 Acc: 0.9954 CD Loss : 0.0000\n",
            "Epoch 3/4\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "110it [00:47,  2.30it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.2737 Acc: 0.9789 CD Loss : 0.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "14it [00:02,  6.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.2307 Acc: 0.9954 CD Loss : 0.0000\n",
            "Epoch 4/4\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "110it [00:48,  2.28it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train Loss: 0.2365 Acc: 0.9846 CD Loss : 0.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "14it [00:02,  6.15it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val Loss: 0.2001 Acc: 0.9954 CD Loss : 0.0000\n",
            "Training complete in 4m 8s\n",
            "Best val loss: 0.200056\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "_Rs249a_wRv5",
        "outputId": "a44c8d9e-8487-44d2-e646-066cea58469f"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "imshow(test_dataset[0][2], cmap='Greys')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fac87fd13d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umEeCPdcz-Uu",
        "outputId": "c2f7e53d-2364-4b7d-82c7-8c32cc40f5c7"
      },
      "source": [
        "input = test_dataset[0][0][None,:,:,:].to(device)\n",
        "model(input)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.0761, -0.9196]], device='cuda:0', grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCQBnNIxNiEc"
      },
      "source": [
        "from sklearn.metrics import auc,average_precision_score, roc_curve,roc_auc_score,precision_recall_curve, f1_score\n",
        "\n",
        "def get_output(model, dataset):\n",
        "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=16,\n",
        "                                             shuffle=False, num_workers=4)\n",
        "    model = model.eval()\n",
        "    y = []\n",
        "    y_hat = []\n",
        "    softmax= torch.nn.Softmax()\n",
        "    with torch.no_grad() :\n",
        "        for inputs, labels, cd in data_loader:\n",
        "            y_hat.append((labels).cpu().numpy())\n",
        "            y.append(torch.nn.Softmax(dim=1)( model(inputs.cuda()))[:,1].detach().cpu().numpy()) # take the probability for cancer\n",
        "    y_hat = np.concatenate( y_hat, axis=0 )\n",
        "    y = np.concatenate( y, axis=0 )\n",
        "    return y, y_hat # in the training set the values were switched\n",
        "\n",
        "def get_auc_f1(model, dataset,fname = None, ):\n",
        "    if fname !=None:\n",
        "        with open(fname, 'rb') as f:\n",
        "            weights = torch.load(f)\n",
        "        if \"classifier.0.weight\" in weights.keys(): #for the gradient models we unfortunately saved all of the weights\n",
        "            model.load_state_dict(weights)\n",
        "        else:\n",
        "            model.classifier.load_state_dict(weights)\n",
        "        y, y_hat = get_output(model.classifier, dataset)\n",
        "    else:   \n",
        "        y, y_hat = get_output(model, dataset)\n",
        "    auc =roc_auc_score(y_hat, y)\n",
        "    f1 = np.asarray([f1_score(y_hat, y > x) for x in np.linspace(0.1,1, num = 10) if (y >x).any() and (y<x).any()]).max()\n",
        "    return auc, f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7sSm3CHN1_T",
        "outputId": "da761cc5-9d21-435b-c645-72d7bea97529"
      },
      "source": [
        "get_auc_f1(model, test_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.0, 1.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qKwJHU1OJLc",
        "outputId": "2ccd94e6-0c9b-4f3c-f31d-2f42a46f633f"
      },
      "source": [
        "out = get_output(model, test_dataset)\n",
        "\n",
        "print(np.where(out[0] > 0.5))\n",
        "print(np.where(out[1] == 1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(array([ 30,  34,  37,  41,  43,  62,  71,  86, 101, 104, 110, 128, 153,\n",
            "       171, 172, 176, 186, 196, 204, 206, 214]),)\n",
            "(array([ 30,  34,  37,  41,  43,  62,  71,  86, 101, 104, 110, 128, 153,\n",
            "       171, 172, 176, 186, 196, 204, 206, 214]),)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9RztNKPKERu",
        "outputId": "431ea0d5-a3cd-445c-9d8f-8cd241d33507"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73V2haOgLOYM",
        "outputId": "01a89c51-5364-4d04-e495-f8eaf8bf424d"
      },
      "source": [
        "print(models.vgg16(pretrained=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}